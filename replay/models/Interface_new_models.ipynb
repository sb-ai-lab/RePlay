{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitPredictStrategy():\n",
    "    \"\"\" Класс для выбора стретагий обучения и предикта \"\"\"\n",
    "    strategies = [\"spark\", \"pandas\", \"polars\"]\n",
    "    not_priority_strategies = [\"pandas\", \"polars\"]\n",
    "    DEFAULT_AVAILABLE_PART_OF_MEMORY = 0.3\n",
    "\n",
    "    def __init__(self, *dfs, fit_on = \"spark\", predict_on = \"spark\", available_memory_part=0.5):\n",
    "        self.is_local_calculating_enabled = False\n",
    "        self.fit_on = fit_on\n",
    "        self.predict_on = predict_on\n",
    "        if available_memory_part is None:\n",
    "            self.available_memory = psutil.virtual_memory()[0] * self.DEFAULT_AVAILABLE_PART_OF_MEMORY\n",
    "\n",
    "        if not self.fit_on in self.strategies or not self.predict_on in self.strategies:\n",
    "            raise ValueError(\"Not supported strategies for fit or predict\")\n",
    "        if (\n",
    "            self.fit_on in self.not_priority_strategies or \n",
    "            self.predict_on in self.not_priority_strategies or \n",
    "            check_spark_is_local()\n",
    "        ):\n",
    "            self.verdict = self.check_df_can_calculated_locally(*dfs)\n",
    "            if verdict is False:\n",
    "                raise ValueError(\"Dataset cant fit inside local computer\")\n",
    "            \n",
    "    def check_df_can_calculated_locally(self, *dfs):\n",
    "        sum_of_memory = 0\n",
    "        for df in dfs:\n",
    "            sum_of_memory += weight_of_df(df)\n",
    "        \n",
    "        if  self.available_memory >= sum_of_memory:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class PopRec(NonPersonolized_RecommenderSparkImpl):\n",
    "    from abc import abstractmethod\n",
    "    class_map = {\n",
    "            \"spark\": _PopRecSpark,\n",
    "            \"pandas\": _PopRecPandas,\n",
    "            \"polars\": _PopRecPolars\n",
    "        }\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            strategy: FitPredictStrategy, \n",
    "            use_rating: bool = False,\n",
    "            add_cold_items: bool = True,\n",
    "            cold_weight: float = 0.5,):\n",
    "        \n",
    "        self.implementation = self.class_map[strategy.fit_on](strategy, use_rating, add_cold_items, cold_weight)\n",
    "        self.use_rating = use_rating\n",
    "        self.add_cold_items = add_cold_items\n",
    "        self.cold_weight = cold_weight\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _fit(self):\n",
    "        return NotImplementedError(\"Реализуйте в классе PopRecSpark,PopRecPolars, PopRecPandas _fit\")\n",
    "\n",
    "class _PopRecSpark(PopRec):\n",
    "    def _fit(self, dataset):\n",
    "        self.implementation = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PopRec:\n",
    "    from abc import abstractmethod, a\n",
    "    class_map = {\n",
    "            \"spark\": _PopRecSpark,\n",
    "            \"pandas\": _PopRecPandas,\n",
    "            \"polars\": _PopRecPolars\n",
    "        }\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            use_rating: bool = False,\n",
    "            add_cold_items: bool = True,\n",
    "            cold_weight: float = 0.5,):\n",
    "        \n",
    "        self.implementation = None\n",
    "        self.use_rating = use_rating\n",
    "        self.add_cold_items = add_cold_items\n",
    "        self.cold_weight = cold_weight\n",
    "\n",
    "        self.is_fitted = False\n",
    "        super().__init__(add_cold_items=add_cold_items, cold_weight=cold_weight)\n",
    "\n",
    "    @property\n",
    "    def item_popularity(self):\n",
    "        return self.implementation._item_popularity\n",
    "    \n",
    "    @property\n",
    "    def fill(self):\n",
    "        return self.implementation._fill\n",
    "    \n",
    "    def _fit(self, dataset):\n",
    "        if dataset.is_spark:\n",
    "            self.implementation = _PopRecSpark(self.use_rating, self.add_cold_items, self.cold_weight)\n",
    "        elif dataset.is_pandas:\n",
    "            self.implementation = _PopRecPandas(self.use_rating, self.add_cold_items, self.cold_weight)\n",
    "        elif dataset.is_polars:\n",
    "            self.implementation = _PopRecPolars(self.use_rating, self.add_cold_items, self.cold_weight)\n",
    "\n",
    "        self.implementation._fit(dataset)\n",
    "        self.is_fitted = True\n",
    "        self._item_popularity = self.implementation.item_popularity\n",
    "        self._fill = self.implementation._fill\n",
    "\n",
    "    def to_pandas(self)\n",
    "        self.implentation.to_pandas()\n",
    "\n",
    "def _copy_simple_parameters_after_fit(self, impl, copy_implementation):\n",
    "        \"\"\" В _BaseRecommenderSparkImpl \"\"\"\n",
    "        copy_implementation.query_column = impl.feature_schema.query_id_column\n",
    "        copy_implementation.item_column = impl.feature_schema.item_id_column\n",
    "        copy_implementation.rating_column = impl.feature_schema.interactions_rating_column\n",
    "        copy_implementation.timestamp_column = impl.feature_schema.interactions_timestamp_column\n",
    "        copy_implementation._num_queries = impl._num_queries\n",
    "        copy_implementation._num_items = impl._num_items\n",
    "        copy_implementation._query_dim_size = impl._query_dim_size\n",
    "        copy_implementation._item_dim_size = impl._item_dim_size\n",
    "        return copy_implementation\n",
    "\n",
    "class _PopRecSpark(NonPersonolizedRecommender):\n",
    "    def _fit(self, dataset):\n",
    "        # стандартный пайплайн обработки, как в текущем пайплайне, на спарке\n",
    "        pass\n",
    "\n",
    "    def to_pandas(self):\n",
    "        copy_implementation = _PopRecPandas(self.use_rating, self.add_cold_items, self.cold_weight)\n",
    "        if self.is_fitted:\n",
    "            copy_implementation = self.copy_simple_parameters_after_fit(copy_implementation)\n",
    "            copy_implementation.fit_items = convert2pandas(self.fit_items)\n",
    "            copy_implementation.fit_queries = convert2pandas(self.fit_queries)\n",
    "            copy_implementation.item_popularity = convert2pandas(self.item_popularity)\n",
    "            copy_implementation.fill = self.fill\n",
    "\n",
    "    def to_polars(self):\n",
    "        copy_implementation = _PopRecPolars(self.use_rating, self.add_cold_items, self.cold_weight)\n",
    "        if self.is_fitted:\n",
    "            copy_implementation = self.copy_simple_parameters_after_fit(copy_implementation)\n",
    "            copy_implementation.fit_items = convert2polars(self.fit_items)\n",
    "            copy_implementation.fit_queries = convert2polars(self.fit_queries)\n",
    "            copy_implementation.item_popularity = convert2polars(self.item_popularity)\n",
    "            copy_implementation.fill = self.fill\n",
    "\n",
    "    \n",
    "class _PopRecPandas(PopRec):\n",
    "    def _fit(self, dataset):\n",
    "        # стандартный пайплайн обработки, как в текущем пайплайне, на пандасе\n",
    "        pass\n",
    "    \n",
    "    def copy_simple_parameters_after_fit(self, copy_implementation):\n",
    "        \"\"\" В _BaseRecommenderSparkImpl \"\"\"\n",
    "        copy_implementation.query_column = self.feature_schema.query_id_column\n",
    "        copy_implementation.item_column = self.feature_schema.item_id_column\n",
    "        copy_implementation.rating_column = self.feature_schema.interactions_rating_column\n",
    "        copy_implementation.timestamp_column = self.feature_schema.interactions_timestamp_column\n",
    "        copy_implementation._num_queries = self._num_queries\n",
    "        copy_implementation._num_items = self._num_items\n",
    "        copy_implementation._query_dim_size = self._query_dim_size\n",
    "        copy_implementation._item_dim_size = self._item_dim_size\n",
    "        return copy_implementation\n",
    "\n",
    "    def to_spark(self):\n",
    "        copy_implementation = _PopRecPandas(self.use_rating, self.add_cold_items, self.cold_weight)\n",
    "        if self.is_fitted:\n",
    "            copy_implementation = self.copy_simple_parameters_after_fit(copy_implementation)\n",
    "            copy_implementation.fit_items = convert2pandas(self.fit_items)\n",
    "            copy_implementation.fit_queries = convert2pandas(self.fit_queries)\n",
    "            copy_implementation.item_popularity = convert2pandas(self.item_popularity)\n",
    "            copy_implementation.fill = self.fill\n",
    "\n",
    "    def to_polars(self):\n",
    "        copy_implementation = _PopRecPolars(self.use_rating, self.add_cold_items, self.cold_weight)\n",
    "        if self.is_fitted:\n",
    "            copy_implementation = self.copy_simple_parameters_after_fit(copy_implementation)\n",
    "            copy_implementation.fit_items = convert2polars(self.fit_items)\n",
    "            copy_implementation.fit_queries = convert2polars(self.fit_queries)\n",
    "            copy_implementation.item_popularity = convert2polars(self.item_popularity)\n",
    "            copy_implementation.fill = self.fill\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from replay.data.dataset import Dataset, FeatureSchema, FeatureInfo, FeatureHint, FeatureType\n",
    "from replay.utils.spark_utils import convert2spark\n",
    "from replay.models.implementations.spark.pop_rec import PopRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(\n",
    "   {\"user_id\": [1, 1, 2, 2, 3, 4],\n",
    "    \"item_id\": [1, 2, 2, 3, 3, 3],\n",
    "    \"rating\": [0.5, 1, 0.1, 0.8, 0.7, 1]}\n",
    ")\n",
    "\n",
    "\n",
    "feature_schema = FeatureSchema(\n",
    "    [\n",
    "        FeatureInfo(\n",
    "            column=\"user_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.QUERY_ID,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"item_id\",\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            feature_hint=FeatureHint.ITEM_ID,\n",
    "        ),\n",
    "        FeatureInfo(\n",
    "            column=\"rating\",\n",
    "            feature_type=FeatureType.NUMERICAL,\n",
    "            feature_hint=FeatureHint.RATING,\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/11 16:21:17 WARN Utils: Your hostname, ecs-alaleksepetrov resolves to a loopback address: 127.0.1.1; using 10.11.12.194 instead (on interface eth0)\n",
      "25/02/11 16:21:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/11 16:21:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/11 16:21:18 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "25/02/11 16:21:19 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:19 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:19 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:22 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:23 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:23 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:23 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:24 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n"
     ]
    }
   ],
   "source": [
    "interactions = convert2spark(data_frame)\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "model = PopRec()\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "140017715916432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "25/02/11 16:15:20 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "25/02/11 16:15:20 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140017715916432\n",
      "True\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(model.implementation.is_fitted)\n",
    "print(type(model.implementation.fit_items))\n",
    "print(id(model))\n",
    "model.to_pandas()\n",
    "print(id(model))\n",
    "print(model.implementation.is_fitted)\n",
    "print(type(model.implementation.fit_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/11 16:21:25 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:26 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:26 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:27 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:27 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build right for right outer join.\n",
      "25/02/11 16:21:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: bigint, item_id: bigint, rating: double]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/11 16:21:28 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:28 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:28 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:28 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:29 WARN CacheManager: Asked to cache already cached data.\n",
      "25/02/11 16:21:29 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/02/11 16:21:29 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:30 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/02/11 16:21:30 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: bigint, item_id: bigint, rating: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_predict(dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "25/02/11 16:21:33 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "25/02/11 16:21:33 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19417/3818102820.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/replay/replay/models/pop_rec.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset, k)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pandas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/replay/replay/models/base_rec.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset, k, queries, items, filter_seen_items, recs_file_path)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaterialized\u001b[0m \u001b[0mrecommendations\u001b[0m \u001b[0mdataframe\u001b[0m  \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcached\u001b[0m \u001b[0mrecommendation\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \"\"\"\n\u001b[0;32m-> 1214\u001b[0;31m         return self._predict_wrap(\n\u001b[0m\u001b[1;32m   1215\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/replay/replay/models/base_rec.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset, k, queries, items, filter_seen_items, recs_file_path)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaterialized\u001b[0m \u001b[0mrecommendations\u001b[0m \u001b[0mdataframe\u001b[0m  \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcached\u001b[0m \u001b[0mrecommendation\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_interactions_queries_items_dataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         recs = self._predict(\n\u001b[1;32m    551\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/replay/replay/models/base_rec.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset, k, queries, items)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtriplet\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \"\"\"\n\u001b[1;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting predict %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mquery_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_features\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0minteractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mquery_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/replay_pip/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "dataset = dataset.to_pandas(inplace=False)\n",
    "model.to_pandas()\n",
    "model.predict(dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16251/1021830671.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minteractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopRec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/replay/replay/models/pop_rec.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PopRecPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_rating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cold_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcold_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m#elif dataset.is_polars:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m#    self.implementation = _PopRecPolars(self.use_rating, self.add_cold_items, self.cold_weight)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/replay/replay/models/base_rec.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhistorical\u001b[0m \u001b[0minteractions\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mitem\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \"\"\"\n\u001b[0;32m-> 1184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/replay/replay/models/base_rec.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractions_rating_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractions_timestamp_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting fit %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             queries = (\n\u001b[1;32m    388\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/replay_pip/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5898\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5899\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "interactions = data_frame\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "model = PopRec()\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replay_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
