from typing import NamedTuple, Optional

import torch
from torch.utils.data import Dataset as TorchDataset
from typing_extensions import deprecated

from replay.data.nn import (
    MutableTensorMap,
    SequentialDataset,
    TensorMap,
    TorchSequentialDataset,
    TorchSequentialValidationDataset,
)


@deprecated(
    "`SasRecTrainingBatch` class is deprecated.",
    stacklevel=2,
)
class SasRecTrainingBatch(NamedTuple):
    """
    Batch of data for training.
    Generated by `SasRecTrainingDataset`.
    """

    query_id: torch.LongTensor
    padding_mask: torch.BoolTensor
    features: TensorMap
    labels: torch.LongTensor
    labels_padding_mask: torch.BoolTensor

    def convert_to_dict(self) -> dict:
        return {
            "query_id": self.query_id,
            "feature_tensor": self.features,
            "padding_mask": self.padding_mask,
            "positive_labels": self.labels,
            "target_padding_mask": self.labels_padding_mask,
        }


@deprecated("`SasRecTrainingDataset` class is deprecated. Use `replay.data.nn.ParquetModule` instead.")
class SasRecTrainingDataset(TorchDataset):
    """
    Dataset that generates samples to train SasRec model.

    As a result of the dataset iteration, a dictionary is formed.
    The keys in the dictionary match the names of the arguments in the model's `forward` function.
    There are also additional keys needed to calculate losses - 'positive_labels`, `target_padding_mask`.
    The `query_id` key is required for possible debugging and calling additional lightning callbacks.
    """

    def __init__(
        self,
        sequential: SequentialDataset,
        max_sequence_length: int,
        sequence_shift: int = 1,
        sliding_window_step: Optional[None] = None,
        padding_value: Optional[int] = None,
        label_feature_name: Optional[str] = None,
    ) -> None:
        """
        :param sequential: Sequential dataset with training data.
        :param max_sequence_length: Max length of sequence.
        :param sequence_shift: Shift of sequence to predict.
        :param sliding_window_step: A sliding window step.
            If not ``None`` provides iteration over sequences with window.
            Default: ``None``.
        :param padding_value: Value for padding a sequence to match the `max_sequence_length`.
            Default: ``0``.
        :param label_feature_name: Name of label feature in provided dataset.
            If ``None`` set an item_id_feature name from sequential dataset.
            Default: ``None``.
        """
        super().__init__()
        if label_feature_name:
            if label_feature_name not in sequential.schema:
                msg = "Label feature name not found in provided schema"
                raise ValueError(msg)

            if not sequential.schema[label_feature_name].is_cat:
                msg = "Label feature must be categorical"
                raise ValueError(msg)

            if not sequential.schema[label_feature_name].is_seq:
                msg = "Label feature must be sequential"
                raise ValueError(msg)

        self._sequence_shift = sequence_shift
        self._max_sequence_length = max_sequence_length + sequence_shift
        self._label_feature_name = label_feature_name or sequential.schema.item_id_feature_name
        self._schema = sequential.schema

        self._inner = TorchSequentialDataset(
            sequential=sequential,
            max_sequence_length=self._max_sequence_length,
            sliding_window_step=sliding_window_step,
            padding_value=padding_value,
        )

    def __len__(self) -> int:
        return len(self._inner)

    def __getitem__(self, index: int) -> dict:
        query_id, padding_mask, features = self._inner[index]

        assert self._label_feature_name
        labels = features[self._label_feature_name][self._sequence_shift :]
        labels_padding_mask = padding_mask[self._sequence_shift :]

        output_features: MutableTensorMap = {}
        for feature_name in self._schema:
            feature = features[feature_name]
            if self._schema[feature_name].is_seq:
                feature = feature[: -self._sequence_shift]
            output_features[feature_name] = feature

        output_features_padding_mask = padding_mask[: -self._sequence_shift]

        return {
            "query_id": query_id,
            "feature_tensor": output_features,
            "padding_mask": output_features_padding_mask,
            "positive_labels": labels,
            "target_padding_mask": labels_padding_mask,
        }


@deprecated(
    "`SasRecPredictionBatch` class is deprecated.",
    stacklevel=2,
)
class SasRecPredictionBatch(NamedTuple):
    """
    Batch of data for model inference.
    Generated by `SasRecPredictionDataset`.
    """

    query_id: torch.LongTensor
    padding_mask: torch.BoolTensor
    features: TensorMap

    def convert_to_dict(self) -> dict:
        return {
            "query_id": self.query_id,
            "feature_tensor": self.features,
            "padding_mask": self.padding_mask,
        }


@deprecated("`SasRecPredictionDataset` class is deprecated. Use `replay.data.nn.ParquetModule` instead.")
class SasRecPredictionDataset(TorchDataset):
    """
    Dataset that generates samples to infer SasRec model

    As a result of the dataset iteration, a dictionary is formed.
    The keys in the dictionary match the names of the arguments in the model's `forward` function.
    The `query_id` key is required for possible debugging and calling additional lightning callbacks.
    """

    def __init__(
        self,
        sequential: SequentialDataset,
        max_sequence_length: int,
        padding_value: Optional[int] = None,
    ) -> None:
        """
        :param sequential: Sequential dataset with data to make predictions at.
        :param max_sequence_length: Max length of sequence.
        :param padding_value: Value for padding a sequence to match the `max_sequence_length`.
            Default: ``0``.
        """
        self._inner = TorchSequentialDataset(
            sequential=sequential,
            max_sequence_length=max_sequence_length,
            padding_value=padding_value,
        )

    def __len__(self) -> int:
        return len(self._inner)

    def __getitem__(self, index: int) -> dict:
        query_id, padding_mask, features = self._inner[index]
        return {
            "query_id": query_id,
            "padding_mask": padding_mask,
            "feature_tensor": features,
        }


@deprecated(
    "`SasRecValidationBatch` class is deprecated.",
    stacklevel=2,
)
class SasRecValidationBatch(NamedTuple):
    """
    Batch of data for validation.
    Generated by `SasRecValidationDataset`.
    """

    query_id: torch.LongTensor
    padding_mask: torch.BoolTensor
    features: TensorMap
    ground_truth: torch.LongTensor
    train: torch.LongTensor

    def convert_to_dict(self) -> dict:
        return {
            "query_id": self.query_id,
            "feature_tensor": self.features,
            "padding_mask": self.padding_mask,
            "ground_truth": self.ground_truth,
            "train": self.train,
        }


@deprecated("`SasRecValidationDataset` class is deprecated. Use `replay.data.nn.ParquetModule` instead.")
class SasRecValidationDataset(TorchDataset):
    """
    Dataset that generates samples to infer and validate SasRec model.

    As a result of the dataset iteration, a dictionary is formed.
    The keys in the dictionary match the names of the arguments in the model's `forward` function.
    The `query_id` key is required for possible debugging and calling additional lightning callbacks.
    Keys 'ground_truth` and `train` keys are required for metrics calculation on validation stage.
    """

    def __init__(
        self,
        sequential: SequentialDataset,
        ground_truth: SequentialDataset,
        train: SequentialDataset,
        max_sequence_length: int,
        padding_value: Optional[int] = None,
        label_feature_name: Optional[str] = None,
    ):
        """
        :param sequential: Sequential dataset with data to make predictions at.
        :param ground_truth: Sequential dataset with ground truth predictions.
        :param train: Sequential dataset with training data.
        :param max_sequence_length: Max length of sequence.
        :param padding_value: Value for padding a sequence to match the `max_sequence_length`.
            Default: ``0``.
        :param label_feature_name: Name of label feature in provided dataset.
            If ``None`` set an item_id_feature name from sequential dataset.
            Default: ``None``.
        """
        self._inner = TorchSequentialValidationDataset(
            sequential=sequential,
            ground_truth=ground_truth,
            train=train,
            max_sequence_length=max_sequence_length,
            padding_value=padding_value,
            label_feature_name=label_feature_name,
        )

    def __len__(self) -> int:
        return len(self._inner)

    def __getitem__(self, index: int) -> dict:
        query_id, padding_mask, features, ground_truth, train = self._inner[index]
        return {
            "query_id": query_id,
            "padding_mask": padding_mask,
            "feature_tensor": features,
            "ground_truth": ground_truth,
            "train": train,
        }
