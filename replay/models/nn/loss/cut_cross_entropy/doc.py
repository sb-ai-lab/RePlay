LINEAR_CROSS_ENTROPY_DOC = """Computes cross-entropy loss using the logits generated by performing
    the matrix multiplication between the embeddings (e) and classifier (c).

    This method saves GPU memory by not materializing the logits into GPU
    main memory.


    Specifically, this computes

    ```python

    loss = F.cross_entropy((e @ c.T).float(), targets)
    ```

    without allocating the intermediary (e @ c.T).float() matrix.

    :param e: Embedding of the inputs used to compute the logits. Shape (..., D)
    :param c: Classifier matrix. Shape (NumClasses, D)
    :param targets: The target class for each input. Values must be in [0, NumClasses). Shape (...)
    :param ignore_index: If an input as a target of this value, it is ignored in the loss computation.
    :param softcap: The value for logit softcapping.
    :param reduction: The reduction to perform over the loss. Supports "mean", "sum", and "none".
    :param shift: When non-zero, the embedding and targets will be shifted along the temporal axis to perform nth-next token prediction.
        Specifically, this is used to efficiently compute the following

        ```python
        shift_e = e[..., :-shift, :].flatten(0, -2)
        shift_targets = targets[..., shift:].flatten()

        loss = F.cross_entropy((shift_e @ c.T), targets)
        ```

        If given a boolean value, False will be treated as zero and True will be treated as one.

        When this value is non-zero or True, e and targets must have shape (..., T, D) and (..., T), respectively.

        Integer values must be in [0, T)
"""

CCE_OPTS_DOC = [
    """
    :param filter_eps: The threshold value used to determine which locations can be safely ignored
        in gradient computation. The default value of "auto" will automatically choose a value
        based on the input dtype.""",
    """
    :param use_kahan: Uses Kahan summation to increase the precision of CCE's reduction along the vocab axis. This only
        makes sense to set to True when filter_eps is None (or is a very very small value).""",
]


def add_doc_start(*docstr: str):
    def add_doc(fn):
        fn.__doc__ = "".join(docstr) + (fn.__doc__ if fn.__doc__ is not None else "")

        return fn

    return add_doc
