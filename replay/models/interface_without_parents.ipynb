{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 116 (740817293.py, line 119)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 119\u001b[0;36m\u001b[0m\n\u001b[0;31m    def predict_without_sampling(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 116\n"
     ]
    }
   ],
   "source": [
    "from replay.utils import PYSPARK_AVAILABLE, PandasDataFrame, SparkDataFrame\n",
    "from replay.data import Dataset\n",
    "\n",
    "class _PandasPopRec:\n",
    "    def __init__(\n",
    "            self, \n",
    "            use_rating: bool = False,\n",
    "            add_cold_items: bool = True,\n",
    "            cold_weight: float = 0.5, sample=True, fill=0.0, seed=42, **kwargs):\n",
    "        self.use_rating = use_rating\n",
    "        self.sample = sample\n",
    "        self.fill = fill\n",
    "        self.seed = seed\n",
    "        self.add_cold_items = add_cold_items\n",
    "        self.cold_weight = cold_weight\n",
    "        self.item_popularity = None\n",
    "        self.fit_items = None\n",
    "        self.fit_queries = None\n",
    "        self.other_params = kwargs\n",
    "\n",
    "    @staticmethod\n",
    "    def _calc_fill(item_popularity: PandasDataFrame, weight: float, rating_column: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculating a fill value a the minimal rating\n",
    "        calculated during model training multiplied by weight.\n",
    "        \"\"\"\n",
    "        return item_popularity[rating_column].min() * weight\n",
    "    \n",
    "    def _get_selected_item_popularity(self, items: PandasDataFrame) -> PandasDataFrame:\n",
    "        \"\"\"\n",
    "        Choose only required item from `item_popularity` dataframe\n",
    "        for further recommendations generation.\n",
    "        \"\"\"\n",
    "        df = self.item_popularity.merge(\n",
    "            items, on=self.item_column, how='right' if self.add_cold_items else 'inner'\n",
    "            )\n",
    "        df = df.fillna(value=self.fill)\n",
    "        return df\n",
    "\n",
    "    def _get_fit_counts(self, entity: str) -> int:\n",
    "        num_entities = \"_num_queries\" if entity == \"query\" else \"_num_items\"\n",
    "        fit_entities = self.fit_queries if entity == \"query\" else self.fit_items\n",
    "        if not hasattr(self, num_entities):\n",
    "            setattr(\n",
    "                self,\n",
    "                num_entities,\n",
    "                fit_entities.count(),\n",
    "            )\n",
    "        return getattr(self, num_entities)\n",
    "\n",
    "    @property\n",
    "    def queries_count(self) -> int:\n",
    "        \"\"\"\n",
    "        :returns: number of queries the model was trained on\n",
    "        \"\"\"\n",
    "        return self._get_fit_counts(\"query\")\n",
    "\n",
    "    def fit(self, dataset: PandasDataFrame):\n",
    "        self.query_column = dataset.feature_schema.query_id_column\n",
    "        self.item_column = dataset.feature_schema.item_id_column\n",
    "        self.rating_column = dataset.feature_schema.interactions_rating_column\n",
    "        self.timestamp_column = dataset.feature_schema.interactions_timestamp_column\n",
    "        self.fit_items =  dataset.interactions[self.item_column].drop_duplicates()\n",
    "        self.fit_queries =  dataset.interactions[self.query_column].drop_duplicates()\n",
    "        self._num_queries = self.fit_queries.shape[0]\n",
    "        self._num_items = self.fit_items.shape[0]\n",
    "        self._query_dim_size = self.fit_queries.max() + 1\n",
    "        self._item_dim_size = self.fit_items.max() + 1\n",
    "        interactions_df = dataset.interactions\n",
    "\n",
    "        if self.use_rating:\n",
    "            item_popularity = interactions_df.groupby(self.item_column, as_index=False)[self.rating_column].sum()\n",
    "        else:\n",
    "            item_popularity = interactions_df.groupby(self.item_column, as_index=False)[self.query_column].nunique()\n",
    "            item_popularity.rename(columns={self.query_column: self.rating_column}, inplace=True)\n",
    "\n",
    "        item_popularity[self.rating_column] = item_popularity[self.rating_column] / self.queries_count\n",
    "\n",
    "        self.item_popularity = item_popularity\n",
    "        self.fill = self._calc_fill(self.item_popularity, self.cold_weight, self.rating_column)\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _calc_max_hist_len(dataset: Dataset, queries: PandasDataFrame) -> int:\n",
    "        query_column = dataset.feature_schema.query_id_column\n",
    "        item_column = dataset.feature_schema.item_id_column\n",
    "        merged_df = dataset.merge(queries, on='query_column', how='left')\n",
    "\n",
    "        # Группировка по столбцу query_column и подсчет уникальных значений в столбце item_column\n",
    "        grouped_df = merged_df.groupby('query_column').item_column.nunique()\n",
    "\n",
    "        # Максимальное количество уникальных значений\n",
    "        max_hist_len = grouped_df.max()\n",
    "        # all queries have empty history\n",
    "        if max_hist_len is None:\n",
    "            max_hist_len = 0\n",
    "\n",
    "        return max_hist_len\n",
    "\n",
    "    def get_items_pd(self, items: PandasDataFrame) -> PandasDataFrame:\n",
    "        \"\"\"\n",
    "        Function to calculate normalized popularities(in fact, probabilities)\n",
    "        of given items. Returns pandas DataFrame.\n",
    "        \"\"\"\n",
    "        selected_item_popularity = self._get_selected_item_popularity(items)\n",
    "        selected_item_popularity[self.rating_column] = selected_item_popularity.apply(\n",
    "            lambda row: 0.1 ** 6 if row['rating_column'] == 0.0 else row['rating_column'],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        total_rating = selected_item_popularity[self.rating_column].sum()\n",
    "\n",
    "        selected_item_popularity[\"probability\"] = selected_item_popularity[self.rating_column] / total_rating\n",
    "        return selected_item_popularity\n",
    "    \n",
    "    def left_wild_join(left_df, right_df, on):\n",
    "        \n",
    "\n",
    "    def predict_without_sampling(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        k: int,\n",
    "        queries: PandasDataFrame,\n",
    "        items: PandasDataFrame,\n",
    "        filter_seen_items: bool = True,\n",
    "    ) -> PandasDataFrame:\n",
    "        \"\"\"\n",
    "        Regular prediction for popularity-based models,\n",
    "        top-k most relevant items from `items` are chosen for each query\n",
    "        \"\"\"\n",
    "        selected_item_popularity = self._get_selected_item_popularity(items if items is not None else self.fit_items) \n",
    "        # TODO: не учел фильтры из _BaseRecommenderSparkImpl _filter_interactions_queries_items_dataframes\n",
    "        sorted_df = selected_item_popularity.sort_values(by=[self.rating_column, self.item_column], ascending=False)\n",
    "        selected_item_popularity[\"rank\"] = sorted_df.index + 1\n",
    "\n",
    "        if filter_seen_items and dataset is not None:\n",
    "            queries = PandasDataFrame(queries if queries is not None else self.fit_queries)\n",
    "            query_to_num_items = (\n",
    "                dataset.interactions.merge(queries\n",
    "                                           , on=self.query_column)\n",
    "                .groupby(self.query_column, as_index=False)[self.item_column].nunique()\n",
    "            ).rename(columns={self.item_column : \"num_items\"})\n",
    "            print(query_to_num_items)\n",
    "            queries = queries.merge(query_to_num_items, on=self.query_column, how=\"left\")\n",
    "            queries = queries.fillna(0)\n",
    "            print(queries)\n",
    "            max_seen = queries['num_items'].max()\n",
    "            selected_item_popularity = selected_item_popularity.query(\"rank <= @k + @max_seen\")\n",
    "            joined = queries.merge(selected_item_popularity, how=\"cross\")\n",
    "            return joined[joined['rank'] <= (k+joined[\"num_items\"])].drop(\"num_items\",axis=1)  # TODO: на пандас и поларс нет left join с нечетким условием. Нужно реализовать через 2 join и union\n",
    "        joined = queries.merge(selected_item_popularity, how=\"cross\")\n",
    "        return joined[joined['rank'] <= k].drop(\"rank\")\n",
    "    \n",
    "    def predict(self, dataset: PandasDataFrame, k: int, queries, items: PandasDataFrame, filter_seen_items=True) -> PandasDataFrame:\n",
    "        return self.predict_without_sampling(dataset, k, queries, items, filter_seen_items)\n",
    "\n",
    "    def fit_predict(self, dataset: PandasDataFrame, k: int, queries: PandasDataFrame = None, items: PandasDataFrame = None, filter_seen_items=True) -> PandasDataFrame:\n",
    "        self.fit(dataset)\n",
    "        return self.predict(dataset, k, queries, items, filter_seen_items)\n",
    "    \n",
    "    def predict_pairs(self, pairs: PandasDataFrame, dataset: PandasDataFrame = None) ->PandasDataFrame:\n",
    "        if self.item_popularity is None:\n",
    "            raise ValueError(\"Model not fitted. Please call fit() first.\")\n",
    "        preds = pairs.merge(self.item_popularity, on=self.item_column, how=\"left\" if self.add_cold_items else \"inner\")\n",
    "        preds[self.rating_column].fillna(self._calc_fill(), inplace=True)\n",
    "        return preds[[self.query_column, self.item_column, self.rating_column]]\n",
    "\n",
    "    def predict_proba(self, dataset: PandasDataFrame, k: int, queries, items: PandasDataFrame, filter_seen_items=True) -> PandasDataFrame:\n",
    "        pass # большая реализация с наследованием и сторонними функциями\n",
    "\n",
    "    def to_spark(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def to_pandas(self):\n",
    "        _SparkPopRec()\n",
    "        pass\n",
    "\n",
    "\n",
    "    def save_model(self, path: str, additional_params = None):\n",
    "        saved_params = {\n",
    "            \"query_column\": self.query_column,\n",
    "            \"item_column\": self.item_column,\n",
    "            \"rating_column\": self.rating_column,\n",
    "            \"timestamp_column\": self.timestamp_column,\n",
    "        }\n",
    "        if additional_params is not None:\n",
    "            saved_params.update(additional_params)\n",
    "        return saved_params\n",
    "        #save_picklable_to_parquet(saved_params, join(path, \"params.dump\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from replay.data.dataset import Dataset, FeatureSchema, FeatureInfo, FeatureHint, FeatureType\n",
    "from replay.utils.spark_utils import convert2spark\n",
    "#from replay.utils.common import convert2polars\n",
    "from replay.models import PopRec\n",
    "\n",
    "data_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\": [1, 1, 2, 2, 3, 4],\n",
    "        \"item_id\": [1, 2, 2, 3, 3, 3],\n",
    "        \"rating\": [0.5, 1, 0.1, 0.8, 0.7, 1]\n",
    "    }\n",
    ")\n",
    "feature_schema = FeatureSchema([\n",
    "    FeatureInfo(\n",
    "        column=\"user_id\",\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_hint=FeatureHint.QUERY_ID,\n",
    "    ),\n",
    "    FeatureInfo(\n",
    "        column=\"item_id\",\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "    ),\n",
    "    FeatureInfo(\n",
    "        \n",
    "        column=\"rating\",\n",
    "        feature_type=FeatureType.NUMERICAL,\n",
    "        feature_hint=FeatureHint.RATING,\n",
    "    )\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/03 14:10:50 WARN Utils: Your hostname, ecs-alaleksepetrov resolves to a loopback address: 127.0.1.1; using 10.11.12.194 instead (on interface eth0)\n",
      "25/03/03 14:10:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/03 14:10:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/03 14:10:51 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "25/03/03 14:10:52 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/03/03 14:10:52 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/03/03 14:10:52 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/03/03 14:10:54 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:10:56 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:10:56 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:10:56 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:10:56 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/03/03 14:10:58 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:10:59 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/03/03 14:10:59 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/03/03 14:11:00 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "25/03/03 14:11:00 WARN HintErrorLogger: Hint (strategy=broadcast) is not supported in the query: build right for right outer join.\n",
      "25/03/03 14:11:00 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "interactions = convert2spark(data_frame)\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "model = PopRec()\n",
    "res = model.fit_predict(dataset, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/03 14:11:01 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:11:01 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:11:01 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:11:01 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "25/03/03 14:11:01 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "interactions = convert2spark(data_frame)\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "model = PopRec()\n",
    "res = model.fit(dataset)\n",
    "#res.sort('user_id').toPandas()#.sort_values(\"user_id\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "03-Mar-25 14:11:01, replay, WARNING: Converting big dataframes from spark to pandas can cause OOM error.\n",
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "25/03/03 14:11:01 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n",
      "/home/alaleksepetrov/projects/replay/replay/utils/spark_utils.py:60: SparkCollectToMasterWarning: Spark Data Frame is collected to master node, this may lead to OOM exception for larger dataset. To remove this warning set allow_collect_to_master=True.\n",
      "  warnings.warn(\n",
      "25/03/03 14:11:02 WARN HintErrorLogger: A join hint (strategy=broadcast) is specified but it is not part of a join relation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_rating': False, 'add_cold_items': True, 'cold_weight': 0.5}\n",
      "dataset=<replay.data.dataset.Dataset object at 0x7fbb2fa85bd0>, filter_seen_items=True\n",
      "items\n",
      "    item_id  rating\n",
      "0        1    0.25\n",
      "1        2    0.50\n",
      "2        3    0.75\n",
      "selected_item_popularity\n",
      "    item_id  rating\n",
      "0        1    0.25\n",
      "1        2    0.50\n",
      "2        3    0.75\n",
      "selected_item_popularity2\n",
      "    item_id  rating  rank\n",
      "0        1    0.25     3\n",
      "1        2    0.50     2\n",
      "2        3    0.75     1\n",
      "   user_id  num_items\n",
      "0        1          2\n",
      "1        2          2\n",
      "2        3          1\n",
      "3        4          1\n",
      "   user_id  num_items\n",
      "0        1          2\n",
      "1        2          2\n",
      "2        3          1\n",
      "3        4          1\n",
      "joined\n",
      "     user_id  num_items  item_id  rating  rank\n",
      "0         1          2        1    0.25     3\n",
      "1         1          2        2    0.50     2\n",
      "2         1          2        3    0.75     1\n",
      "3         2          2        1    0.25     3\n",
      "4         2          2        2    0.50     2\n",
      "5         2          2        3    0.75     1\n",
      "6         3          1        1    0.25     3\n",
      "7         3          1        2    0.50     2\n",
      "8         3          1        3    0.75     1\n",
      "9         4          1        1    0.25     3\n",
      "10        4          1        2    0.50     2\n",
      "11        4          1        3    0.75     1\n",
      "dataset.interaction\n",
      "    user_id  item_id  rating\n",
      "0        1        1     0.5\n",
      "1        1        2     1.0\n",
      "2        2        2     0.1\n",
      "3        2        3     0.8\n",
      "4        3        3     0.7\n",
      "5        4        3     1.0\n",
      "queries_interactions\n",
      "    query  item  rating\n",
      "0      1     1     0.5\n",
      "1      1     2     1.0\n",
      "2      2     2     0.1\n",
      "3      2     3     0.8\n",
      "4      3     3     0.7\n",
      "5      4     3     1.0\n",
      "recs\n",
      "    user_id  item_id  rating  rank\n",
      "0        1        1    0.25     3\n",
      "1        1        2    0.50     2\n",
      "2        1        3    0.75     1\n",
      "3        2        1    0.25     3\n",
      "4        2        2    0.50     2\n",
      "5        2        3    0.75     1\n",
      "6        3        2    0.50     2\n",
      "7        3        3    0.75     1\n",
      "8        4        2    0.50     2\n",
      "9        4        3    0.75     1\n",
      "   user_id  item_id  rating  rank  query  item     _merge\n",
      "0        1        1    0.25     3    1.0   1.0       both\n",
      "1        1        2    0.50     2    1.0   2.0       both\n",
      "2        1        3    0.75     1    NaN   NaN  left_only\n",
      "3        2        1    0.25     3    NaN   NaN  left_only\n",
      "4        2        2    0.50     2    2.0   2.0       both\n",
      "5        2        3    0.75     1    2.0   3.0       both\n",
      "6        3        2    0.50     2    NaN   NaN  left_only\n",
      "7        3        3    0.75     1    3.0   3.0       both\n",
      "8        4        2    0.50     2    NaN   NaN  left_only\n",
      "9        4        3    0.75     1    4.0   3.0       both\n",
      "sorted_df\n",
      "    user_id  item_id  rating  rank\n",
      "2        1        3    0.75     1\n",
      "3        2        1    0.25     3\n",
      "6        3        2    0.50     2\n",
      "8        4        2    0.50     2\n",
      "top_k_df\n",
      "    user_id  item_id  rating  rank\n",
      "2        1        3    0.75     1\n",
      "3        2        1    0.25     3\n",
      "6        3        2    0.50     2\n",
      "8        4        2    0.50     2\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "2        1        3    0.75\n",
       "3        2        1    0.25\n",
       "6        3        2    0.50\n",
       "8        4        2    0.50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from replay.utils.common import convert2polars\n",
    "model.to_pandas()\n",
    "interactions = data_frame#convert2polars(data_frame)\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "res = model.predict(dataset, 1)\n",
    "print(type(res))\n",
    "res.sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT PREDICT: dataset.is_polars=True, filter_seen_items=True\n",
      "items\n",
      " shape: (3, 2)\n",
      "┌─────────┬────────┐\n",
      "│ item_id ┆ rating │\n",
      "│ ---     ┆ ---    │\n",
      "│ i64     ┆ f64    │\n",
      "╞═════════╪════════╡\n",
      "│ 1       ┆ 0.25   │\n",
      "│ 2       ┆ 0.5    │\n",
      "│ 3       ┆ 0.75   │\n",
      "└─────────┴────────┘\n",
      "selected_item_popularity\n",
      " shape: (3, 2)\n",
      "┌─────────┬────────┐\n",
      "│ item_id ┆ rating │\n",
      "│ ---     ┆ ---    │\n",
      "│ i64     ┆ f64    │\n",
      "╞═════════╪════════╡\n",
      "│ 1       ┆ 0.25   │\n",
      "│ 2       ┆ 0.5    │\n",
      "│ 3       ┆ 0.75   │\n",
      "└─────────┴────────┘\n",
      "selected_item_popularity2\n",
      " shape: (3, 3)\n",
      "┌──────┬─────────┬────────┐\n",
      "│ rank ┆ item_id ┆ rating │\n",
      "│ ---  ┆ ---     ┆ ---    │\n",
      "│ u32  ┆ i64     ┆ f64    │\n",
      "╞══════╪═════════╪════════╡\n",
      "│ 1    ┆ 3       ┆ 0.75   │\n",
      "│ 2    ┆ 2       ┆ 0.5    │\n",
      "│ 3    ┆ 1       ┆ 0.25   │\n",
      "└──────┴─────────┴────────┘\n",
      "joined\n",
      " shape: (12, 5)\n",
      "┌─────────┬───────────┬──────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ rank ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---  ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ u32  ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪══════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 1    ┆ 3       ┆ 0.75   │\n",
      "│ 1       ┆ 2         ┆ 2    ┆ 2       ┆ 0.5    │\n",
      "│ 1       ┆ 2         ┆ 3    ┆ 1       ┆ 0.25   │\n",
      "│ 3       ┆ 1         ┆ 1    ┆ 3       ┆ 0.75   │\n",
      "│ 3       ┆ 1         ┆ 2    ┆ 2       ┆ 0.5    │\n",
      "│ …       ┆ …         ┆ …    ┆ …       ┆ …      │\n",
      "│ 2       ┆ 2         ┆ 2    ┆ 2       ┆ 0.5    │\n",
      "│ 2       ┆ 2         ┆ 3    ┆ 1       ┆ 0.25   │\n",
      "│ 4       ┆ 1         ┆ 1    ┆ 3       ┆ 0.75   │\n",
      "│ 4       ┆ 1         ┆ 2    ┆ 2       ┆ 0.5    │\n",
      "│ 4       ┆ 1         ┆ 3    ┆ 1       ┆ 0.25   │\n",
      "└─────────┴───────────┴──────┴─────────┴────────┘\n",
      "recs in predict\n",
      " shape: (10, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.75   │\n",
      "│ 1       ┆ 2         ┆ 2       ┆ 0.5    │\n",
      "│ 1       ┆ 2         ┆ 1       ┆ 0.25   │\n",
      "│ 3       ┆ 1         ┆ 3       ┆ 0.75   │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "│ 2       ┆ 2         ┆ 3       ┆ 0.75   │\n",
      "│ 2       ┆ 2         ┆ 2       ┆ 0.5    │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.25   │\n",
      "│ 4       ┆ 1         ┆ 3       ┆ 0.75   │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "dataset.interaction\n",
      " shape: (6, 3)\n",
      "┌─────────┬─────────┬────────┐\n",
      "│ user_id ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ i64     ┆ f64    │\n",
      "╞═════════╪═════════╪════════╡\n",
      "│ 1       ┆ 1       ┆ 0.5    │\n",
      "│ 1       ┆ 2       ┆ 1.0    │\n",
      "│ 2       ┆ 2       ┆ 0.1    │\n",
      "│ 2       ┆ 3       ┆ 0.8    │\n",
      "│ 3       ┆ 3       ┆ 0.7    │\n",
      "│ 4       ┆ 3       ┆ 1.0    │\n",
      "└─────────┴─────────┴────────┘\n",
      "queries_interactions\n",
      " shape: (6, 3)\n",
      "┌───────┬──────┬────────┐\n",
      "│ query ┆ item ┆ rating │\n",
      "│ ---   ┆ ---  ┆ ---    │\n",
      "│ i64   ┆ i64  ┆ f64    │\n",
      "╞═══════╪══════╪════════╡\n",
      "│ 1     ┆ 1    ┆ 0.5    │\n",
      "│ 1     ┆ 2    ┆ 1.0    │\n",
      "│ 2     ┆ 2    ┆ 0.1    │\n",
      "│ 2     ┆ 3    ┆ 0.8    │\n",
      "│ 3     ┆ 3    ┆ 0.7    │\n",
      "│ 4     ┆ 3    ┆ 1.0    │\n",
      "└───────┴──────┴────────┘\n",
      "recs\n",
      " shape: (10, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.75   │\n",
      "│ 1       ┆ 2         ┆ 2       ┆ 0.5    │\n",
      "│ 1       ┆ 2         ┆ 1       ┆ 0.25   │\n",
      "│ 3       ┆ 1         ┆ 3       ┆ 0.75   │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "│ 2       ┆ 2         ┆ 3       ┆ 0.75   │\n",
      "│ 2       ┆ 2         ┆ 2       ┆ 0.5    │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.25   │\n",
      "│ 4       ┆ 1         ┆ 3       ┆ 0.75   │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "shape: (4, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.75   │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.25   │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "sorted_df\n",
      " shape: (4, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.75   │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.25   │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "top_k_df\n",
      " shape: (4, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.75   │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.25   │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.5    │\n",
      "└─────────┴───────────┴─────────┴────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th></tr><tr><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>3</td><td>0.75</td></tr><tr><td>2</td><td>1</td><td>0.25</td></tr><tr><td>3</td><td>2</td><td>0.5</td></tr><tr><td>4</td><td>2</td><td>0.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌─────────┬─────────┬────────┐\n",
       "│ user_id ┆ item_id ┆ rating │\n",
       "│ ---     ┆ ---     ┆ ---    │\n",
       "│ i64     ┆ i64     ┆ f64    │\n",
       "╞═════════╪═════════╪════════╡\n",
       "│ 1       ┆ 3       ┆ 0.75   │\n",
       "│ 2       ┆ 1       ┆ 0.25   │\n",
       "│ 3       ┆ 2       ┆ 0.5    │\n",
       "│ 4       ┆ 2       ┆ 0.5    │\n",
       "└─────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = interactions = convert2polars(data_frame)\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "model = PopRec()\n",
    "res = model.fit_predict(dataset, 1)#, filter_seen_items=False)\n",
    "res#.sort_values(\"user_id\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset=<replay.data.dataset.Dataset object at 0x7fa73ad60c10>, filter_seen_items=True\n",
      "items\n",
      "    item_id  rating\n",
      "0        1   0.125\n",
      "1        2   0.275\n",
      "2        3   0.625\n",
      "selected_item_popularity\n",
      "    item_id  rating\n",
      "0        1   0.125\n",
      "1        2   0.275\n",
      "2        3   0.625\n",
      "selected_item_popularity2\n",
      "    item_id  rating  rank\n",
      "0        1   0.125     3\n",
      "1        2   0.275     2\n",
      "2        3   0.625     1\n",
      "   user_id  num_items\n",
      "0        1          2\n",
      "1        2          2\n",
      "2        3          1\n",
      "3        4          1\n",
      "   user_id  num_items\n",
      "0        1          2\n",
      "1        2          2\n",
      "2        3          1\n",
      "3        4          1\n",
      "joined\n",
      "     user_id  num_items  item_id  rating  rank\n",
      "0         1          2        1   0.125     3\n",
      "1         1          2        2   0.275     2\n",
      "2         1          2        3   0.625     1\n",
      "3         2          2        1   0.125     3\n",
      "4         2          2        2   0.275     2\n",
      "5         2          2        3   0.625     1\n",
      "6         3          1        1   0.125     3\n",
      "7         3          1        2   0.275     2\n",
      "8         3          1        3   0.625     1\n",
      "9         4          1        1   0.125     3\n",
      "10        4          1        2   0.275     2\n",
      "11        4          1        3   0.625     1\n",
      "dataset.interaction\n",
      "    user_id  item_id  rating\n",
      "0        1        1     0.5\n",
      "1        1        2     1.0\n",
      "2        2        2     0.1\n",
      "3        2        3     0.8\n",
      "4        3        3     0.7\n",
      "5        4        3     1.0\n",
      "queries_interactions\n",
      "    query  item  rating\n",
      "0      1     1     0.5\n",
      "1      1     2     1.0\n",
      "2      2     2     0.1\n",
      "3      2     3     0.8\n",
      "4      3     3     0.7\n",
      "5      4     3     1.0\n",
      "recs\n",
      "    user_id  item_id  rating  rank\n",
      "0        1        1   0.125     3\n",
      "1        1        2   0.275     2\n",
      "2        1        3   0.625     1\n",
      "3        2        1   0.125     3\n",
      "4        2        2   0.275     2\n",
      "5        2        3   0.625     1\n",
      "6        3        2   0.275     2\n",
      "7        3        3   0.625     1\n",
      "8        4        2   0.275     2\n",
      "9        4        3   0.625     1\n",
      "   user_id  item_id  rating  rank  query  item     _merge\n",
      "0        1        1   0.125     3    1.0   1.0       both\n",
      "1        1        2   0.275     2    1.0   2.0       both\n",
      "2        1        3   0.625     1    NaN   NaN  left_only\n",
      "3        2        1   0.125     3    NaN   NaN  left_only\n",
      "4        2        2   0.275     2    2.0   2.0       both\n",
      "5        2        3   0.625     1    2.0   3.0       both\n",
      "6        3        2   0.275     2    NaN   NaN  left_only\n",
      "7        3        3   0.625     1    3.0   3.0       both\n",
      "8        4        2   0.275     2    NaN   NaN  left_only\n",
      "9        4        3   0.625     1    4.0   3.0       both\n",
      "sorted_df\n",
      "    user_id  item_id  rating  rank\n",
      "2        1        3   0.625     1\n",
      "3        2        1   0.125     3\n",
      "6        3        2   0.275     2\n",
      "8        4        2   0.275     2\n",
      "top_k_df\n",
      "    user_id  item_id  rating  rank\n",
      "2        1        3   0.625     1\n",
      "3        2        1   0.125     3\n",
      "6        3        2   0.275     2\n",
      "8        4        2   0.275     2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "2        1        3   0.625\n",
       "3        2        1   0.125\n",
       "6        3        2   0.275\n",
       "8        4        2   0.275"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = data_frame\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "model = PopRec(use_rating=True)\n",
    "res = model.fit_predict(dataset, 1)\n",
    "res#.sort_values(\"user_id\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT PREDICT: dataset.is_polars=True, filter_seen_items=True\n",
      "items\n",
      " shape: (3, 2)\n",
      "┌─────────┬────────┐\n",
      "│ item_id ┆ rating │\n",
      "│ ---     ┆ ---    │\n",
      "│ i64     ┆ f64    │\n",
      "╞═════════╪════════╡\n",
      "│ 2       ┆ 0.275  │\n",
      "│ 3       ┆ 0.625  │\n",
      "│ 1       ┆ 0.125  │\n",
      "└─────────┴────────┘\n",
      "selected_item_popularity\n",
      " shape: (3, 2)\n",
      "┌─────────┬────────┐\n",
      "│ item_id ┆ rating │\n",
      "│ ---     ┆ ---    │\n",
      "│ i64     ┆ f64    │\n",
      "╞═════════╪════════╡\n",
      "│ 2       ┆ 0.275  │\n",
      "│ 3       ┆ 0.625  │\n",
      "│ 1       ┆ 0.125  │\n",
      "└─────────┴────────┘\n",
      "selected_item_popularity2\n",
      " shape: (3, 3)\n",
      "┌──────┬─────────┬────────┐\n",
      "│ rank ┆ item_id ┆ rating │\n",
      "│ ---  ┆ ---     ┆ ---    │\n",
      "│ u32  ┆ i64     ┆ f64    │\n",
      "╞══════╪═════════╪════════╡\n",
      "│ 1    ┆ 3       ┆ 0.625  │\n",
      "│ 2    ┆ 2       ┆ 0.275  │\n",
      "│ 3    ┆ 1       ┆ 0.125  │\n",
      "└──────┴─────────┴────────┘\n",
      "joined\n",
      " shape: (12, 5)\n",
      "┌─────────┬───────────┬──────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ rank ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---  ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ u32  ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪══════╪═════════╪════════╡\n",
      "│ 2       ┆ 2         ┆ 1    ┆ 3       ┆ 0.625  │\n",
      "│ 2       ┆ 2         ┆ 2    ┆ 2       ┆ 0.275  │\n",
      "│ 2       ┆ 2         ┆ 3    ┆ 1       ┆ 0.125  │\n",
      "│ 4       ┆ 1         ┆ 1    ┆ 3       ┆ 0.625  │\n",
      "│ 4       ┆ 1         ┆ 2    ┆ 2       ┆ 0.275  │\n",
      "│ …       ┆ …         ┆ …    ┆ …       ┆ …      │\n",
      "│ 3       ┆ 1         ┆ 2    ┆ 2       ┆ 0.275  │\n",
      "│ 3       ┆ 1         ┆ 3    ┆ 1       ┆ 0.125  │\n",
      "│ 1       ┆ 2         ┆ 1    ┆ 3       ┆ 0.625  │\n",
      "│ 1       ┆ 2         ┆ 2    ┆ 2       ┆ 0.275  │\n",
      "│ 1       ┆ 2         ┆ 3    ┆ 1       ┆ 0.125  │\n",
      "└─────────┴───────────┴──────┴─────────┴────────┘\n",
      "recs in predict\n",
      " shape: (10, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 2       ┆ 2         ┆ 3       ┆ 0.625  │\n",
      "│ 2       ┆ 2         ┆ 2       ┆ 0.275  │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.125  │\n",
      "│ 4       ┆ 1         ┆ 3       ┆ 0.625  │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 3       ┆ 1         ┆ 3       ┆ 0.625  │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.625  │\n",
      "│ 1       ┆ 2         ┆ 2       ┆ 0.275  │\n",
      "│ 1       ┆ 2         ┆ 1       ┆ 0.125  │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "dataset.interaction\n",
      " shape: (6, 3)\n",
      "┌─────────┬─────────┬────────┐\n",
      "│ user_id ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ i64     ┆ f64    │\n",
      "╞═════════╪═════════╪════════╡\n",
      "│ 1       ┆ 1       ┆ 0.5    │\n",
      "│ 1       ┆ 2       ┆ 1.0    │\n",
      "│ 2       ┆ 2       ┆ 0.1    │\n",
      "│ 2       ┆ 3       ┆ 0.8    │\n",
      "│ 3       ┆ 3       ┆ 0.7    │\n",
      "│ 4       ┆ 3       ┆ 1.0    │\n",
      "└─────────┴─────────┴────────┘\n",
      "queries_interactions\n",
      " shape: (6, 3)\n",
      "┌───────┬──────┬────────┐\n",
      "│ query ┆ item ┆ rating │\n",
      "│ ---   ┆ ---  ┆ ---    │\n",
      "│ i64   ┆ i64  ┆ f64    │\n",
      "╞═══════╪══════╪════════╡\n",
      "│ 1     ┆ 1    ┆ 0.5    │\n",
      "│ 1     ┆ 2    ┆ 1.0    │\n",
      "│ 2     ┆ 2    ┆ 0.1    │\n",
      "│ 2     ┆ 3    ┆ 0.8    │\n",
      "│ 3     ┆ 3    ┆ 0.7    │\n",
      "│ 4     ┆ 3    ┆ 1.0    │\n",
      "└───────┴──────┴────────┘\n",
      "recs\n",
      " shape: (10, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 2       ┆ 2         ┆ 3       ┆ 0.625  │\n",
      "│ 2       ┆ 2         ┆ 2       ┆ 0.275  │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.125  │\n",
      "│ 4       ┆ 1         ┆ 3       ┆ 0.625  │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 3       ┆ 1         ┆ 3       ┆ 0.625  │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.625  │\n",
      "│ 1       ┆ 2         ┆ 2       ┆ 0.275  │\n",
      "│ 1       ┆ 2         ┆ 1       ┆ 0.125  │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "shape: (4, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.125  │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.625  │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "sorted_df\n",
      " shape: (4, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.625  │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.125  │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "└─────────┴───────────┴─────────┴────────┘\n",
      "top_k_df\n",
      " shape: (4, 4)\n",
      "┌─────────┬───────────┬─────────┬────────┐\n",
      "│ user_id ┆ num_items ┆ item_id ┆ rating │\n",
      "│ ---     ┆ ---       ┆ ---     ┆ ---    │\n",
      "│ i64     ┆ u32       ┆ i64     ┆ f64    │\n",
      "╞═════════╪═══════════╪═════════╪════════╡\n",
      "│ 1       ┆ 2         ┆ 3       ┆ 0.625  │\n",
      "│ 2       ┆ 2         ┆ 1       ┆ 0.125  │\n",
      "│ 3       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "│ 4       ┆ 1         ┆ 2       ┆ 0.275  │\n",
      "└─────────┴───────────┴─────────┴────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th></tr><tr><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>3</td><td>0.625</td></tr><tr><td>2</td><td>1</td><td>0.125</td></tr><tr><td>3</td><td>2</td><td>0.275</td></tr><tr><td>4</td><td>2</td><td>0.275</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌─────────┬─────────┬────────┐\n",
       "│ user_id ┆ item_id ┆ rating │\n",
       "│ ---     ┆ ---     ┆ ---    │\n",
       "│ i64     ┆ i64     ┆ f64    │\n",
       "╞═════════╪═════════╪════════╡\n",
       "│ 1       ┆ 3       ┆ 0.625  │\n",
       "│ 2       ┆ 1       ┆ 0.125  │\n",
       "│ 3       ┆ 2       ┆ 0.275  │\n",
       "│ 4       ┆ 2       ┆ 0.275  │\n",
       "└─────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = convert2polars(data_frame)\n",
    "dataset = Dataset(feature_schema, interactions)\n",
    "model = PopRec(use_rating=True)\n",
    "res = model.fit_predict(dataset, 1)\n",
    "res#.sort_values(\"user_id\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "isinstance([1], Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use_rating', 'fit', '_A', 'B']\n",
      "False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PopRecSpark' object has no attribute 'cached_dfs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m a \u001b[38;5;241m=\u001b[39m PopRec()\n\u001b[1;32m     55\u001b[0m a\u001b[38;5;241m.\u001b[39mf()\n\u001b[0;32m---> 56\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcached_dfs\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mBase.cached_dfs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_dfs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_implementation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcached_dfs\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PopRecSpark' object has no attribute 'cached_dfs'"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class Base(ABC):\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _implementation(self):\n",
    "        \"\"\" Impl\"\"\"\n",
    "    \n",
    "    @property\n",
    "    def cached_dfs(self):\n",
    "        \n",
    "        return self._implementation.cached_dfs\n",
    "\n",
    "    def fit(self):\n",
    "        return self._implementation.fit()\n",
    "\n",
    "class PopRec(Base):\n",
    "    def __init__(self):\n",
    "        self.a = 3\n",
    "        self.__implementation = None\n",
    "\n",
    "    @property\n",
    "    def _implementation(self):\n",
    "        return self.__implementation\n",
    "    \n",
    "    @_implementation.setter\n",
    "    def _implementation(self, value):\n",
    "        self.__implementation = value\n",
    "\n",
    "    def _all_attributes_or_functions(self): # TODO: куда лучше вынести?\n",
    "        cls = self._implementation.__class__\n",
    "        all_params = []\n",
    "        all_params.extend(dir(self._implementation))\n",
    "        all_params.extend(self._implementation.__dict__.keys())\n",
    "        all_params.extend(getattr(cls, \"__annotations__\", {}))\n",
    "        all_params.extend(dir(cls))\n",
    "        \n",
    "        return list(set(all_params))\n",
    "\n",
    "    def f(self):\n",
    "        self._implementation = PopRecSpark()\n",
    "        print(list(filter(lambda x: '__' not in x, self._all_attributes_or_functions())))\n",
    "        print('cached_dfs' in self._all_attributes_or_functions())\n",
    "        return self.fit()\n",
    "    \n",
    "class PopRecSpark:\n",
    "    _A: int = 3\n",
    "    B: str    \n",
    "    def __init__(self, use_rating=True):\n",
    "        self.use_rating = use_rating\n",
    "    def fit(self):\n",
    "        return 4\n",
    "    \n",
    "a = PopRec()\n",
    "a.f()\n",
    "a.cached_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoderTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from replay.preprocessing.label_encoder import LabelEncoder, LabelEncodingRule\n",
    "user_interactions = pd.DataFrame([\n",
    "    (\"u1\", \"item_1\", \"item_1\"),\n",
    "    (\"u2\", \"item_2\", \"item_2\"),\n",
    "    (\"u3\", \"item_3\", \"item_3\"),\n",
    "    ], columns=[\"user_id\", \"item_1\", \"item_2\"])\n",
    "\n",
    "add_user_interactions = pd.DataFrame([\n",
    "    (\"u5\", \"item_1\", \"item_1\"),\n",
    "    (\"u6\", \"item_2\", \"item_2\"),\n",
    "    (\"u7\", \"item_3\", \"item_3\"),\n",
    "    ], columns=[\"user_id\", \"item_1\", \"item_2\"])\n",
    "\n",
    "encoder = LabelEncoder([\n",
    "         LabelEncodingRule(\"user_id\"),\n",
    "         LabelEncodingRule(\"item_1\"),\n",
    "         LabelEncodingRule(\"item_2\"),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<replay.preprocessing.label_encoder.LabelEncoder at 0x7f269036a190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(user_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alaleksepetrov/projects/replay/replay/preprocessing/label_encoder.py:256: LabelEncoderTransformWarning: partial_fit will have no effect because, there are no new values in the incoming dataset at column item_1\n",
      "  warnings.warn(\n",
      "/home/alaleksepetrov/projects/replay/replay/preprocessing/label_encoder.py:256: LabelEncoderTransformWarning: partial_fit will have no effect because, there are no new values in the incoming dataset at column item_2\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<replay.preprocessing.label_encoder.LabelEncoder at 0x7f269036a190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.partial_fit(add_user_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replay_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
