{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecd3ed4",
   "metadata": {},
   "source": [
    "![Иллюстрация сплита](/img/gts_split.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ef887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Literal, Sequence, Optional, Tuple\n",
    "from rs_datasets import MovieLens\n",
    "\n",
    "from replay.splitters import (\n",
    "    TimeSplitter,\n",
    "    LastNSplitter,\n",
    "    NewUsersSplitter\n",
    ")\n",
    "from replay.preprocessing.filters import (\n",
    "    InteractionEntriesFilter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54f9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MovieLens(\"1m\")  \n",
    "ratings = ml.ratings      \n",
    "\n",
    "query_column = \"user_id\"\n",
    "item_column = \"item_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f77272",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_splitter = TimeSplitter(\n",
    "    time_threshold=0.1,\n",
    "    query_column=query_column,\n",
    "    item_column=item_column\n",
    ")\n",
    "\n",
    "interaction_filter = InteractionEntriesFilter(\n",
    "    min_inter_per_user=1,\n",
    "    query_column=query_column,\n",
    "    item_column=item_column\n",
    ")\n",
    "\n",
    "loo_splitter = LastNSplitter(\n",
    "    N=1,\n",
    "    divide_column=query_column,\n",
    "    query_column=query_column,\n",
    "    item_column=item_column\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b29a3",
   "metadata": {},
   "source": [
    "Создание тестового holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89859bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test_holdout = time_splitter.split(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b241de5",
   "metadata": {},
   "source": [
    "Создание валидационного holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "474a77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val_holdout = time_splitter.split(train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944d242",
   "metadata": {},
   "source": [
    "Очистка обучающей части от слишком коротких последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addccff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = interaction_filter.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63812c",
   "metadata": {},
   "source": [
    "__Примечание:__\n",
    "После разбиения обучающая выборка часто меняется: отделяется валидация, применяются различные фильтры (min count, удаление дубликатов, фильтры последовательностей и т.д.). Итоговая отфильтрованная обучающая выборка будет не равна, той, которая была на момент сплита, поэтому в `val_holdout/test_holdout` будут новые холодные айтемы/пользователи. Исходя из этого, более логично фильтрацию холодных айтемов/пользователей вынести в отдельную функцию, чем оставлять внутри класса сплиттера.\n",
    "\n",
    "Удаление \"холодных\" айтемов из holdout'ов на основании очищенного обучающего набора. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dda1f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cold(\n",
    "    target: pd.DataFrame,\n",
    "    reference: pd.DataFrame,\n",
    "    *,\n",
    "    mode: Literal[\"items\", \"users\", \"both\"] = \"items\",\n",
    "    query_column: str = \"user_id\",\n",
    "    item_column: str = \"item_id\",\n",
    "    copy: bool = True\n",
    "):\n",
    "    if mode not in {\"items\", \"users\", \"both\"}:\n",
    "        raise ValueError(\"mode must be 'items' | 'users' | 'both'\")\n",
    "\n",
    "    df = target.copy(deep=True) if copy else target\n",
    "\n",
    "    if mode in {\"items\", \"both\"}:\n",
    "        if item_column not in df.columns or item_column not in reference.columns:\n",
    "            raise KeyError(f\"Column '{item_column}' must be in both dataframes\")\n",
    "        allowed_items = reference[item_column].unique()\n",
    "        df = df[df[item_column].isin(allowed_items)]\n",
    "\n",
    "    if mode in {\"users\", \"both\"}:\n",
    "        if query_column not in df.columns or query_column not in reference.columns:\n",
    "            raise KeyError(f\"Column '{query_column}' must be in both dataframes\")\n",
    "        allowed_users = reference[query_column].unique()\n",
    "        df = df[df[query_column].isin(allowed_users)]\n",
    "\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e49e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_holdout = filter_cold(val_holdout, train, mode=\"items\")\n",
    "test_holdout = filter_cold(test_holdout, train, mode=\"items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645be79",
   "metadata": {},
   "source": [
    "__Опционально:__ удаление холодных айтемов из `train_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbbd9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = filter_cold(train_val, train, mode=\"items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13e909",
   "metadata": {},
   "source": [
    "Формирование валидационного таргета и входа, отделяя последний элемент в истории пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc758e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input, val_target = loo_splitter.split(val_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea5ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_subsets(\n",
    "    *dfs: pd.DataFrame,\n",
    "    columns: Optional[Sequence[str]] = None,\n",
    "    check_columns: bool = True,\n",
    "    subset_for_duplicates: Optional[Sequence[str]] = None,\n",
    "    on_duplicate: Literal[\"error\", \"drop\", \"ignore\"] = \"error\",\n",
    "):\n",
    "    if not dfs:\n",
    "        raise ValueError(\"At least one dataframe is required\")\n",
    "    \n",
    "    ref_cols = list(dfs[0].columns) if columns is None else list(columns)\n",
    "        \n",
    "    # Проверка на совпадение столбцов\n",
    "    aligned = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        if check_columns:\n",
    "            if set(df.columns) != set(ref_cols):\n",
    "                raise ValueError(\n",
    "                    f\"Columns mismatch in dataframe #{i}: \"\n",
    "                    f\"{sorted(df.columns)} != {sorted(ref_cols)}\"\n",
    "                )\n",
    "        aligned.append(df[ref_cols])\n",
    "\n",
    "    merged = pd.concat(aligned, axis=0, ignore_index=True)\n",
    "            \n",
    "    # Удаление дубликатов\n",
    "    dup_subset = ref_cols if subset_for_duplicates is None else list(subset_for_duplicates)\n",
    "    dup_mask = merged.duplicated(subset=dup_subset, keep=\"first\")\n",
    "    dup_count = int(dup_mask.sum())\n",
    "    \n",
    "    if dup_count > 0:\n",
    "        if on_duplicate == \"error\":\n",
    "            sample = merged.loc[dup_mask, dup_subset].head(5)\n",
    "            raise ValueError(\n",
    "                f\"Found {dup_count} duplicate rows on subset {dup_subset}. \"\n",
    "                f\"Sample:\\n{sample}\"\n",
    "            )\n",
    "        if on_duplicate == \"drop\":\n",
    "            merged = merged.drop_duplicates(subset=dup_subset, keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e90038",
   "metadata": {},
   "source": [
    "Сборка входа для валидации (добавление истории из обучающего набора)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a33f4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input = merge_subsets(train, val_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa8ec7",
   "metadata": {},
   "source": [
    "Удаление \"холодных\" пользователей: оставляем в `val_target` только тех пользователей, которые присутствуют в `val_input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ada34ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_target = filter_cold(val_target, val_input, mode=\"users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b3fb3",
   "metadata": {},
   "source": [
    "Ограничение размера валидации (5000 пользователей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed32ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_target[query_column].nunique() > 5000:\n",
    "    new_users_splitter = NewUsersSplitter(\n",
    "        test_size=5000/val_target[query_column].nunique(),\n",
    "        query_column=query_column,\n",
    "        item_column=item_column,\n",
    "    )\n",
    "    _, val_target = new_users_splitter.split(val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d056d0",
   "metadata": {},
   "source": [
    "По аналогии с валидацией делаем обработку для теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68e87687",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_target = loo_splitter.split(test_holdout)\n",
    "\n",
    "test_input = merge_subsets(train, test_input)\n",
    "\n",
    "test_target = filter_cold(test_target, test_input, mode=\"users\")\n",
    "\n",
    "if test_target[query_column].nunique() > 10000:\n",
    "    new_users_splitter = NewUsersSplitter(\n",
    "        test_size=10000/test_target[query_column].nunique(),\n",
    "        query_column=query_column,\n",
    "        item_column=item_column,\n",
    "    )\n",
    "    _, test_target = new_users_splitter.split(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76124227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
