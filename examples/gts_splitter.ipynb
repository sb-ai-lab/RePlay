{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecd3ed4",
   "metadata": {},
   "source": [
    "![Иллюстрация сплита](/img/gts_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268735a7",
   "metadata": {},
   "source": [
    "### Описание сплита\n",
    "\n",
    "__Цель сплита:__ смоделировать онлайн-сценарий рекомендаций без утечек по времени. Обучаемся на прошлом, валидируемся на более новом временном окне, финально тестируемся на самом свежем разрезе. Задача в валидации и тесте - предсказать следующий элемент (LOO). Для этого у каждого пользователя берём его последнюю интеракцию в соответствующем окне как цель, а входом служит история до неё.\n",
    "\n",
    "__Получающиеся выборки:__\n",
    "- `train` - всё до `T_val` (очищено базовыми фильтрами).\n",
    "- `val_input + val_target` - окно `[T_val, T_test)`: последняя интеракция пользователя - таргет; вход - вся история до неё + история из `train`.\n",
    "- `test_input + test_target` - окно `[T_test, +inf)`: тестовый набор, аналогично валидации.\n",
    "- _(опц.)_ `train_val` - промежуточный слой после первого временного сплита.\n",
    "\n",
    "### Пайплайн\n",
    "1) __Первый временной сплит - выделяем тест__.\\\n",
    "Разбиваем исходный набор данных `ratings`, используя `TimeSplitter`, на два множества - `train_val` и `test_holdout`.\n",
    "- __Зачем:__ выделить тестовую выборку.\n",
    "- __Результат:__ `train_val` - данные для обучения и валидации, `test_holdout` - данные для теста.\n",
    "2) __Второй временной сплит - выделяем валидацию__.\\\n",
    "Разбиваем получившийся с предыдущего шага набор данных `train_val`, используя `TimeSplitter`, на обучающую и валидационную выборки - `train` и `val_holdout` соответственно.\n",
    "- __Зачем:__ выделить валидационную выборку.\n",
    "- __Результат:__ `train` - данные для обучения, `val_holdout` - данные для валидации.\n",
    "3) __Очистка обучающей части__\\\n",
    "_Примечение:_ ниже будет описан пример того, как может выглядеть очистка обучающей части, на практике могут быть другие варианты.\\\n",
    "Фильтруем из `train` последовательности длины 1.\n",
    "- __Зачем:__ обучение на последовательностях длины 1 не имеет смысла, так как невозможно корректно определить историю пользователя и следующий айтем (таргет).\n",
    "- __Результат:__ обучающая выборка содержит корректные последовательности, которые могут быть использованы для обучения модели.\n",
    "4) __Удаление \"холодных\" айтемов из holdout'ов__\\\n",
    "Из `val_holdout` и `test_holdout` удаляются холодные айтемы с помощью функции `filter_cold`.\n",
    "- __Зачем:__ для моделей, которые не умеют работать с \"холодными\" айтемами (например `SASRec`), оценка на таких айтемах не имеет смысла, поэтому из валидационной и тестовой выборок их необходимо убрать. Приэтом, если модель способно предсказывать \"холодные\" айтемы, то данный шаг можно не выполнять.\n",
    "- __Результат:__ `val_holdout` и `test_holdout` содержат только те айтемы, которые содержатся в `train`. и которые модель действительно способна предсказать.\n",
    "5) __Формируем LOO в валидации__\n",
    "Делаем LOO сплит для валидационного набора `val_holdout`.\n",
    "- __Зачем:__ последний айтем из валидации делаем таргетом, а всё до него - входом, для которого модель должна предсказать следующий элемент в истории.\n",
    "- __Результат:__ `val_target` - последний айтем в валидационной выборке, `val_input` - история до последнего элемента из того же набора данных.\n",
    "6) __Добавляем обучающую историю в вход валидации__\\\n",
    "После предыдущего шага `val_input` содержит только историю пользователя из валидационного набора `val_holdout`, приэтом данные из обучающей выборки `train` сюда не включены. Поэтому, чтобы сделать историю пользователя более полной, а не ограничиваться только лишь тем, что папало в валидацию, необходимо добавить данные из обучающего набора `train`.\n",
    "- __Зачем:__ модель \"видит\" всю историю пользователя на момент предсказания.\n",
    "- __Результат:__ `val_input` становится объединением `val_input` с предыдущего шага и `train`.\n",
    "7) __Удаляем \"холодных пользователей\" из таргета валидации__\\\n",
    "После применения различных фильтров над обучающей выборкой, из неё часть пользователей, могла пропасть. Например, в нашем случае это пользователи с историей, которая содержит меньше двух айтемов. Делать оценку модели на таких пользователях бессмысленно, поскольку для них нет нупустой истории.\n",
    "- __Зачем:__ корректная оценка модели для пользователей с непустой историей.\n",
    "- __Результат:__ в `val_target` содержатся только те пользователи, которые есть в `val_input`.\n",
    "8) __Ограничение размера валидации__\\\n",
    "Ограничиваем число пользователей в валидации до 5000 (порого можно подбирать индивидуально), чтобы снизить время, требуемое для оценки на валидационном периоде.\n",
    "- __Зачем:__ ускорить оценку модели.\n",
    "- __Результат:__ количество юзеров в `val_target` не превышает 5000.\n",
    "9) __Аналогичные шаги для теста__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ef887b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "from typing import Literal, Sequence, Optional, Tuple\n",
    "from rs_datasets import MovieLens\n",
    "\n",
    "from replay.splitters import (\n",
    "    TimeSplitter,\n",
    "    LastNSplitter,\n",
    "    NewUsersSplitter\n",
    ")\n",
    "from replay.preprocessing.filters import (\n",
    "    InteractionEntriesFilter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf0508",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "Ниже реализованы две вспомогательные функции - `filter_cold` для фильтрации холодных пользователей и айтемов, а также `merge_subsets` - для объединения наборов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e1df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_table(\n",
    "    metrics: pd.DataFrame,\n",
    "    name: str,\n",
    "    query_column: str = \"user_id\",\n",
    "    item_column: str = \"item_id\",\n",
    "    timestamp_column: str = \"timestamp\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для вывода статистики по датасету.\n",
    "    \"\"\"\n",
    "    cnt_users = metrics[query_column].nunique()\n",
    "    cnt_items = metrics[item_column].nunique()\n",
    "    cnt_interactions = len(metrics)\n",
    "    max_timestamp = metrics[timestamp_column].max()\n",
    "    min_timestamp = metrics[timestamp_column].min()\n",
    "    \n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(f\"Users: {cnt_users}, Items: {cnt_items}, Interactions: {cnt_interactions}, Max timestamp: {max_timestamp}, Min timestamp: {min_timestamp}\\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db4868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cold(\n",
    "    target: pd.DataFrame,\n",
    "    reference: pd.DataFrame,\n",
    "    *,\n",
    "    mode: Literal[\"items\", \"users\", \"both\"] = \"items\",\n",
    "    query_column: str = \"user_id\",\n",
    "    item_column: str = \"item_id\",\n",
    "    copy: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Фильтрует целевой датасет по каталогу (айтемам) и/или пользователям,\n",
    "    разрешённым в эталонном датасете.\n",
    "\n",
    "    Параметры\n",
    "    ---------\n",
    "    target : pd.DataFrame\n",
    "        Датасет, который требуется отфильтровать.\n",
    "    reference : pd.DataFrame\n",
    "        Датасет-эталон: из него берутся допустимые `item_id` и/или `user_id`.\n",
    "    mode : {\"items\", \"users\", \"both\"}, default \"items\"\n",
    "        Что фильтровать: только айтемы, только пользователей или оба множества.\n",
    "    query_column : str, default \"user_id\"\n",
    "        Имя столбца с пользователями.\n",
    "    item_column : str, default \"item_id\"\n",
    "        Имя столбца с айтемами.\n",
    "    copy : bool, default True\n",
    "        Если True — возвращает копию; если False — фильтрует на месте.\n",
    "\n",
    "    Возвращает\n",
    "    ----------\n",
    "    pd.DataFrame\n",
    "        Отфильтрованный датасет `target`.\n",
    "    \"\"\"\n",
    "    if mode not in {\"items\", \"users\", \"both\"}:\n",
    "        raise ValueError(\"mode must be 'items' | 'users' | 'both'\")\n",
    "\n",
    "    df = target.copy(deep=True) if copy else target\n",
    "\n",
    "    if mode in {\"items\", \"both\"}:\n",
    "        if item_column not in df.columns or item_column not in reference.columns:\n",
    "            raise KeyError(f\"Column '{item_column}' must be in both dataframes\")\n",
    "        allowed_items = reference[item_column].unique()\n",
    "        df = df[df[item_column].isin(allowed_items)]\n",
    "\n",
    "    if mode in {\"users\", \"both\"}:\n",
    "        if query_column not in df.columns or query_column not in reference.columns:\n",
    "            raise KeyError(f\"Column '{query_column}' must be in both dataframes\")\n",
    "        allowed_users = reference[query_column].unique()\n",
    "        df = df[df[query_column].isin(allowed_users)]\n",
    "\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce91d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_subsets(\n",
    "    *dfs: pd.DataFrame,\n",
    "    columns: Optional[Sequence[str]] = None,\n",
    "    check_columns: bool = True,\n",
    "    subset_for_duplicates: Optional[Sequence[str]] = None,\n",
    "    on_duplicate: Literal[\"error\", \"drop\", \"ignore\"] = \"error\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Объединяет несколько датафреймов построчно с согласованием столбцов\n",
    "    и контролем дубликатов.\n",
    "\n",
    "    Параметры\n",
    "    ---------\n",
    "    dfs : pd.DataFrame\n",
    "        Перечень датафреймов для объединения.\n",
    "    columns : Sequence[str] | None, default None\n",
    "        Явный порядок/набор столбцов. Если None — берётся порядок из первого df.\n",
    "    check_columns : bool, default True\n",
    "        Проверять совпадение множеств столбцов у всех датафреймов.\n",
    "    subset_for_duplicates : Sequence[str] | None, default None\n",
    "        Подмножество столбцов для поиска дубликатов; по умолчанию — все.\n",
    "    on_duplicate : {\"error\", \"drop\", \"ignore\"}, default \"error\"\n",
    "        Политика обработки дубликатов.\n",
    "\n",
    "    Возвращает\n",
    "    ----------\n",
    "    pd.DataFrame\n",
    "        Объединённый датафрейм без дубликатов (если выбрано `drop`).\n",
    "    \"\"\"\n",
    "    if not dfs:\n",
    "        raise ValueError(\"At least one dataframe is required\")\n",
    "    \n",
    "    ref_cols = list(dfs[0].columns) if columns is None else list(columns)\n",
    "        \n",
    "    # Проверка на совпадение столбцов\n",
    "    aligned = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        if check_columns:\n",
    "            if set(df.columns) != set(ref_cols):\n",
    "                raise ValueError(\n",
    "                    f\"Columns mismatch in dataframe #{i}: \"\n",
    "                    f\"{sorted(df.columns)} != {sorted(ref_cols)}\"\n",
    "                )\n",
    "        aligned.append(df[ref_cols])\n",
    "\n",
    "    merged = pd.concat(aligned, axis=0, ignore_index=True)\n",
    "            \n",
    "    # Удаление дубликатов\n",
    "    dup_subset = ref_cols if subset_for_duplicates is None else list(subset_for_duplicates)\n",
    "    dup_mask = merged.duplicated(subset=dup_subset, keep=\"first\")\n",
    "    dup_count = int(dup_mask.sum())\n",
    "    \n",
    "    if dup_count > 0:\n",
    "        if on_duplicate == \"error\":\n",
    "            sample = merged.loc[dup_mask, dup_subset].head(5)\n",
    "            raise ValueError(\n",
    "                f\"Found {dup_count} duplicate rows on subset {dup_subset}. \"\n",
    "                f\"Sample:\\n{sample}\"\n",
    "            )\n",
    "        if on_duplicate == \"drop\":\n",
    "            merged = merged.drop_duplicates(subset=dup_subset, keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1096d",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54f9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ratings\n",
      "Users: 6040, Items: 3706, Interactions: 1000209, Max timestamp: 1046454590, Min timestamp: 956703932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml = MovieLens(\"1m\")  \n",
    "ratings = ml.ratings      \n",
    "\n",
    "query_column = \"user_id\"\n",
    "item_column = \"item_id\"\n",
    "\n",
    "print_metrics_table(ratings, \"ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f77272",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_splitter = TimeSplitter(\n",
    "    time_threshold=0.1,\n",
    "    query_column=query_column,\n",
    "    item_column=item_column\n",
    ")\n",
    "\n",
    "interaction_filter = InteractionEntriesFilter(\n",
    "    min_inter_per_user=2,\n",
    "    query_column=query_column,\n",
    "    item_column=item_column\n",
    ")\n",
    "\n",
    "loo_splitter = LastNSplitter(\n",
    "    N=1,\n",
    "    divide_column=query_column,\n",
    "    query_column=query_column,\n",
    "    item_column=item_column\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b29a3",
   "metadata": {},
   "source": [
    "Создание тестового holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89859bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train_val\n",
      "Users: 6011, Items: 3678, Interactions: 900188, Max timestamp: 978133367, Min timestamp: 956703932\n",
      "\n",
      "Dataset: test_holdout\n",
      "Users: 1209, Items: 3407, Interactions: 100021, Max timestamp: 1046454590, Min timestamp: 978133414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_val, test_holdout = time_splitter.split(ratings)\n",
    "print_metrics_table(train_val, \"train_val\")\n",
    "print_metrics_table(test_holdout, \"test_holdout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b241de5",
   "metadata": {},
   "source": [
    "Создание валидационного holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "474a77a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train\n",
      "Users: 5454, Items: 3662, Interactions: 810169, Max timestamp: 975965591, Min timestamp: 956703932\n",
      "\n",
      "Dataset: val_holdout\n",
      "Users: 1045, Items: 3278, Interactions: 90019, Max timestamp: 978133367, Min timestamp: 975965621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, val_holdout = time_splitter.split(train_val)\n",
    "print_metrics_table(train, \"train\")\n",
    "print_metrics_table(val_holdout, \"val_holdout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944d242",
   "metadata": {},
   "source": [
    "Очистка обучающей части от слишком коротких последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "addccff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train\n",
      "Users: 5454, Items: 3662, Interactions: 810169, Max timestamp: 975965591, Min timestamp: 956703932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = interaction_filter.transform(train)\n",
    "print_metrics_table(train, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0697adc",
   "metadata": {},
   "source": [
    "Число данных в обучающей выборке не изменилось, поскольку набор не содержит пользователей, для которых есть только одно взаимодействие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63812c",
   "metadata": {},
   "source": [
    "__Примечание:__\n",
    "После разбиения обучающая выборка часто меняется: отделяется валидация, применяются различные фильтры (min count, удаление дубликатов, фильтры последовательностей и т.д.). Итоговая отфильтрованная обучающая выборка будет не равна, той, которая была на момент сплита, поэтому в `test_holdout` будут новые холодные айтемы/пользователи. Исходя из этого, более логично фильтрацию холодных айтемов/пользователей вынести в отдельную функцию, чем оставлять внутри класса сплиттера.\n",
    "\n",
    "Удаление \"холодных\" айтемов из holdout'ов на основании очищенного обучающего набора. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e49e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: val_holdout\n",
      "Users: 1045, Items: 3262, Interactions: 90002, Max timestamp: 978133367, Min timestamp: 975965621\n",
      "\n",
      "Dataset: test_holdout\n",
      "Users: 1208, Items: 3374, Interactions: 99923, Max timestamp: 1046454590, Min timestamp: 978133414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_holdout = filter_cold(val_holdout, train, mode=\"items\")\n",
    "test_holdout = filter_cold(test_holdout, train, mode=\"items\")\n",
    "\n",
    "print_metrics_table(val_holdout, \"val_holdout\")\n",
    "print_metrics_table(test_holdout, \"test_holdout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645be79",
   "metadata": {},
   "source": [
    "__Опционально:__ удаление холодных айтемов из `train_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbbd9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train_val\n",
      "Users: 6011, Items: 3662, Interactions: 900171, Max timestamp: 978133367, Min timestamp: 956703932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_val = filter_cold(train_val, train, mode=\"items\")\n",
    "print_metrics_table(train_val, \"train_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13e909",
   "metadata": {},
   "source": [
    "Формирование валидационного таргета и входа, отделяя последний элемент в истории пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc758e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: val_input\n",
      "Users: 987, Items: 3257, Interactions: 88957, Max timestamp: 978133348, Min timestamp: 975965621\n",
      "\n",
      "Dataset: val_target\n",
      "Users: 1045, Items: 692, Interactions: 1045, Max timestamp: 978133367, Min timestamp: 975966585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_input, val_target = loo_splitter.split(val_holdout)\n",
    "print_metrics_table(val_input, \"val_input\")\n",
    "print_metrics_table(val_target, \"val_target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e90038",
   "metadata": {},
   "source": [
    "Сборка входа для валидации (добавление истории из обучающего набора)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a33f4eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: val_input\n",
      "Users: 6011, Items: 3662, Interactions: 899126, Max timestamp: 978133348, Min timestamp: 956703932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_input = merge_subsets(train, val_input)\n",
    "print_metrics_table(val_input, \"val_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa8ec7",
   "metadata": {},
   "source": [
    "Удаление \"холодных\" пользователей: оставляем в `val_target` только тех пользователей, которые присутствуют в `val_input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada34ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: val_target\n",
      "Users: 1045, Items: 692, Interactions: 1045, Max timestamp: 978133367, Min timestamp: 975966585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_target = filter_cold(val_target, val_input, mode=\"users\")\n",
    "print_metrics_table(val_target, \"val_target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b3fb3",
   "metadata": {},
   "source": [
    "Ограничение размера валидации (5000 пользователей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed32ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: val_target\n",
      "Users: 1045, Items: 692, Interactions: 1045, Max timestamp: 978133367, Min timestamp: 975966585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if val_target[query_column].nunique() > 5000:\n",
    "    new_users_splitter = NewUsersSplitter(\n",
    "        test_size=5000/val_target[query_column].nunique(),\n",
    "        query_column=query_column,\n",
    "        item_column=item_column,\n",
    "    )\n",
    "    _, val_target = new_users_splitter.split(val_target)\n",
    "    \n",
    "print_metrics_table(val_target, \"val_target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d056d0",
   "metadata": {},
   "source": [
    "По аналогии с валидацией делаем обработку для теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68e87687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: test_target\n",
      "Users: 1203, Items: 788, Interactions: 1203, Max timestamp: 1046454590, Min timestamp: 978136554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input, test_target = loo_splitter.split(test_holdout)\n",
    "\n",
    "test_input = merge_subsets(train, test_input)\n",
    "\n",
    "test_target = filter_cold(test_target, test_input, mode=\"users\")\n",
    "\n",
    "if test_target[query_column].nunique() > 10000:\n",
    "    new_users_splitter = NewUsersSplitter(\n",
    "        test_size=10000/test_target[query_column].nunique(),\n",
    "        query_column=query_column,\n",
    "        item_column=item_column,\n",
    "    )\n",
    "    _, test_target = new_users_splitter.split(test_target)\n",
    "    \n",
    "print_metrics_table(test_target, \"test_target\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
