{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import lightning as L\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from replay.metrics.torch_metrics_builder import metrics_to_df\n",
    "from replay.data import (\n",
    "    FeatureHint,\n",
    "    FeatureSource,\n",
    "    FeatureType,\n",
    ")\n",
    "from replay.data.nn import (\n",
    "    TensorFeatureInfo,\n",
    "    TensorFeatureSource,\n",
    "    TensorSchema,\n",
    ")\n",
    "from replay.preprocessing.label_encoder import LabelEncoder, LabelEncodingRule, SequenceEncodingRule\n",
    "from replay.metrics import MAP, OfflineMetrics, Precision, Recall\n",
    "from replay.splitters import LastNSplitter, RatioSplitter\n",
    "\n",
    "# Fix seed to ensure reproducibility\n",
    "L.seed_everything(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = pd.read_csv(\"./data/ml1m_users.dat\", sep=\"\\t\", names=[\"user_id\", \"gender\", \"age\", \"occupation\", \"zip_code\"])\n",
    "item_features = pd.read_csv(\"./data/ml1m_items.dat\", sep=\"\\t\", names=[\"item_id\", \"title\", \"genres\"])\n",
    "interactions = pd.read_csv(\"./data/ml1m_ratings.dat\", sep=\"\\t\", names=[\"user_id\", \"item_id\",\"rating\",\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000138</th>\n",
       "      <td>6040</td>\n",
       "      <td>858</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000153</th>\n",
       "      <td>6040</td>\n",
       "      <td>2384</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999873</th>\n",
       "      <td>6040</td>\n",
       "      <td>593</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000192</th>\n",
       "      <td>6040</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000007</th>\n",
       "      <td>6040</td>\n",
       "      <td>1961</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825793</th>\n",
       "      <td>4958</td>\n",
       "      <td>2399</td>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825438</th>\n",
       "      <td>4958</td>\n",
       "      <td>1407</td>\n",
       "      <td>5</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825731</th>\n",
       "      <td>4958</td>\n",
       "      <td>2634</td>\n",
       "      <td>3</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825724</th>\n",
       "      <td>4958</td>\n",
       "      <td>3264</td>\n",
       "      <td>4</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825603</th>\n",
       "      <td>4958</td>\n",
       "      <td>1924</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating  timestamp\n",
       "1000138     6040      858       4          0\n",
       "1000153     6040     2384       4          1\n",
       "999873      6040      593       5          2\n",
       "1000192     6040     2019       5          3\n",
       "1000007     6040     1961       4          4\n",
       "...          ...      ...     ...        ...\n",
       "825793      4958     2399       1        446\n",
       "825438      4958     1407       5        447\n",
       "825731      4958     2634       3        448\n",
       "825724      4958     3264       4        449\n",
       "825603      4958     1924       4        450\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[\"timestamp\"] = interactions[\"timestamp\"].astype(\"int64\")\n",
    "interactions = interactions.sort_values(by=\"timestamp\")\n",
    "interactions[\"timestamp\"] = interactions.groupby(\"user_id\").cumcount()\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RatioSplitter(\n",
    "    test_size=0.1,\n",
    "    divide_column=\"user_id\",\n",
    "    query_column=\"user_id\",\n",
    "    drop_cold_users=True, \n",
    "    drop_cold_items=True,\n",
    ")\n",
    "\n",
    "raw_test_events, raw_test_gt = splitter.split(interactions)\n",
    "raw_val_events, raw_val_gt = splitter.split(raw_test_events)\n",
    "raw_train_events = raw_val_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_data_by_train_items(data, train_events):\n",
    "    data = data[data[\"item_id\"].isin(train_events[\"item_id\"])]\n",
    "    return data\n",
    "\n",
    "raw_test_events = align_data_by_train_items(raw_test_events, raw_train_events)\n",
    "raw_test_gt = align_data_by_train_items(raw_test_gt, raw_train_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LabelEncoder([\n",
    "    LabelEncodingRule(\"user_id\", default_value=\"last\"),\n",
    "    LabelEncodingRule(\"item_id\", default_value=\"last\")\n",
    "])\n",
    "\n",
    "raw_train_events = raw_train_events.sort_values(by=\"item_id\", ascending=True)\n",
    "train_events = tokenizer.fit_transform(raw_train_events)\n",
    "val_events = tokenizer.transform(raw_val_events)\n",
    "val_gt = tokenizer.transform(raw_val_gt)\n",
    "test_events = tokenizer.transform(raw_test_events)\n",
    "test_gt = tokenizer.transform(raw_test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.data.nn.utils import groupby_sequences\n",
    "\n",
    "\n",
    "def bake_data(df: pd.DataFrame):\n",
    "    grouped_interactions = groupby_sequences(\n",
    "        events=df,\n",
    "        groupby_col=\"user_id\",\n",
    "        sort_col=\"timestamp\"\n",
    "    )\n",
    "\n",
    "    return grouped_interactions\n",
    "\n",
    "train_events = bake_data(train_events)\n",
    "val_events = bake_data(val_events)\n",
    "val_gt = bake_data(val_gt)\n",
    "test_events = bake_data(test_events)\n",
    "test_gt = bake_data(test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[4, 5, 3, 5, 5, 5, 1, 1, 5, 4, 2, 4, 2, 3, 3, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1763, 1126, 1938, 1095, 1092, 2119, 163, 3218...</td>\n",
       "      <td>[1597, 2932, 848, 1155, 2150, 2638, 3098, 3101...</td>\n",
       "      <td>[1763, 1126, 1938, 1095, 1092, 2119, 163, 3218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[464, 930, 3012, 2692, 1994, 1238, 722, 2970, ...</td>\n",
       "      <td>[591, 31, 2350, 2866, 432, 3235, 2386, 181, 32...</td>\n",
       "      <td>[464, 930, 3012, 2692, 1994, 1238, 722, 2970, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[4, 4, 4, 3, 5, 4, 5, 4, 5, 4, 4, 5, 4, 4, 4, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1102, 528, 3438, 1229, 1763, 1909, 589, 1127,...</td>\n",
       "      <td>[521, 2215, 251, 2673, 202, 793, 3463, 1964, 2...</td>\n",
       "      <td>[1102, 528, 3438, 1229, 1763, 1909, 589, 1127,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 3, 5, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[3156, 1192, 769, 1763, 1471, 1095, 2917, 3473...</td>\n",
       "      <td>[210, 1189, 2146, 920, 143, 2074, 1012, 3060, ...</td>\n",
       "      <td>[3156, 1192, 769, 1763, 1471, 1095, 2917, 3473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[5, 4, 3, 3, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[837, 1131, 621, 1592, 1080, 3100, 2180, 3096,...</td>\n",
       "      <td>[3250, 1184, 1165, 1688]</td>\n",
       "      <td>[837, 1131, 621, 1592, 1080, 3100, 2180, 3096,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             rating  \\\n",
       "0        0  [4, 5, 3, 5, 5, 5, 1, 1, 5, 4, 2, 4, 2, 3, 3, ...   \n",
       "1        1  [3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, ...   \n",
       "2        2  [4, 4, 4, 3, 5, 4, 5, 4, 5, 4, 4, 5, 4, 4, 4, ...   \n",
       "3        3  [5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 3, 5, ...   \n",
       "4        4  [5, 4, 3, 3, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "\n",
       "                                           timestamp  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                             item_id  \\\n",
       "0  [1763, 1126, 1938, 1095, 1092, 2119, 163, 3218...   \n",
       "1  [464, 930, 3012, 2692, 1994, 1238, 722, 2970, ...   \n",
       "2  [1102, 528, 3438, 1229, 1763, 1909, 589, 1127,...   \n",
       "3  [3156, 1192, 769, 1763, 1471, 1095, 2917, 3473...   \n",
       "4  [837, 1131, 621, 1592, 1080, 3100, 2180, 3096,...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  [1597, 2932, 848, 1155, 2150, 2638, 3098, 3101...   \n",
       "1  [591, 31, 2350, 2866, 432, 3235, 2386, 181, 32...   \n",
       "2  [521, 2215, 251, 2673, 202, 793, 3463, 1964, 2...   \n",
       "3  [210, 1189, 2146, 920, 143, 2074, 1012, 3060, ...   \n",
       "4                           [3250, 1184, 1165, 1688]   \n",
       "\n",
       "                                               train  \n",
       "0  [1763, 1126, 1938, 1095, 1092, 2119, 163, 3218...  \n",
       "1  [464, 930, 3012, 2692, 1994, 1238, 722, 2970, ...  \n",
       "2  [1102, 528, 3438, 1229, 1763, 1909, 589, 1127,...  \n",
       "3  [3156, 1192, 769, 1763, 1471, 1095, 2917, 3473...  \n",
       "4  [837, 1131, 621, 1592, 1080, 3100, 2180, 3096,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_gt_to_join = val_gt.loc[:, [\"user_id\", \"item_id\"]].rename(columns={\"item_id\": \"ground_truth\"})\n",
    "train_events_to_join = train_events.loc[:, [\"user_id\", \"item_id\"]].rename(columns={\"item_id\": \"train\"})\n",
    "\n",
    "val_events = (val_events\n",
    "              .merge(val_gt_to_join, how=\"inner\", on=\"user_id\")\n",
    "              .merge(train_events_to_join, how=\"inner\", on=\"user_id\")\n",
    ")\n",
    "val_events.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./preprocessed/\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "TRAIN_PATH = os.path.join(data_dir, \"train.parquet\")\n",
    "VAL_PATH = os.path.join(data_dir, \"val.parquet\")\n",
    "TEST_PATH =  os.path.join(data_dir, \"test.parquet\")\n",
    "\n",
    "train_events.to_parquet(TRAIN_PATH)\n",
    "val_events.to_parquet(VAL_PATH)\n",
    "test_events.to_parquet(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "FEATURE_MAPPING_PATH = os.path.join(data_dir, \"feature_mapping.pickle\")\n",
    "\n",
    "# feature_mapping = {\n",
    "#     **tokenizer.item_id_encoder.mapping,\n",
    "#     **(tokenizer.item_features_encoder.mapping if tokenizer.item_features_encoder is not None else {}),\n",
    "#     **(tokenizer.interactions_encoder.mapping if tokenizer.interactions_encoder is not None else {}),\n",
    "# }\n",
    "feature_mapping = {\n",
    "    \"item_id\" : tokenizer.rules[1]._mapping\n",
    "}\n",
    "with open(FEATURE_MAPPING_PATH, \"wb\") as f:  #\n",
    "    pickle.dump(feature_mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "      <td>3668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title                        genres  \\\n",
       "0                       Toy Story (1995)   Animation|Children's|Comedy   \n",
       "1                         Jumanji (1995)  Adventure|Children's|Fantasy   \n",
       "2                Grumpier Old Men (1995)                Comedy|Romance   \n",
       "3               Waiting to Exhale (1995)                  Comedy|Drama   \n",
       "4     Father of the Bride Part II (1995)                        Comedy   \n",
       "...                                  ...                           ...   \n",
       "3878             Meet the Parents (2000)                        Comedy   \n",
       "3879          Requiem for a Dream (2000)                         Drama   \n",
       "3880                    Tigerland (2000)                         Drama   \n",
       "3881             Two Family House (2000)                         Drama   \n",
       "3882               Contender, The (2000)                Drama|Thriller   \n",
       "\n",
       "      item_id  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  \n",
       "...       ...  \n",
       "3878     3664  \n",
       "3879     3665  \n",
       "3880     3666  \n",
       "3881     3667  \n",
       "3882     3668  \n",
       "\n",
       "[3669 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features = item_features[item_features[\"item_id\"].isin(raw_train_events[\"item_id\"])]\n",
    "\n",
    "item_features_encoded = tokenizer.rules[1].transform(item_features)\n",
    "item_features_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ENCODED_FEATURES = os.path.join(data_dir, \"item_features_encoded.parquet\")\n",
    "item_features_encoded.loc[:, [\"item_id\"]].to_parquet(PATH_ENCODED_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 192\n",
    "ITEM_FEATURE_NAME = \"item_id\"\n",
    "\n",
    "NUM_UNIQUE_ITEMS = len(tokenizer.mapping[\"item_id\"])\n",
    "\n",
    "tensor_schema = TensorSchema(\n",
    "    [\n",
    "        TensorFeatureInfo(\n",
    "            \"item_id\",\n",
    "            is_seq=True,\n",
    "            feature_type=FeatureType.CATEGORICAL,\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            padding_value=NUM_UNIQUE_ITEMS,\n",
    "            cardinality=NUM_UNIQUE_ITEMS+1,  # taking into account padding\n",
    "            feature_hint=FeatureHint.ITEM_ID,\n",
    "            feature_sources=[TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"item_id\")]\n",
    "        ),\n",
    "        # TensorFeatureInfo(\n",
    "        #     \"genres\",\n",
    "        #     is_seq=True,\n",
    "        #     feature_type=FeatureType.CATEGORICAL_LIST,\n",
    "        #     embedding_dim=EMBEDDING_DIM,\n",
    "        #     padding_value=NUM_UNIQUE_GENRE_VALUES,\n",
    "        #     cardinality=NUM_UNIQUE_GENRE_VALUES+1,\n",
    "        #     feature_sources=[TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"genres\")]\n",
    "        # ),\n",
    "        # TensorFeatureInfo(\n",
    "        #     \"title\",\n",
    "        #     is_seq=True,\n",
    "        #     feature_type=FeatureType.NUMERICAL_LIST,\n",
    "        #     tensor_dim=TITLE_EMB_DIM,\n",
    "        #     embedding_dim=EMBEDDING_DIM,\n",
    "        #     padding_value=0,\n",
    "        #     feature_sources=[TensorFeatureSource(FeatureSource.ITEM_FEATURES, \"title\")]\n",
    "        # )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.nn.transforms import (\n",
    "    GroupTransform,\n",
    "    RenameTransform,\n",
    "    NextTokenTransform,\n",
    "    UnsqueezeTransform,\n",
    "    UniformNegativeSamplingTransform\n",
    ")\n",
    "\n",
    "MAX_SEQ_LEN = 50\n",
    "BATCH_SIZE = 64\n",
    "SHIFT=1\n",
    "\n",
    "TRANSFORMS = {\n",
    "    \"train\": [\n",
    "        NextTokenTransform(label_field=\"item_id\", query_features=\"user_id\", shift=SHIFT, out_feature_name=\"positive_labels\"),\n",
    "        RenameTransform({\"user_id\": \"query_id\", \"item_id_mask\": \"padding_mask\",  \"positive_labels_mask\": \"target_padding_mask\"}),\n",
    "        UniformNegativeSamplingTransform(vocab_size=NUM_UNIQUE_ITEMS, num_negative_samples=500),\n",
    "        UnsqueezeTransform(\"target_padding_mask\", -1),\n",
    "        UnsqueezeTransform(\"positive_labels\", -1),\n",
    "        GroupTransform({\"feature_tensors\": tensor_schema.names})\n",
    "    ],\n",
    "    \"val\": [\n",
    "        RenameTransform({\"user_id\": \"query_id\", \"item_id_mask\": \"padding_mask\"}),\n",
    "        GroupTransform({\"feature_tensors\": tensor_schema.names}),\n",
    "    ],\n",
    "    \"test\": [\n",
    "        RenameTransform({\"user_id\": \"query_id\", \"item_id_mask\": \"padding_mask\"}),\n",
    "        GroupTransform({\"feature_tensors\": tensor_schema.names})\n",
    "    ]\n",
    "}\n",
    "\n",
    "shared_meta = {\n",
    "    \"user_id\": {},\n",
    "    \"item_id\": {\"shape\": MAX_SEQ_LEN+1, \"padding\": tensor_schema[\"item_id\"].padding_value},\n",
    "    \"genres\": {\"shape\": [MAX_SEQ_LEN+1, MAX_LEN_GENRE], \"padding\": tensor_schema[\"genres\"].padding_value},\n",
    "    \"title\": {\"shape\": [MAX_SEQ_LEN+1, TITLE_EMB_DIM], \"padding\": tensor_schema[\"title\"].padding_value},\n",
    "}\n",
    "\n",
    "METADATA = {\n",
    "    \"train\": copy.deepcopy(shared_meta),\n",
    "    \"val\": {\n",
    "        **copy.deepcopy(shared_meta),\n",
    "        \"train\": {\n",
    "            \"shape\": MAX_SEQ_LEN,\n",
    "            \"padding\": tensor_schema[\"item_id\"].padding_value\n",
    "        },\n",
    "        \"ground_truth\": {\n",
    "            \"shape\": MAX_SEQ_LEN,\n",
    "            \"padding\": tensor_schema[\"item_id\"].padding_value\n",
    "        },\n",
    "    },\n",
    "    \"test\": copy.deepcopy(shared_meta)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.data.nn import ParquetModule\n",
    "\n",
    "parquet_datamodule = ParquetModule(\n",
    "    train_path=TRAIN_PATH,\n",
    "    val_path=VAL_PATH,\n",
    "    test_path=TEST_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    metadata=METADATA,\n",
    "    transforms=TRANSFORMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.nn.sequential import TwoTower\n",
    "from replay.nn import DefaultAttentionMask, SequenceEmbedding, SumAggregator, SwiGLUEncoder, ConcatAggregator\n",
    "from replay.nn.loss import CESampled, CE, BCE, BCESampled, LogInCE, LogInCESampled, LogOutCE\n",
    "from replay.nn.sequential import SasRecAggregator, SasRecTransformerLayer, DiffTransformerLayer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded_features = None\n",
    "excluded_features = list(set(excluded_features or []))\n",
    "excluded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<replay.nn.sequential.twotower.model.ItemReference at 0x7fc598e12a10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from replay.nn.sequential import ItemReference\n",
    "\n",
    "i = ItemReference(tensor_schema, PATH_ENCODED_FEATURES)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twotower = TwoTower.build_original(schema=tensor_schema,\n",
    "                                   embedding_dim=EMBEDDING_DIM,\n",
    "                                    item_reference_path=PATH_ENCODED_FEATURES\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HEADS = 2\n",
    "NUM_BLOCKS = 2\n",
    "DROPOUT = 0.2\n",
    "FEATURE_NAMES = [\"item_id\"]\n",
    "\n",
    "# common_aggregator = SumAggregator(embedding_dim=EMBEDDING_DIM)\n",
    "common_aggregator = ConcatAggregator(\n",
    "    input_embedding_dims=[EMBEDDING_DIM],\n",
    "    output_embedding_dim=EMBEDDING_DIM)\n",
    "\n",
    "excluded_features = None\n",
    "twotower = TwoTower(\n",
    "    schema=tensor_schema,\n",
    "    embedder=SequenceEmbedding(\n",
    "        schema=tensor_schema,\n",
    "        categorical_list_feature_aggregation_method=\"sum\",\n",
    "        excluded_features=excluded_features,\n",
    "    ),\n",
    "    attn_mask_builder=DefaultAttentionMask(\n",
    "        reference_feature_name=tensor_schema.item_id_feature_name,\n",
    "        num_heads=NUM_HEADS,\n",
    "    ),\n",
    "    query_tower_feature_names=FEATURE_NAMES,\n",
    "    item_tower_feature_names=FEATURE_NAMES,\n",
    "    query_embedding_aggregator=SasRecAggregator(\n",
    "        embedding_aggregator=common_aggregator,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "        dropout=DROPOUT,\n",
    "    ),\n",
    "    item_embedding_aggregator=common_aggregator,\n",
    "    query_encoder=DiffTransformerLayer(\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "    ),\n",
    "    query_tower_output_normalization=torch.nn.LayerNorm(EMBEDDING_DIM),\n",
    "    item_encoder=SwiGLUEncoder(embedding_dim=EMBEDDING_DIM, hidden_dim=2*EMBEDDING_DIM),\n",
    "    \n",
    "    item_reference_path=PATH_ENCODED_FEATURES,\n",
    "    loss=CESampled(padding_idx=tensor_schema.item_id_features.item().padding_value),\n",
    "    context_merger=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.nn.lightning import LightningModule\n",
    "from replay.nn.optimizer_utils import FatOptimizerFactory, LambdaLRSchedulerFactory\n",
    "\n",
    "model = LightningModule(twotower, \n",
    "                        lr_scheduler_factory=LambdaLRSchedulerFactory(warmup_steps=6),\n",
    "                        optimizer_factory=FatOptimizerFactory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/evtsinovnik/.conda/envs/replay/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/evtsinovnik/RePlay/examples/.checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | SasRec | 1.8 M  | train\n",
      "-----------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.006     Total estimated model params size (MB)\n",
      "40        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9026abe22b6f44ea8c56b49986341a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evtsinovnik/.conda/envs/replay/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:122: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16321d7a4b6d449f9c3d19cd71a063d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5662a613478b4b5daf196b563761833b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 95: 'recall@10' reached 0.01660 (best 0.01660), saving model to '/home/evtsinovnik/RePlay/examples/.checkpoints/epoch=0-step=95-v34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.083984  0.033989  0.024495  0.048034\n",
      "ndcg    0.083984  0.083884  0.081045  0.085554\n",
      "recall  0.001680  0.016602  0.031758  0.008555\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071204f517e24a6f976ec8790069a526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 190: 'recall@10' reached 0.01961 (best 0.01961), saving model to '/home/evtsinovnik/RePlay/examples/.checkpoints/epoch=1-step=190.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.107422  0.039323  0.029221  0.052272\n",
      "ndcg    0.107422  0.098296  0.096111  0.097699\n",
      "recall  0.002148  0.019609  0.037969  0.009727\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f2f53a9cba4d339f97b863549a5570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 285: 'recall@10' reached 0.02148 (best 0.02148), saving model to '/home/evtsinovnik/RePlay/examples/.checkpoints/epoch=2-step=285.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.091797  0.043252  0.031479  0.055690\n",
      "ndcg    0.091797  0.104995  0.098759  0.103680\n",
      "recall  0.001836  0.021484  0.038945  0.010703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from replay.nn.lightning.callbacks import ComputeMetricsCallback\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "\n",
    "validation_metrics_callback = ComputeMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=len(tokenizer.mapping[\"item_id\"]),\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=3,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=parquet_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LightningModule.load_from_checkpoint(checkpoint_callback.best_model_path, model=twotower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/evtsinovnik/.conda/envs/replay/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:122: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ef1a080cc04d478b79d9b7772c05e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([64, 3669])\n",
      "item_embeddings torch.Size([3669, 192])\n",
      "logits torch.Size([24, 3669])\n"
     ]
    }
   ],
   "source": [
    "from replay.nn.lightning.postprocessors import SeenItemsFilter\n",
    "from replay.nn.lightning.callbacks import ComputeMetricsCallback, PandasTopItemsCallback, PolarsTopItemsCallback, SparkTopItemsCallback, TorchTopItemsCallback, HiddenStatesCallback\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/test\", name=\"GPT_example\")\n",
    "\n",
    "TOPK = [1, 2, 3]\n",
    "\n",
    "postprocessor = SeenItemsFilter(\n",
    "        seen_path=TEST_PATH,\n",
    "        item_count=tensor_schema[ITEM_FEATURE_NAME].cardinality-1,\n",
    "        query_column=\"user_id\",\n",
    "        item_column=tensor_schema.item_id_feature_name\n",
    "    )\n",
    "postprocessors = [postprocessor]\n",
    "\n",
    "pandas_prediction_callback = PandasTopItemsCallback(\n",
    "    top_k=max(TOPK),\n",
    "    query_column=\"user_id\",\n",
    "    item_column=\"item_id\",\n",
    "    rating_column=\"score\",\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "metrics_callback = ComputeMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\", \"coverage\"],\n",
    "    ks=TOPK,\n",
    "    postprocessors=postprocessors,\n",
    "    item_count=tensor_schema[ITEM_FEATURE_NAME].cardinality,\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    callbacks=[\n",
    "        pandas_prediction_callback,\n",
    "             metrics_callback\n",
    "             ],\n",
    "    logger=csv_logger,\n",
    "    inference_mode=True\n",
    ")\n",
    "\n",
    "trainer.predict(best_model, datamodule=parquet_datamodule, return_predictions=False)\n",
    "\n",
    "pandas_res = pandas_prediction_callback.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7201,  0.4378, -2.8051,  ..., -0.6522,  1.7160, -0.3824],\n",
       "         [-1.7601,  0.4055, -2.7832,  ..., -0.6392,  1.6754, -0.4011],\n",
       "         [-1.7452,  0.4201, -2.7750,  ..., -0.6306,  1.6847, -0.3832],\n",
       "         ...,\n",
       "         [-1.7222,  0.4265, -2.7614,  ..., -0.6046,  1.6727, -0.4025],\n",
       "         [-1.7226,  0.4232, -2.7611,  ..., -0.6055,  1.6823, -0.3897],\n",
       "         [-1.7128,  0.4193, -2.7668,  ..., -0.6021,  1.6806, -0.3935]],\n",
       "\n",
       "        [[-1.7079,  0.4461, -2.7777,  ..., -0.5705,  1.6361, -0.3696],\n",
       "         [-1.6855,  0.4683, -2.8039,  ..., -0.5824,  1.6170, -0.3704],\n",
       "         [-1.6991,  0.4424, -2.7856,  ..., -0.5903,  1.6562, -0.3784],\n",
       "         ...,\n",
       "         [-1.7243,  0.4363, -2.7662,  ..., -0.6099,  1.6528, -0.3922],\n",
       "         [-1.7236,  0.4325, -2.7662,  ..., -0.6046,  1.6672, -0.3896],\n",
       "         [-1.7205,  0.4386, -2.7662,  ..., -0.6152,  1.6567, -0.3775]],\n",
       "\n",
       "        [[-1.7079,  0.4461, -2.7777,  ..., -0.5705,  1.6361, -0.3696],\n",
       "         [-1.6896,  0.4542, -2.7940,  ..., -0.5513,  1.6326, -0.3511],\n",
       "         [-1.6778,  0.4251, -2.7880,  ..., -0.5760,  1.5765, -0.3438],\n",
       "         ...,\n",
       "         [-1.7131,  0.4226, -2.7722,  ..., -0.5882,  1.6552, -0.3848],\n",
       "         [-1.7229,  0.4202, -2.7643,  ..., -0.6021,  1.6565, -0.3850],\n",
       "         [-1.7061,  0.4094, -2.7687,  ..., -0.6031,  1.6405, -0.3742]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.6329,  0.4922, -2.8230,  ..., -0.7495,  1.5194, -0.2124],\n",
       "         [-1.6508,  0.6183, -2.8544,  ..., -0.7938,  1.4637, -0.1240],\n",
       "         [-1.6414,  0.4797, -2.8196,  ..., -0.7158,  1.5304, -0.2388],\n",
       "         ...,\n",
       "         [-1.7284,  0.4368, -2.7803,  ..., -0.5873,  1.6809, -0.4079],\n",
       "         [-1.7262,  0.4271, -2.7812,  ..., -0.5932,  1.6859, -0.4061],\n",
       "         [-1.7182,  0.4278, -2.7737,  ..., -0.5887,  1.6790, -0.4045]],\n",
       "\n",
       "        [[-1.6329,  0.4922, -2.8230,  ..., -0.7495,  1.5194, -0.2124],\n",
       "         [-1.6508,  0.6183, -2.8544,  ..., -0.7938,  1.4637, -0.1240],\n",
       "         [-1.6414,  0.4797, -2.8196,  ..., -0.7158,  1.5304, -0.2388],\n",
       "         ...,\n",
       "         [-1.7226,  0.4332, -2.7498,  ..., -0.5998,  1.6660, -0.4016],\n",
       "         [-1.7371,  0.4309, -2.7601,  ..., -0.5946,  1.6682, -0.4032],\n",
       "         [-1.7314,  0.4366, -2.7633,  ..., -0.5889,  1.6817, -0.3925]],\n",
       "\n",
       "        [[-1.6329,  0.4922, -2.8230,  ..., -0.7495,  1.5194, -0.2124],\n",
       "         [-1.6508,  0.6183, -2.8544,  ..., -0.7938,  1.4637, -0.1240],\n",
       "         [-1.6414,  0.4797, -2.8196,  ..., -0.7158,  1.5304, -0.2388],\n",
       "         ...,\n",
       "         [-1.7164,  0.4497, -2.7736,  ..., -0.5898,  1.6491, -0.3952],\n",
       "         [-1.7181,  0.4402, -2.7738,  ..., -0.5911,  1.6625, -0.4003],\n",
       "         [-1.7164,  0.4369, -2.7794,  ..., -0.5874,  1.6755, -0.3883]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[score: double, user_id: bigint, item_id: bigint]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_res = tokenizer.inverse_transform(pandas_res)\n",
    "pandas_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6038</td>\n",
       "      <td>2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6038</td>\n",
       "      <td>2933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id item_id\n",
       "0           0     209\n",
       "0           0     101\n",
       "0           0     837\n",
       "0           0     322\n",
       "0           0    1431\n",
       "...       ...     ...\n",
       "6038     6038    2872\n",
       "6038     6038    2933\n",
       "6039     6039    1159\n",
       "6039     6039    1123\n",
       "6039     6039    2500\n",
       "\n",
       "[102469 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gt.loc[:, [\"user_id\", \"item_id\"]].explode(\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evtsinovnik/RePlay/replay/metrics/offline_metrics.py:375: UserWarning: ground_truth contains queries that are not presented in recommendations\n",
      "  warnings.warn(f\"{dataset_name} contains queries that are not presented in recommendations\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAP</th>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.003155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.004912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                 1         2         3\n",
       "MAP        0.005960  0.003849  0.003155\n",
       "Precision  0.005960  0.004719  0.004912\n",
       "Recall     0.000409  0.000592  0.000918"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_metrics = OfflineMetrics(\n",
    "    [Recall(TOPK), Precision(TOPK), MAP(TOPK)],\n",
    "    query_column=\"user_id\",\n",
    "    rating_column=\"score\"\n",
    ")(pandas_res, test_gt.loc[:, [\"user_id\", \"item_id\"]].explode(\"item_id\"))\n",
    "\n",
    "metrics_to_df(result_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
