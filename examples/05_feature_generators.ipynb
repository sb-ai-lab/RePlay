{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859b0060",
   "metadata": {},
   "source": [
    "# Feature generation with RePlay\n",
    "\n",
    "This notebook presents the RePlay functionality for features preprocessing and generation of new users and item features based on existing features and interactions history. RePlay offers classes:\n",
    "\n",
    "* CatFeaturesTransformer - one-hot encoding for categorical features\n",
    "* LogStatFeaturesProcessor - generates users and items statistical features based on historical interactions\n",
    "* ConditionalPopularityProcessor - generates popularity among users and items conditioned on categorical feature value for given user-item pair\n",
    "* HistoryBasedFeaturesProcessor - applies LogStatFeaturesProcessor and ConditionalPopularityProcessor as a pipeline\n",
    "\n",
    "\n",
    "### Fit \n",
    "\n",
    "To train a feature generator use the method `.fit()`.\n",
    "\n",
    "### Transform the data\n",
    "\n",
    "Method `.transform()` allows you to transform the data based on the train dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948b058f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x133bef760>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pyspark.sql import functions as sf\n",
    "from replay.utils.session_handler import get_spark_session, State \n",
    "\n",
    "from replay.preprocessing.data_preparator import DataPreparator, Indexer\n",
    "from replay.utils import convert2spark\n",
    "\n",
    "spark = State().session\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b7060",
   "metadata": {},
   "source": [
    "## Get started\n",
    "\n",
    "Download the dataset **MovieLens** and preprocess it with `DataPreparator` and `Indexer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430f0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"./data/ml1m_ratings.dat\", sep=\"\\t\", names=[\"userId\", \"itemId\",\"relevance\",\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01049a",
   "metadata": {},
   "source": [
    "For each user, we will add the categorical variable `month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc50982",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val = pd.to_datetime(ratings[\"timestamp\"], unit='s').map(lambda x: x.month)\n",
    "ratings.loc[:,\"month\"] = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ed6bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11-Nov-22 20:19:04, replay, INFO: Columns with ids of users or items are present in mapping. The dataframe will be treated as an interactions log.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-------------------+-----+\n",
      "|user_id|item_id|relevance|          timestamp|month|\n",
      "+-------+-------+---------+-------------------+-----+\n",
      "|      1|   1193|      5.0|2001-01-01 01:12:40|   12|\n",
      "|      1|    661|      3.0|2001-01-01 01:35:09|   12|\n",
      "+-------+-------+---------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp = DataPreparator()\n",
    "log = dp.transform(data=ratings,\n",
    "                  columns_mapping={\n",
    "                      \"user_id\": \"userId\",\n",
    "                      \"item_id\":  \"itemId\",\n",
    "                      \"relevance\": \"relevance\",\n",
    "                      \"timestamp\": \"timestamp\"\n",
    "                  })\n",
    "\n",
    "log.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c3451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+-------------------+-----+\n",
      "|user_idx|item_idx|relevance|          timestamp|month|\n",
      "+--------+--------+---------+-------------------+-----+\n",
      "|    4131|      43|      5.0|2001-01-01 01:12:40|   12|\n",
      "|    4131|     585|      3.0|2001-01-01 01:35:09|   12|\n",
      "+--------+--------+---------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = Indexer(user_col='user_id', item_col='item_id')\n",
    "indexer.fit(users=log.select('user_id'),\n",
    "            items=log.select('item_id'))\n",
    "log = indexer.transform(df=log)\n",
    "log.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cad651",
   "metadata": {},
   "source": [
    "We will leave only the first 20 users and will not take the 12th month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1024ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_20_users = log.where(\"user_idx < 20 and month != 12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6324d0",
   "metadata": {},
   "source": [
    "Let's create a dataframe with user attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f5a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = [\"M\",\"F\"]\n",
    "age = [20,30,40]\n",
    "\n",
    "user_features =  spark.createDataFrame(\n",
    "    [(i, age[random.randint(0,2)], gender[random.randint(0,1)])for i in range(20)]\n",
    ").toDF(\"user_idx\", \"age\" , \"gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57312b8c",
   "metadata": {},
   "source": [
    "## class CatFeaturesTransformer()\n",
    "\n",
    "Transform categorical features in ``cat_cols_list`` with one-hot encoding and remove original columns.\n",
    "    \n",
    "Parameters:\n",
    "* `cat_cols_list` - List of categorical columns\n",
    "* `alias` - Prefix of the generated column names (default is \"ohe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8fe841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.preprocessing.data_preparator import CatFeaturesTransformer\n",
    "cft = CatFeaturesTransformer([\"month\"])\n",
    "cft.fit(log_20_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb0de255",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm = cft.transform(log_20_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462d1fb",
   "metadata": {},
   "source": [
    "#### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587d2c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " user_idx  | 16                  \n",
      " item_idx  | 366                 \n",
      " relevance | 4.0                 \n",
      " timestamp | 2001-01-10 21:07:43 \n",
      " month     | 1                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_20_users.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09268270",
   "metadata": {},
   "source": [
    "#### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58dda77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------\n",
      " user_idx     | 16                  \n",
      " item_idx     | 366                 \n",
      " relevance    | 4.0                 \n",
      " timestamp    | 2001-01-10 21:07:43 \n",
      " ohe_month_9  | 0                   \n",
      " ohe_month_1  | 1                   \n",
      " ohe_month_5  | 0                   \n",
      " ohe_month_2  | 0                   \n",
      " ohe_month_6  | 0                   \n",
      " ohe_month_3  | 0                   \n",
      " ohe_month_10 | 0                   \n",
      " ohe_month_7  | 0                   \n",
      " ohe_month_4  | 0                   \n",
      " ohe_month_11 | 0                   \n",
      " ohe_month_8  | 0                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e9dd3",
   "metadata": {},
   "source": [
    "### Processing of cold users and items\n",
    "If the dataframe contains new values, not presented in train, those values are ignored (encoded columns will be all zeros)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96cc39c",
   "metadata": {},
   "source": [
    "To show this, add a user to the DataFrame with the value 12 in the \"month\" attribute. The value was absent in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d43b0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_with_12_month_attriubute = log.where(\"month == 12\").limit(1)\n",
    "\n",
    "user_idx, item_idx = user_with_12_month_attriubute.select(\"user_idx\", \"item_idx\").first()\n",
    "\n",
    "log_21_users  = log_20_users.union(user_with_12_month_attriubute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e3a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm_21_users = cft.transform(log_21_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1ec88",
   "metadata": {},
   "source": [
    "As we can see, for a user with a month value of 12, all attributes are **0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa5c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------\n",
      " user_idx     | 4131                \n",
      " item_idx     | 43                  \n",
      " relevance    | 5.0                 \n",
      " timestamp    | 2001-01-01 01:12:40 \n",
      " ohe_month_9  | 0                   \n",
      " ohe_month_1  | 0                   \n",
      " ohe_month_5  | 0                   \n",
      " ohe_month_2  | 0                   \n",
      " ohe_month_6  | 0                   \n",
      " ohe_month_3  | 0                   \n",
      " ohe_month_10 | 0                   \n",
      " ohe_month_7  | 0                   \n",
      " ohe_month_4  | 0                   \n",
      " ohe_month_11 | 0                   \n",
      " ohe_month_8  | 0                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm_21_users.where(f\"user_idx == {user_idx} and item_idx == {item_idx}\").show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e512232",
   "metadata": {},
   "source": [
    "## class LogStatFeaturesProcessor()\n",
    "\n",
    "Calculate user and item features based on historical interactions.\n",
    "\n",
    "Generated features:\n",
    "\n",
    "* `(u/i)_log_num_interact` - logarithm of the number of interactions\n",
    "* `(u/i)_log_interact_days_count` - logarithm of the number of unique dates with user-item interactions \n",
    "* `(u/i)_min_interact_date` - min interaction timestamp\n",
    "* `(u/i)_max_interact_date` - max interaction timestamp\n",
    "* `(u/i)_std` - standard deviation of relevance values for a user/item\n",
    "* `(u/i)_mean` - mean relevance values for a user/item\n",
    "* `(u/i)_quantile_05` - 0.05 percentile of relevance relevance for a user/item\n",
    "* `(u/i)_quantile_5` - 0.5 percentile of relevance relevance for a user/item\n",
    "* `(u/i)_quantile_95` - 0.95 percentile of relevance relevance for a user/item\n",
    "* `(u/i)_history_length_days` - difference between min interact date and max interact date\n",
    "* `(u/i)_last_interaction_gap_days` - number of days since last interaction\n",
    "* `(u/i)_mean_log_num_interact` - average logarithm of number of item/user interactions that the user/item interacted with\n",
    "* `(u/i)_(i/u)_log_num_interact_diff` - difference between the logarithm of the number of user/item interactions and **(u/i)_mean_log_num_interact** for this user/item\n",
    "* `na_(u/i)_log_features` - flag, indicating cold user/item, absent in training log\n",
    "    \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "* `u_mean_log_num_interact`   $$mean\\;log\\;num\\;interact\\;(u) = \\frac{\\Sigma_{i \\in I_u} log(itr(i)) }{\\|I_u\\|}$$ <br>\n",
    "Where:<br>\n",
    "  $\\;\\;i$ - item<br>$\\;\\;I_u$ - products that the user interacted with and $\\;\\;\\|I_u\\|$ is their number<br>$\\;\\;{itr(i)}$ - number of interactions of item<br><br><br>\n",
    "  \n",
    "* `u_i_log_num_interact_diff`   $$log\\;num\\;interact\\;diff\\;(u) = itr(u) - mean\\;log\\;num\\;interact\\;(u)$$ <br>Where:<br>\n",
    "  $\\;\\;u$ - user<br>$\\;\\;{itr(u)}$ - number of interactions of user<br><br><br>\n",
    "  \n",
    "* `abnormality`:\n",
    "  $$Abnormality(u) = \\frac{\\Sigma_{r \\in R_u} | n_{u,r} - \\overline{n_{r}} | }{\\| R_u \\|}$$ <br>Where:<br>\n",
    "  $\\;\\;n_{u,r}$ - represents the rating that user $u$ assigned to resource $r$<br>$\\;\\;\\overline{n_{r}}$ - the average rating of $r$<br>$\\;\\;R_u$ - the set of resources rated by $u$ and $\\|Ru\\|$ is their number<br><br>\n",
    "\n",
    "* `abnormalityCR` \n",
    "  $$Abnormality(u) = \\frac{\\Sigma_{r \\in R_u} (( n_{u,r} - \\overline{n_{r}} ) * contr(r))^2 }{\\| R_u \\|}$$ <br>\n",
    "  \n",
    "  $$contr(r) = 1 - \\frac{\\sigma_r - \\sigma_{min} }{\\sigma_{max} - \\sigma_{min}}$$<br>Where:<br>\n",
    "  $\\;\\;\\sigma_r$ - the standard deviation of the ratings associated with the resource $r$<br>$\\;\\;\\sigma_{min}$ and $\\;\\;\\sigma_{max}$ are respectively the smallest and the largest possible stanard deviation values, among resources\n",
    "  \n",
    "[More about abnormality, abnormalityCR](https://hal.inria.fr/hal-01254172/document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "054ff8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.preprocessing.history_based_fp import LogStatFeaturesProcessor\n",
    "lf = LogStatFeaturesProcessor()\n",
    "lf.fit(log_20_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f17003fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm = lf.transform(log_20_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e975d38",
   "metadata": {},
   "source": [
    "#### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ecc8101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " user_idx  | 16                  \n",
      " item_idx  | 366                 \n",
      " relevance | 4.0                 \n",
      " timestamp | 2001-01-10 21:07:43 \n",
      " month     | 1                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_20_users.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad835103",
   "metadata": {},
   "source": [
    "#### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "815c7bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " item_idx                    | 366                  \n",
      " user_idx                    | 16                   \n",
      " relevance                   | 4.0                  \n",
      " timestamp                   | 2001-01-10 21:07:43  \n",
      " month                       | 1                    \n",
      " u_log_num_interact          | 6.736966958001855    \n",
      " u_log_interact_days_count   | 4.795790545596741    \n",
      " u_min_interact_date         | 2001-01-10 20:59:24  \n",
      " u_max_interact_date         | 2003-02-27 15:31:39  \n",
      " u_std                       | 0.9460530559956203   \n",
      " u_mean                      | 3.561091340450771    \n",
      " u_quantile_05               | 2.0                  \n",
      " u_quantile_5                | 4.0                  \n",
      " u_quantile_95               | 5.0                  \n",
      " u_history_length_days       | 778                  \n",
      " u_last_interaction_gap_days | 0                    \n",
      " abnormality                 | 0.5423858158630311   \n",
      " abnormalityCR               | 0.19071128887487904  \n",
      " u_mean_i_log_num_interact   | 2.3656028196037595   \n",
      " i_log_num_interact          | 2.833213344056216    \n",
      " i_log_interact_days_count   | 2.70805020110221     \n",
      " i_min_interact_date         | 2000-05-10 00:52:44  \n",
      " i_max_interact_date         | 2001-01-10 21:07:43  \n",
      " i_std                       | 0.7717436331412898   \n",
      " i_mean                      | 3.7058823529411766   \n",
      " i_quantile_05               | 2.0                  \n",
      " i_quantile_5                | 4.0                  \n",
      " i_quantile_95               | 5.0                  \n",
      " i_history_length_days       | 245                  \n",
      " i_last_interaction_gap_days | 778                  \n",
      " i_mean_u_log_num_interact   | 7.147766712715646    \n",
      " na_u_log_features           | 0.0                  \n",
      " na_i_log_features           | 0.0                  \n",
      " u_i_log_num_interact_diff   | -0.41079975471379093 \n",
      " i_u_log_num_interact_diff   | 0.46761052445245666  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8d5b0",
   "metadata": {},
   "source": [
    "### Processing of cold users and items\n",
    "\n",
    "There are 3 possible scenarios:\n",
    "\n",
    "1. Cold user - a user which was not presented in the training log.\n",
    "    All items' statistics will be present, but the user statistics will be `0`.<br>Flag `na_u_log_features` will be `1`.\n",
    "<br>\n",
    "<br>\n",
    "2. Cold item - an item which was not presented in the training log.\n",
    "    All the user statistics will be present, but the item statistics will be `0`.<br>Flag `na_i_log_features` will be `1`.\n",
    "<br>\n",
    "<br>\n",
    "3. A pair of cold user cold item - user and item which were not presented in the training log.\n",
    "    All statistics will be `0`.<br>Flags `na_u_log_features`, `na_i_log_features` will be `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf38dd",
   "metadata": {},
   "source": [
    "#### Add cold user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "105ea9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cold = (\n",
    "    log.join(\n",
    "        log_20_users.select(sf.col(\"user_idx\").alias(\"u_idx\"), sf.col(\"item_idx\").alias(\"i_idx\")),\n",
    "        on=sf.col(\"u_idx\") == sf.col(\"user_idx\"),\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .filter(sf.col(\"i_idx\").isNull())\n",
    "    .select(log.columns)\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "user_idx, item_idx = user_cold.select(\"user_idx\", \"item_idx\").first()\n",
    "\n",
    "log_21_users  = log_20_users.union(user_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e07b7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm = lf.transform(log_21_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cbf4598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------\n",
      " item_idx                    | 2001                \n",
      " user_idx                    | 38                  \n",
      " relevance                   | 3.0                 \n",
      " timestamp                   | 2000-07-12 08:05:23 \n",
      " month                       | 7                   \n",
      " u_log_num_interact          | 0.0                 \n",
      " u_log_interact_days_count   | 0.0                 \n",
      " u_min_interact_date         | 1970-01-01 03:00:00 \n",
      " u_max_interact_date         | 1970-01-01 03:00:00 \n",
      " u_std                       | 0.0                 \n",
      " u_mean                      | 0.0                 \n",
      " u_quantile_05               | 0.0                 \n",
      " u_quantile_5                | 0.0                 \n",
      " u_quantile_95               | 0.0                 \n",
      " u_history_length_days       | 0                   \n",
      " u_last_interaction_gap_days | 0                   \n",
      " abnormality                 | 0.0                 \n",
      " abnormalityCR               | 0.0                 \n",
      " u_mean_i_log_num_interact   | 0.0                 \n",
      " i_log_num_interact          | 1.791759469228055   \n",
      " i_log_interact_days_count   | 1.791759469228055   \n",
      " i_min_interact_date         | 2000-05-12 19:38:22 \n",
      " i_max_interact_date         | 2000-11-22 04:03:35 \n",
      " i_std                       | 0.983192080250175   \n",
      " i_mean                      | 2.8333333333333335  \n",
      " i_quantile_05               | 1.0                 \n",
      " i_quantile_5                | 3.0                 \n",
      " i_quantile_95               | 4.0                 \n",
      " i_history_length_days       | 194                 \n",
      " i_last_interaction_gap_days | 827                 \n",
      " i_mean_u_log_num_interact   | 7.195477149106103   \n",
      " na_u_log_features           | 1.0                 \n",
      " na_i_log_features           | 0.0                 \n",
      " u_i_log_num_interact_diff   | -7.195477149106103  \n",
      " i_u_log_num_interact_diff   | 1.791759469228055   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm.where(f\"user_idx == {user_idx}\").show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c6fd3",
   "metadata": {},
   "source": [
    "#### Add cold item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56133e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cold = (\n",
    "    log.join(\n",
    "        log_20_users.select(sf.col(\"user_idx\").alias(\"u_idx\"), sf.col(\"item_idx\").alias(\"i_idx\")),\n",
    "        on=sf.col(\"i_idx\") == sf.col(\"item_idx\"),\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .filter(sf.col(\"i_idx\").isNull())\n",
    "    .select(log.columns)\n",
    "    .filter(\"user_idx < 20\")\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "user_idx, item_idx = item_cold.select(\"user_idx\", \"item_idx\").first()\n",
    "\n",
    "log_21_users  = log_20_users.union(item_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f3cba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm = lf.transform(log_21_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa08096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------\n",
      " item_idx                    | 3078                \n",
      " user_idx                    | 4                   \n",
      " relevance                   | 2.0                 \n",
      " timestamp                   | 2000-12-07 03:23:32 \n",
      " month                       | 12                  \n",
      " u_log_num_interact          | 6.911747300251674   \n",
      " u_log_interact_days_count   | 2.6390573296152584  \n",
      " u_min_interact_date         | 2000-11-22 03:47:32 \n",
      " u_max_interact_date         | 2002-05-13 02:30:58 \n",
      " u_std                       | 0.8582482337323498  \n",
      " u_mean                      | 3.0468127490039842  \n",
      " u_quantile_05               | 2.0                 \n",
      " u_quantile_5                | 3.0                 \n",
      " u_quantile_95               | 4.0                 \n",
      " u_history_length_days       | 537                 \n",
      " u_last_interaction_gap_days | 290                 \n",
      " abnormality                 | 0.696032092299538   \n",
      " abnormalityCR               | 0.30599330777137257 \n",
      " u_mean_i_log_num_interact   | 2.3843670209191963  \n",
      " i_log_num_interact          | 0.0                 \n",
      " i_log_interact_days_count   | 0.0                 \n",
      " i_min_interact_date         | 1970-01-01 03:00:00 \n",
      " i_max_interact_date         | 1970-01-01 03:00:00 \n",
      " i_std                       | 0.0                 \n",
      " i_mean                      | 0.0                 \n",
      " i_quantile_05               | 0.0                 \n",
      " i_quantile_5                | 0.0                 \n",
      " i_quantile_95               | 0.0                 \n",
      " i_history_length_days       | 0                   \n",
      " i_last_interaction_gap_days | 0                   \n",
      " i_mean_u_log_num_interact   | 0.0                 \n",
      " na_u_log_features           | 0.0                 \n",
      " na_i_log_features           | 1.0                 \n",
      " u_i_log_num_interact_diff   | 6.911747300251674   \n",
      " i_u_log_num_interact_diff   | -2.3843670209191963 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm.where(f\"item_idx == {item_idx}\").show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22cb61e",
   "metadata": {},
   "source": [
    "#### Add cold item and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f404f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_user_cold = (\n",
    "    log.join(\n",
    "        log_20_users.select(sf.col(\"user_idx\").alias(\"u_idx\"), sf.col(\"item_idx\").alias(\"i_idx\")),\n",
    "        on=sf.col(\"i_idx\") == sf.col(\"item_idx\"),\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .filter(sf.col(\"i_idx\").isNull())\n",
    "    .select(log.columns)\n",
    "    .filter(\"user_idx > 20\")\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "user_idx, item_idx = item_user_cold.select(\"user_idx\", \"item_idx\").first()\n",
    "\n",
    "log_21_users  = log_20_users.union(item_user_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc08e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm = lf.transform(log_21_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bffa56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------\n",
      " item_idx                    | 3078                \n",
      " user_idx                    | 1335                \n",
      " relevance                   | 1.0                 \n",
      " timestamp                   | 2000-12-02 02:41:14 \n",
      " month                       | 12                  \n",
      " u_log_num_interact          | 0.0                 \n",
      " u_log_interact_days_count   | 0.0                 \n",
      " u_min_interact_date         | 1970-01-01 03:00:00 \n",
      " u_max_interact_date         | 1970-01-01 03:00:00 \n",
      " u_std                       | 0.0                 \n",
      " u_mean                      | 0.0                 \n",
      " u_quantile_05               | 0.0                 \n",
      " u_quantile_5                | 0.0                 \n",
      " u_quantile_95               | 0.0                 \n",
      " u_history_length_days       | 0                   \n",
      " u_last_interaction_gap_days | 0                   \n",
      " abnormality                 | 0.0                 \n",
      " abnormalityCR               | 0.0                 \n",
      " u_mean_i_log_num_interact   | 0.0                 \n",
      " i_log_num_interact          | 0.0                 \n",
      " i_log_interact_days_count   | 0.0                 \n",
      " i_min_interact_date         | 1970-01-01 03:00:00 \n",
      " i_max_interact_date         | 1970-01-01 03:00:00 \n",
      " i_std                       | 0.0                 \n",
      " i_mean                      | 0.0                 \n",
      " i_quantile_05               | 0.0                 \n",
      " i_quantile_5                | 0.0                 \n",
      " i_quantile_95               | 0.0                 \n",
      " i_history_length_days       | 0                   \n",
      " i_last_interaction_gap_days | 0                   \n",
      " i_mean_u_log_num_interact   | 0.0                 \n",
      " na_u_log_features           | 1.0                 \n",
      " na_i_log_features           | 1.0                 \n",
      " u_i_log_num_interact_diff   | 0.0                 \n",
      " i_u_log_num_interact_diff   | 0.0                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm.where(f\"item_idx == {item_idx} and user_idx == {user_idx}\").show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a73c6",
   "metadata": {},
   "source": [
    "## class ConditionalPopularityProcessor()\n",
    "\n",
    "Calculate popularity based on user or item categorical features.\n",
    "If user features are provided, item features will be generated and vice versa.\n",
    "\n",
    "Parameters:\n",
    "* `cat_features_list` - List of columns with categorical features to use\n",
    "    for conditional popularity calculation\n",
    "    \n",
    "Generated features:\n",
    "* `(u/i)_pop_by_<cat>` - Calculated popularity of a user or item among categories\n",
    "* `na_(u/i)_pop_by_<cat>` - flag, indicating the absence of historical data for calculate popularity of a user or item among categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96f0fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.preprocessing.history_based_fp import ConditionalPopularityProcessor\n",
    "cpp = ConditionalPopularityProcessor([\"age\",\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87764227",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp.fit(log_20_users, user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af27eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm = cpp.transform(log_20_users.join(user_features, on=\"user_idx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0195afe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " item_idx           | 1658                \n",
      " gender             | F                   \n",
      " age                | 30                  \n",
      " user_idx           | 0                   \n",
      " relevance          | 5.0                 \n",
      " timestamp          | 2000-08-04 00:14:32 \n",
      " month              | 8                   \n",
      " i_pop_by_age       | 0.5                 \n",
      " na_i_pop_by_age    | false               \n",
      " i_pop_by_gender    | 0.8333333333333334  \n",
      " na_i_pop_by_gender | false               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10112c71",
   "metadata": {},
   "source": [
    "Popularity is calculated as the proportion of user/item interactions among a certain category of items/users.\n",
    "\n",
    "We trained the ConditionalPopularityProcessor() on categorical users features. Therefore, we can observe the distribution of interactions with a certain item among different groups of users.\n",
    "\n",
    "Since popularity is calculated as the proportion of interactions, the total popularity among a particular feature for any item is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a805ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------------+\n",
      "|item_idx|age|i_pop_by_age|\n",
      "+--------+---+------------+\n",
      "|     634| 20|         0.2|\n",
      "|     634| 40|         0.3|\n",
      "|     634| 30|         0.5|\n",
      "+--------+---+------------+\n",
      "\n",
      "+--------+------+---------------+\n",
      "|item_idx|gender|i_pop_by_gender|\n",
      "+--------+------+---------------+\n",
      "|     634|     F|            0.6|\n",
      "|     634|     M|            0.4|\n",
      "+--------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpp.conditional_pop_dict[\"age\"].where(\"item_idx == 634\").show()\n",
    "cpp.conditional_pop_dict[\"gender\"].where(\"item_idx == 634\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a50359",
   "metadata": {},
   "source": [
    "#### Add item with cold features\n",
    "\n",
    "If we apply `.transform()` to a new `user/item` - `item/user categorical feature value` pair, absent during training, the popularity feature will be 0 and `na_(u/i)_pop_by_<cat>` feature will be **true**, indicating the absence of historical data for the `user/item` - `feature value` combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "588ba4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cold = (\n",
    "    log.join(\n",
    "        log_20_users.select(sf.col(\"user_idx\").alias(\"u_idx\"), sf.col(\"item_idx\").alias(\"i_idx\")),\n",
    "        on=sf.col(\"i_idx\") == sf.col(\"item_idx\"),\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .filter(sf.col(\"i_idx\").isNull())\n",
    "    .select(log.columns)\n",
    "    .filter(\"user_idx < 20\")\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "user_idx, item_idx = item_cold.select(\"user_idx\", \"item_idx\").first()\n",
    "\n",
    "user_feature_for_21_users = user_features.union(\n",
    "    spark.createDataFrame(\n",
    "        [[item_idx, 35, gender[random.randint(0,1)]]]\n",
    "    ).toDF(\"user_idx\", \"age\" , \"gender\")\n",
    ")\n",
    "\n",
    "log_21_users  = log_20_users.union(item_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7e0c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_trsfrm = cpp.transform(log_21_users.join(user_feature_for_21_users, on=\"user_idx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2db537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " item_idx           | 3078                \n",
      " gender             | M                   \n",
      " age                | 30                  \n",
      " user_idx           | 4                   \n",
      " relevance          | 2.0                 \n",
      " timestamp          | 2000-12-07 03:23:32 \n",
      " month              | 12                  \n",
      " i_pop_by_age       | 0.0                 \n",
      " na_i_pop_by_age    | true                \n",
      " i_pop_by_gender    | 0.0                 \n",
      " na_i_pop_by_gender | true                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_trsfrm.where(f\"item_idx == {item_idx}\").show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f635e",
   "metadata": {},
   "source": [
    "## class HistoryBasedFeaturesProcessor()\n",
    "\n",
    "This class combines the functionality LogStatFeaturesProcessor() and ConditionalPopularityProcessor() for more convenient feature generation.\n",
    "\n",
    "See LogStatFeaturesProcessor and ConditionalPopularityProcessor documentation\n",
    "for detailed description of generated features.\n",
    "\n",
    "Parameters:\n",
    "* `use_log_features` - if **True** statistical log-based features\n",
    "    generated by LogStatFeaturesProcessor\n",
    "* `use_conditional_popularity` - if **True** conditional popularity\n",
    "    features generated by ConditionalPopularityProcessor\n",
    "* `user_cat_features_list` - list of user categorical features\n",
    "    used to calculate item conditional popularity features\n",
    "* `item_cat_features_list` - list of item categorical features\n",
    "    used to calculate user conditional popularity features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb556328",
   "metadata": {},
   "source": [
    "If `use_log_features` is `True`, features are generated with the LogStatFeaturesProcessor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b41f54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.preprocessing.history_based_fp import HistoryBasedFeaturesProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f560a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbf = HistoryBasedFeaturesProcessor(\n",
    "    use_log_features=True,\n",
    "    use_conditional_popularity=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96e1bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbf.fit(log_20_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d57d8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " item_idx                    | 366                  \n",
      " user_idx                    | 16                   \n",
      " relevance                   | 4.0                  \n",
      " timestamp                   | 2001-01-10 21:07:43  \n",
      " month                       | 1                    \n",
      " u_log_num_interact          | 6.736966958001855    \n",
      " u_log_interact_days_count   | 4.795790545596741    \n",
      " u_min_interact_date         | 2001-01-10 20:59:24  \n",
      " u_max_interact_date         | 2003-02-27 15:31:39  \n",
      " u_std                       | 0.9460530559956203   \n",
      " u_mean                      | 3.561091340450771    \n",
      " u_quantile_05               | 2.0                  \n",
      " u_quantile_5                | 4.0                  \n",
      " u_quantile_95               | 5.0                  \n",
      " u_history_length_days       | 778                  \n",
      " u_last_interaction_gap_days | 0                    \n",
      " abnormality                 | 0.5423858158630311   \n",
      " abnormalityCR               | 0.19071128887487904  \n",
      " u_mean_i_log_num_interact   | 2.3656028196037595   \n",
      " i_log_num_interact          | 2.833213344056216    \n",
      " i_log_interact_days_count   | 2.70805020110221     \n",
      " i_min_interact_date         | 2000-05-10 00:52:44  \n",
      " i_max_interact_date         | 2001-01-10 21:07:43  \n",
      " i_std                       | 0.7717436331412898   \n",
      " i_mean                      | 3.7058823529411766   \n",
      " i_quantile_05               | 2.0                  \n",
      " i_quantile_5                | 4.0                  \n",
      " i_quantile_95               | 5.0                  \n",
      " i_history_length_days       | 245                  \n",
      " i_last_interaction_gap_days | 778                  \n",
      " i_mean_u_log_num_interact   | 7.147766712715646    \n",
      " na_u_log_features           | 0.0                  \n",
      " na_i_log_features           | 0.0                  \n",
      " u_i_log_num_interact_diff   | -0.41079975471379093 \n",
      " i_u_log_num_interact_diff   | 0.46761052445245666  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hbf.transform(log_20_users).show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de66e2",
   "metadata": {},
   "source": [
    "If `use_conditional_popularity` is `True` and the lists of user/item categorical features are passed, features are generated with the ConditionalPopularityProcessor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad1ddefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbf = HistoryBasedFeaturesProcessor(\n",
    "    use_log_features=False,\n",
    "    use_conditional_popularity=True,\n",
    "    user_cat_features_list=[\"age\",\"gender\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec812282",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbf.fit(log_20_users, user_features=user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1ec70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " item_idx           | 1658                \n",
      " gender             | F                   \n",
      " age                | 30                  \n",
      " user_idx           | 0                   \n",
      " relevance          | 5.0                 \n",
      " timestamp          | 2000-08-04 00:14:32 \n",
      " month              | 8                   \n",
      " i_pop_by_age       | 0.5                 \n",
      " na_i_pop_by_age    | false               \n",
      " i_pop_by_gender    | 0.8333333333333334  \n",
      " na_i_pop_by_gender | false               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hbf.transform(log_20_users.join(user_features, on=\"user_idx\")).show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d7c7b",
   "metadata": {},
   "source": [
    "We can also use the full functionality of the class, and get all the features we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71af68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbf = HistoryBasedFeaturesProcessor(\n",
    "    use_log_features=True,\n",
    "    use_conditional_popularity=True,\n",
    "    user_cat_features_list=[\"age\",\"gender\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "709be2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbf.fit(log_20_users, user_features=user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ced3f03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 395:>              (0 + 12) / 12][Stage 402:>               (0 + 0) / 36]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " item_idx                    | 18                   \n",
      " gender                      | F                    \n",
      " age                         | 40                   \n",
      " user_idx                    | 18                   \n",
      " relevance                   | 5.0                  \n",
      " timestamp                   | 2000-05-09 19:45:35  \n",
      " month                       | 5                    \n",
      " u_log_num_interact          | 7.085064293952548    \n",
      " u_log_interact_days_count   | 3.7376696182833684   \n",
      " u_min_interact_date         | 2000-05-09 19:45:35  \n",
      " u_max_interact_date         | 2002-10-05 03:36:10  \n",
      " u_std                       | 0.7457986974338456   \n",
      " u_mean                      | 3.6758793969849246   \n",
      " u_quantile_05               | 2.0                  \n",
      " u_quantile_5                | 4.0                  \n",
      " u_quantile_95               | 5.0                  \n",
      " u_history_length_days       | 879                  \n",
      " u_last_interaction_gap_days | 145                  \n",
      " abnormality                 | 0.5100401525140352   \n",
      " abnormalityCR               | 0.16933410070777033  \n",
      " u_mean_i_log_num_interact   | 2.4123043228357837   \n",
      " i_log_num_interact          | 2.9444389791664403   \n",
      " i_log_interact_days_count   | 2.70805020110221     \n",
      " i_min_interact_date         | 2000-05-09 19:45:35  \n",
      " i_max_interact_date         | 2000-11-28 21:39:54  \n",
      " i_std                       | 0.611775290321498    \n",
      " i_mean                      | 4.473684210526316    \n",
      " i_quantile_05               | 3.0                  \n",
      " i_quantile_5                | 5.0                  \n",
      " i_quantile_95               | 5.0                  \n",
      " i_history_length_days       | 203                  \n",
      " i_last_interaction_gap_days | 821                  \n",
      " i_mean_u_log_num_interact   | 7.144389208284245    \n",
      " na_u_log_features           | 0.0                  \n",
      " na_i_log_features           | 0.0                  \n",
      " u_i_log_num_interact_diff   | -0.05932491433169762 \n",
      " i_u_log_num_interact_diff   | 0.5321346563306566   \n",
      " i_pop_by_age                | 0.21052631578947367  \n",
      " na_i_pop_by_age             | false                \n",
      " i_pop_by_gender             | 0.6842105263157895   \n",
      " na_i_pop_by_gender          | false                \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hbf.transform(log_20_users.join(user_features, on=\"user_idx\")).show(1, vertical=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
