{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b428c1",
      "metadata": {
        "id": "73b428c1"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2ebbc6",
      "metadata": {
        "id": "3f2ebbc6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from optuna.exceptions import ExperimentalWarning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95754d27",
      "metadata": {
        "id": "95754d27"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from replay.session_handler import get_spark_session, State\n",
        "\n",
        "from replay.models import RandomRec\n",
        "from replay.obp_evaluation.replay_offline import RePlayOfflinePolicyLearner\n",
        "from replay.obp_evaluation.utils import bandit_subset, get_est_rewards_by_reg\n",
        "\n",
        "import obp\n",
        "from obp.dataset import OpenBanditDataset\n",
        "from obp.policy import IPWLearner\n",
        "from obp.ope import (\n",
        "    OffPolicyEvaluation,\n",
        "    DirectMethod,\n",
        "    InverseProbabilityWeighting,\n",
        "    DoublyRobust\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e42a85f",
      "metadata": {
        "id": "9e42a85f",
        "outputId": "60b7eed8-18ef-4706-e880-3526779241e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/08/18 16:37:06 WARN Utils: Your hostname, hdilab01-X299-UD4-Pro resolves to a loopback address: 127.0.1.1; using 172.21.136.90 instead (on interface enp0s31f6)\n",
            "23/08/18 16:37:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hdilab01/anaconda3/envs/rec_sys/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "23/08/18 16:37:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "23/08/18 16:37:07 WARN DependencyUtils: Local jar /home/hdilab01/hdiRecSys/obp_connector/notebooks/jars/replay_2.12-0.1_spark_3.1.jar does not exist, skipping.\n",
            "23/08/18 16:37:07 INFO SparkContext: Running Spark version 3.1.3\n",
            "23/08/18 16:37:07 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
            "23/08/18 16:37:07 INFO ResourceUtils: ==============================================================\n",
            "23/08/18 16:37:07 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
            "23/08/18 16:37:07 INFO ResourceUtils: ==============================================================\n",
            "23/08/18 16:37:07 INFO SparkContext: Submitted application: pyspark-shell\n",
            "23/08/18 16:37:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
            "23/08/18 16:37:07 INFO ResourceProfile: Limiting resource is cpu\n",
            "23/08/18 16:37:07 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
            "23/08/18 16:37:07 INFO SecurityManager: Changing view acls to: hdilab01\n",
            "23/08/18 16:37:07 INFO SecurityManager: Changing modify acls to: hdilab01\n",
            "23/08/18 16:37:07 INFO SecurityManager: Changing view acls groups to: \n",
            "23/08/18 16:37:07 INFO SecurityManager: Changing modify acls groups to: \n",
            "23/08/18 16:37:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hdilab01); groups with view permissions: Set(); users  with modify permissions: Set(hdilab01); groups with modify permissions: Set()\n",
            "23/08/18 16:37:07 INFO Utils: Successfully started service 'sparkDriver' on port 35951.\n",
            "23/08/18 16:37:07 INFO SparkEnv: Registering MapOutputTracker\n",
            "23/08/18 16:37:07 INFO SparkEnv: Registering BlockManagerMaster\n",
            "23/08/18 16:37:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
            "23/08/18 16:37:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
            "23/08/18 16:37:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
            "23/08/18 16:37:07 INFO DiskBlockManager: Created local directory at /home/hdilab01/tmp/blockmgr-dba238df-8100-46b3-99d2-343361965cdc\n",
            "23/08/18 16:37:07 INFO MemoryStore: MemoryStore started with capacity 12.4 GiB\n",
            "23/08/18 16:37:07 INFO SparkEnv: Registering OutputCommitCoordinator\n",
            "23/08/18 16:37:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "23/08/18 16:37:07 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
            "23/08/18 16:37:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://localhost:4041\n",
            "23/08/18 16:37:07 ERROR SparkContext: Failed to add jars/replay_2.12-0.1_spark_3.1.jar to Spark environment\n",
            "java.io.FileNotFoundException: Jar /home/hdilab01/hdiRecSys/obp_connector/notebooks/jars/replay_2.12-0.1_spark_3.1.jar not found\n",
            "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:1929)\n",
            "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:1983)\n",
            "\tat org.apache.spark.SparkContext.$anonfun$new$12(SparkContext.scala:501)\n",
            "\tat org.apache.spark.SparkContext.$anonfun$new$12$adapted(SparkContext.scala:501)\n",
            "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
            "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
            "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
            "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:501)\n",
            "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
            "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
            "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
            "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
            "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
            "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
            "23/08/18 16:37:07 INFO Executor: Starting executor ID driver on host 172.21.136.90\n",
            "23/08/18 16:37:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33109.\n",
            "23/08/18 16:37:07 INFO NettyBlockTransferService: Server created on localhost:33109\n",
            "23/08/18 16:37:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
            "23/08/18 16:37:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 33109, None)\n",
            "23/08/18 16:37:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33109 with 12.4 GiB RAM, BlockManagerId(driver, localhost, 33109, None)\n",
            "23/08/18 16:37:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 33109, None)\n",
            "23/08/18 16:37:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 33109, None)\n",
            "23/08/18 16:37:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/hdilab01/hdiRecSys/obp_connector/notebooks/spark-warehouse').\n",
            "23/08/18 16:37:08 INFO SharedState: Warehouse path is 'file:/home/hdilab01/hdiRecSys/obp_connector/notebooks/spark-warehouse'.\n"
          ]
        }
      ],
      "source": [
        "spark = State(get_spark_session()).session\n",
        "spark.sparkContext.setLogLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324b7d5b",
      "metadata": {
        "id": "324b7d5b"
      },
      "source": [
        "Lets define OpenBanditDataset class with random policy. For the purpose of demonstration we won't use the whole dataset but only subset of size 10000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4afcf8ac",
      "metadata": {
        "id": "4afcf8ac",
        "outputId": "ce317409-385f-40ae-d953-d73e58d1655e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:obp.dataset.real:When `data_path` is not given, this class downloads the small-sized version of Open Bandit Dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7000\n",
            "3000\n"
          ]
        }
      ],
      "source": [
        "data_path = None # Path to the Open Bandit Dataset\n",
        "behavior_policy = \"random\"\n",
        "\n",
        "# Define OBP dataset and split it into train and test\n",
        "dataset = OpenBanditDataset(behavior_policy=behavior_policy, data_path=data_path, campaign='all')\n",
        "bandit_feedback_train, bandit_feedback_test = dataset.obtain_batch_bandit_feedback(test_size=0.3, is_timeseries_split=True)\n",
        "\n",
        "print(bandit_feedback_train[\"n_rounds\"])\n",
        "print(bandit_feedback_test[\"n_rounds\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f68017",
      "metadata": {
        "id": "d6f68017",
        "outputId": "04b1fb78-6161-4fe9-cc7d-7b4a7c25cfe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['n_rounds', 'n_actions', 'action', 'position', 'reward', 'pscore', 'context', 'action_context'])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bandit_feedback_train.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07d7624e",
      "metadata": {
        "id": "07d7624e"
      },
      "source": [
        "The keys of the dictionary are as follows.\n",
        "- n_rounds: number of rounds, data size of the logged bandit data;\n",
        "- n_actions: number of actions $|\\mathcal{A}|$;\n",
        "- action: action variables sampled by the behavior policy;\n",
        "- position: positions where actions are recommended, there are three positions in the ZOZOTOWN rec interface;\n",
        "- reward: binary reward variables, click indicators;\n",
        "- pscore: action choice probabilities by the behavior policy, propensity scores;\n",
        "- context: context vectors such as user-related features and user-item affinity scores;\n",
        "- action_context: item-related context vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f9485f",
      "metadata": {
        "id": "34f9485f"
      },
      "outputs": [],
      "source": [
        "#Define replay model\n",
        "model = RandomRec(seed=42)\n",
        "\n",
        "#Define learner which connects OBP data format with replay\n",
        "learner = RePlayOfflinePolicyLearner(n_actions=dataset.n_actions,\n",
        "                                     replay_model=model,\n",
        "                                     len_list=dataset.len_list,) #len_list is the number of predicted items per user"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2a9a3e",
      "metadata": {
        "id": "ff2a9a3e"
      },
      "source": [
        "**RePlayOfflinePolicyLearner** has the following methods\n",
        "- *fit(action, reward, timestamp, context, action_context)*;\n",
        "- *predict(n_rounds, context)* (context can be None thus n_rounds is **required**);\n",
        "- *optimize(bandit_feedback, val_size, param_borders, criterion, budget, new_study)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b92b89",
      "metadata": {
        "id": "c3b92b89",
        "outputId": "b5ffc288-e854-462b-b23b-e4621ae05d6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-08-18 16:37:08,919]\u001b[0m A new study created in memory with name: no-name-1018a8ca-3204-4d3e-a432-dabd14af6f56\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:15,599]\u001b[0m Trial 0 finished with value: 0.004010039096860206 and parameters: {'distribution': 'relevance', 'alpha': 169.64919642896555}. Best is trial 0 with value: 0.004010039096860206.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:17,655]\u001b[0m Trial 1 finished with value: 0.004010039096860206 and parameters: {'distribution': 'relevance', 'alpha': 583.812879578577}. Best is trial 0 with value: 0.004010039096860206.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:19,417]\u001b[0m Trial 2 finished with value: 0.004010039096860206 and parameters: {'distribution': 'relevance', 'alpha': 681.236753135904}. Best is trial 0 with value: 0.004010039096860206.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:21,216]\u001b[0m Trial 3 finished with value: 0.004010039096860206 and parameters: {'distribution': 'relevance', 'alpha': 786.2407660894739}. Best is trial 0 with value: 0.004010039096860206.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:22,979]\u001b[0m Trial 4 finished with value: 0.004010039096860206 and parameters: {'distribution': 'relevance', 'alpha': 585.3588626006618}. Best is trial 0 with value: 0.004010039096860206.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:24,646]\u001b[0m Trial 5 finished with value: 0.004010039096860206 and parameters: {'distribution': 'relevance', 'alpha': 717.9578573892538}. Best is trial 0 with value: 0.004010039096860206.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:26,895]\u001b[0m Trial 6 finished with value: 0.004277772668905336 and parameters: {'distribution': 'popular_based', 'alpha': 433.4315646083148}. Best is trial 6 with value: 0.004277772668905336.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:28,683]\u001b[0m Trial 7 finished with value: 0.004010039096860206 and parameters: {'distribution': 'relevance', 'alpha': 284.22165864563846}. Best is trial 6 with value: 0.004277772668905336.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:30,627]\u001b[0m Trial 8 finished with value: 0.004281787997779934 and parameters: {'distribution': 'popular_based', 'alpha': 939.3315911259522}. Best is trial 8 with value: 0.004281787997779934.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:32,519]\u001b[0m Trial 9 finished with value: 0.004279128299226652 and parameters: {'distribution': 'popular_based', 'alpha': 535.2546293291616}. Best is trial 8 with value: 0.004281787997779934.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:34,373]\u001b[0m Trial 10 finished with value: 0.004281865863281231 and parameters: {'distribution': 'popular_based', 'alpha': 959.5764547126181}. Best is trial 10 with value: 0.004281865863281231.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:36,125]\u001b[0m Trial 11 finished with value: 0.004281985642934386 and parameters: {'distribution': 'popular_based', 'alpha': 992.3696842851293}. Best is trial 11 with value: 0.004281985642934386.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:37,944]\u001b[0m Trial 12 finished with value: 0.004281789064898126 and parameters: {'distribution': 'popular_based', 'alpha': 939.6036111901312}. Best is trial 11 with value: 0.004281985642934386.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:39,630]\u001b[0m Trial 13 finished with value: 0.004281988531421982 and parameters: {'distribution': 'popular_based', 'alpha': 993.1865302583232}. Best is trial 13 with value: 0.004281988531421982.\u001b[0m\n",
            "\u001b[32m[I 2023-08-18 16:37:41,308]\u001b[0m Trial 14 finished with value: 0.004281322661762895 and parameters: {'distribution': 'popular_based', 'alpha': 833.310069818403}. Best is trial 13 with value: 0.004281988531421982.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'distribution': 'popular_based', 'alpha': 993.1865302583232}\n"
          ]
        }
      ],
      "source": [
        "#Define borders for the optimized parameters\n",
        "param_borders = {\n",
        "    \"distribution\": [\"popular_based\", \"relevance\"],\n",
        "    \"alpha\": [-0.5, 1000],\n",
        "}\n",
        "\n",
        "#Take subset of train data to validate our model with OBP\n",
        "bandit_feedback_subset = bandit_subset([0, 7000], bandit_feedback_train) #The first parameter is a slice of subset [a, b]\n",
        "print(learner.optimize(bandit_feedback_subset, val_size=0.3, param_borders=param_borders, budget=15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56181ad2",
      "metadata": {
        "id": "56181ad2",
        "outputId": "9c092915-f786-40b3-a26f-39c0b1b87c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3000, 80, 3)\n"
          ]
        }
      ],
      "source": [
        "#Fit replay model inside our learner\n",
        "learner.fit(\n",
        "    action=bandit_feedback_train[\"action\"],\n",
        "    reward=bandit_feedback_train[\"reward\"],\n",
        "    timestamp=np.arange(bandit_feedback_train[\"n_rounds\"]),\n",
        "    context=bandit_feedback_train[\"context\"],\n",
        "    action_context=bandit_feedback_train[\"action_context\"]\n",
        ")\n",
        "\n",
        "#Predict distribution over actions: shape (n_rounds, n_actions, len_list)\n",
        "action_dist = learner.predict(bandit_feedback_test[\"n_rounds\"], bandit_feedback_test[\"context\"])\n",
        "\n",
        "print(action_dist.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ba6cfbe",
      "metadata": {
        "id": "7ba6cfbe"
      },
      "source": [
        "When we get distribution over actions - we can run any evaluation procedure from the OBP. Here we use three estimators\n",
        "- *IPW*: Average rewards with importance weights\n",
        "- *DM*: Average predicted rewards using the classifier\n",
        "- *DR*: Combination of the above methods with zero bias and lower variance\n",
        "\n",
        "Also, we can construct confidence intervals for each of these methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a270431c",
      "metadata": {
        "id": "a270431c"
      },
      "outputs": [],
      "source": [
        "ope = OffPolicyEvaluation(\n",
        "    bandit_feedback=bandit_feedback_test,\n",
        "    ope_estimators=[InverseProbabilityWeighting(), DirectMethod(), DoublyRobust()]\n",
        ")\n",
        "\n",
        "estimated_rewards_by_reg_model = get_est_rewards_by_reg(dataset.n_actions,\n",
        "                                                        dataset.len_list,\n",
        "                                                        bandit_feedback_train,\n",
        "                                                        bandit_feedback_test)\n",
        "\n",
        "estimated_policy_value = ope.estimate_policy_values(\n",
        "    action_dist=action_dist,\n",
        "    estimated_rewards_by_reg_model=estimated_rewards_by_reg_model,\n",
        ")\n",
        "\n",
        "estimated_ci = ope.estimate_intervals(\n",
        "    action_dist=action_dist,\n",
        "    estimated_rewards_by_reg_model=estimated_rewards_by_reg_model,\n",
        "    n_bootstrap_samples=10000,\n",
        "    random_state=12345,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3291a3",
      "metadata": {
        "id": "af3291a3",
        "outputId": "6b900c5d-8cdc-4bdc-e28a-72c7dbbd0c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores for LinUCB ipw : 3.345, dm : 3.952, dr : 3.370\n",
            "Estimated confidence intervals:\n",
            "                       ipw        dm        dr\n",
            "mean              0.003338  0.003952  0.003363\n",
            "95.0% CI (lower)  0.001343  0.003896  0.001398\n",
            "95.0% CI (upper)  0.005661  0.004008  0.005622\n"
          ]
        }
      ],
      "source": [
        "out_str = f\"Scores for LinUCB\"\n",
        "for key, val in estimated_policy_value.items():\n",
        "    out_str += f\" {key} : {(1e3 * val):.3f},\"\n",
        "\n",
        "out_str = out_str[:-1]\n",
        "\n",
        "print(out_str)\n",
        "print(\"Estimated confidence intervals:\")\n",
        "print(pd.DataFrame(estimated_ci).to_string())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}