{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of the Bert4Rec training and inference stages\n",
    "Note that all the given examples can be run without using PySpark, using only Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from replay.metrics import OfflineMetrics, Recall, Precision, MAP, NDCG, HitRate, MRR\n",
    "from replay.metrics.torch_metrics_builder import metrics_to_df\n",
    "from replay.splitters import LastNSplitter\n",
    "from replay.data import (\n",
    "    FeatureHint,\n",
    "    FeatureInfo,\n",
    "    FeatureSchema,\n",
    "    FeatureSource,\n",
    "    FeatureType,\n",
    "    Dataset,\n",
    ")\n",
    "from replay.models.nn.optimizer_utils import FatOptimizerFactory\n",
    "from replay.models.nn.sequential.callbacks import (\n",
    "    ValidationMetricsCallback,\n",
    "    SparkPredictionCallback,\n",
    "    PandasPredictionCallback,\n",
    "    TorchPredictionCallback,\n",
    "    QueryEmbeddingsPredictionCallback,\n",
    ")\n",
    "from replay.models.nn.sequential.postprocessors import RemoveSeenItems\n",
    "from replay.data.nn import (\n",
    "    SequenceTokenizer,\n",
    "    SequentialDataset,\n",
    "    TensorFeatureSource,\n",
    "    TensorSchema,\n",
    "    TensorFeatureInfo\n",
    ")\n",
    "from replay.models.nn.sequential import Bert4Rec\n",
    "from replay.models.nn.sequential.bert4rec import (\n",
    "    Bert4RecPredictionDataset,\n",
    "    Bert4RecTrainingDataset,\n",
    "    Bert4RecValidationDataset,\n",
    "    Bert4RecPredictionBatch,\n",
    "    Bert4RecModel\n",
    ")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "### Load raw movielens-1M interactions, item features and user features.\n",
    "In the current implementation, the Bert4Rec does not take into account the features of items or users. They are only used to get a complete list of users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rs-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rs_datasets import MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = MovieLens(\"1m\")\n",
    "interactions = movielens.ratings\n",
    "user_features = movielens.users\n",
    "item_features = movielens.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109\n",
       "2        1      914       3  978301968\n",
       "3        1     3408       4  978300275\n",
       "4        1     2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  occupation zip_code\n",
       "0        1      F    1          10    48067\n",
       "1        2      M   56          16    70072\n",
       "2        3      M   25          15    55117\n",
       "3        4      M   45           7    02460\n",
       "4        5      M   25          20    55455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing duplicates in the timestamp column without changing the original items order where timestamp is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000138</th>\n",
       "      <td>6040</td>\n",
       "      <td>858</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000153</th>\n",
       "      <td>6040</td>\n",
       "      <td>2384</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999873</th>\n",
       "      <td>6040</td>\n",
       "      <td>593</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000007</th>\n",
       "      <td>6040</td>\n",
       "      <td>1961</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000192</th>\n",
       "      <td>6040</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825793</th>\n",
       "      <td>4958</td>\n",
       "      <td>2399</td>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825438</th>\n",
       "      <td>4958</td>\n",
       "      <td>1407</td>\n",
       "      <td>5</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825724</th>\n",
       "      <td>4958</td>\n",
       "      <td>3264</td>\n",
       "      <td>4</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825731</th>\n",
       "      <td>4958</td>\n",
       "      <td>2634</td>\n",
       "      <td>3</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825603</th>\n",
       "      <td>4958</td>\n",
       "      <td>1924</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating  timestamp\n",
       "1000138     6040      858       4          0\n",
       "1000153     6040     2384       4          1\n",
       "999873      6040      593       5          2\n",
       "1000007     6040     1961       4          3\n",
       "1000192     6040     2019       5          4\n",
       "...          ...      ...     ...        ...\n",
       "825793      4958     2399       1        446\n",
       "825438      4958     1407       5        447\n",
       "825724      4958     3264       4        448\n",
       "825731      4958     2634       3        449\n",
       "825603      4958     1924       4        450\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[\"timestamp\"] = interactions[\"timestamp\"].astype(\"int64\")\n",
    "interactions = interactions.sort_values(by=\"timestamp\")\n",
    "interactions[\"timestamp\"] = interactions.groupby(\"user_id\").cumcount()\n",
    "interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split interactions into the train, validation and test datasets using LastNSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = LastNSplitter(\n",
    "    N=1,\n",
    "    divide_column=\"user_id\",\n",
    "    query_column=\"user_id\",\n",
    "    strategy=\"interactions\",\n",
    ")\n",
    "\n",
    "raw_test_events, raw_test_gt = splitter.split(interactions)\n",
    "raw_validation_events, raw_validation_gt = splitter.split(raw_test_events)\n",
    "raw_train_events = raw_validation_events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare FeatureSchema required to create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_feature_schema(is_ground_truth: bool) -> FeatureSchema:\n",
    "    base_features = FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"user_id\",\n",
    "                feature_hint=FeatureHint.QUERY_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"item_id\",\n",
    "                feature_hint=FeatureHint.ITEM_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    if is_ground_truth:\n",
    "        return base_features\n",
    "\n",
    "    all_features = base_features + FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"timestamp\",\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "                feature_hint=FeatureHint.TIMESTAMP,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return all_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset for the training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_train_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets (events and ground_truth) for the validation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_validation_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=raw_validation_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets (events and ground_truth) for the testing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_test_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=raw_test_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the tensor schema\n",
    "A schema shows the correspondence of columns from the source dataset with the internal representation of tensors inside the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_FEATURE_NAME = \"item_id_seq\"\n",
    "\n",
    "tensor_schema = TensorSchema(\n",
    "    TensorFeatureInfo(\n",
    "        name=ITEM_FEATURE_NAME,\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_sources=[TensorFeatureSource(FeatureSource.INTERACTIONS, train_dataset.feature_schema.item_id_column)],\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "        embedding_dim=300,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequential datasets using SequenceTokenizer\n",
    "The SequentialDataset internally store data in the form of sequences of items sorted by increasing interaction time (timestamp). A SequenceTokenizer is used to convert to this format. In addition, the SequenceTokenizer encodes all categorical columns from the source dataset and stores mapping inside itself.\n",
    "SequentialDataset.keep_common_query_ids is used to leave only sequences from the same users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset)\n",
    "\n",
    "sequential_train_dataset = tokenizer.transform(train_dataset)\n",
    "\n",
    "sequential_validation_dataset = tokenizer.transform(validation_dataset)\n",
    "sequential_validation_gt = tokenizer.transform(validation_gt, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_validation_dataset, sequential_validation_gt = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_validation_dataset, sequential_validation_gt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_ids = test_gt.query_ids\n",
    "test_query_ids_np = tokenizer.query_id_encoder.transform(test_query_ids)[\"user_id\"].values\n",
    "sequential_test_dataset = tokenizer.transform(test_dataset).filter_by_query_id(test_query_ids_np)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "### Create Bert4Rec model instance and run the training stage using lightning\n",
    "After each epoch validation metrics are shown. You can change the list of validation metrics in ValidationMetricsCallback\n",
    "The model is determined to be the best and is saved if the metric updates its maximum during validation (see the ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 100\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "MAX_EPOCHS = 1\n",
    "\n",
    "model = Bert4Rec(\n",
    "    tensor_schema,\n",
    "    block_count=2,\n",
    "    head_count=4,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=0.001),\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    # if you use multiple dataloaders, then add the serial number of the dataloader to the suffix of the metric name.\n",
    "    # For example,\"recall@10/dataloader_idx_0\"\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_validation_dataset)]\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"Bert4Rec_example\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=Bert4RecTrainingDataset(\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=Bert4RecValidationDataset(\n",
    "        sequential_validation_dataset,\n",
    "        sequential_validation_gt,\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the best model is saved inside checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Bert4Rec.load_from_checkpoint(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference stage\n",
    "### Prepare Dataloader and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataloader = DataLoader(\n",
    "    dataset=Bert4RecPredictionDataset(\n",
    "        sequential_test_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/test\", name=\"Bert4Rec_example\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference\n",
    "You can get the recommendations in four formats: PySpark DataFrame, Pandas DataFrame, Polars DataFrame, PyTorch tensors. Each of the types corresponds a callback.\n",
    "\n",
    "You can filter the results using postprocessors strategy. For example the RemoveSeenItems postprocessor is filtering out the items that already have been seen in test dataset.\n",
    "\n",
    "You don't need to use all three callbacks. This is shown only for example\n",
    "\n",
    "Also, you can get user embeddings, that were used to perform predictions, using `get_query_embedding` method inside Bert4RecModel or `QueryEmbeddingsPredictionCallback` for lightning module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To operate with PySpark DataFrames and use ``SparkPredictionCallback`` you should create a spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.utils.session_handler import get_spark_session\n",
    "spark_session = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = [1, 10, 20, 100]\n",
    "\n",
    "postprocessors = [RemoveSeenItems(sequential_test_dataset)]\n",
    "\n",
    "spark_prediction_callback = SparkPredictionCallback(\n",
    "    spark_session=spark_session,\n",
    "    top_k=max(TOPK),\n",
    "    query_column=\"user_id\",\n",
    "    item_column=\"item_id\",\n",
    "    rating_column=\"score\",\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "\n",
    "pandas_prediction_callback = PandasPredictionCallback(\n",
    "    top_k=max(TOPK),\n",
    "    query_column=\"user_id\",\n",
    "    item_column=\"item_id\",\n",
    "    rating_column=\"score\",\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "\n",
    "torch_prediction_callback = TorchPredictionCallback(\n",
    "    top_k=max(TOPK),\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "\n",
    "query_embeddings_callback = QueryEmbeddingsPredictionCallback()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    callbacks=[\n",
    "        spark_prediction_callback,\n",
    "        pandas_prediction_callback,\n",
    "        torch_prediction_callback,\n",
    "        query_embeddings_callback,\n",
    "    ],\n",
    "    logger=csv_logger,\n",
    "    inference_mode=True\n",
    ")\n",
    "trainer.predict(best_model, dataloaders=prediction_dataloader, return_predictions=False)\n",
    "\n",
    "spark_res = spark_prediction_callback.get_result()\n",
    "pandas_res = pandas_prediction_callback.get_result()\n",
    "torch_user_ids, torch_item_ids, torch_scores = torch_prediction_callback.get_result()\n",
    "user_embeddings = query_embeddings_callback.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|user_id|item_id|             score|\n",
      "+-------+-------+------------------+\n",
      "|      0|   2559|2.1270530223846436|\n",
      "|      0|   1539|2.1258444786071777|\n",
      "|      0|    589| 2.071683883666992|\n",
      "|      0|   1192| 1.998902440071106|\n",
      "|      0|   1178|1.9865914583206177|\n",
      "|      0|    585|1.8850951194763184|\n",
      "|      0|   2647|1.8264131546020508|\n",
      "|      0|   2821|1.8195174932479858|\n",
      "|      0|   1284|1.8040269613265991|\n",
      "|      0|   2789|1.8005681037902832|\n",
      "|      0|   2502|1.7928752899169922|\n",
      "|      0|   1220| 1.791283369064331|\n",
      "|      0|    108|1.7866688966751099|\n",
      "|      0|   1196|1.7825181484222412|\n",
      "|      0|   1227|1.7511154413223267|\n",
      "|      0|   2530| 1.718513011932373|\n",
      "|      0|   1111| 1.713446855545044|\n",
      "|      0|    293| 1.691711187362671|\n",
      "|      0|    642|1.6797393560409546|\n",
      "|      0|   2327|1.6610043048858643|\n",
      "+-------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2559</td>\n",
       "      <td>2.127053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1539</td>\n",
       "      <td>2.125844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>589</td>\n",
       "      <td>2.071684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1192</td>\n",
       "      <td>1.998902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1178</td>\n",
       "      <td>1.986591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>3686</td>\n",
       "      <td>0.782319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>2512</td>\n",
       "      <td>0.782027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>1556</td>\n",
       "      <td>0.781867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>584</td>\n",
       "      <td>0.779429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>3684</td>\n",
       "      <td>0.774854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id item_id     score\n",
       "0           0    2559  2.127053\n",
       "0           0    1539  2.125844\n",
       "0           0     589  2.071684\n",
       "0           0    1192  1.998902\n",
       "0           0    1178  1.986591\n",
       "...       ...     ...       ...\n",
       "6039     6039    3686  0.782319\n",
       "6039     6039    2512  0.782027\n",
       "6039     6039    1556  0.781867\n",
       "6039     6039     584  0.779429\n",
       "6039     6039    3684  0.774854\n",
       "\n",
       "[604000 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor([2559, 1539,  589, 1192, 1178,  585, 2647, 2821, 1284, 2789, 2502, 1220,\n",
      "         108, 1196, 1227, 2530, 1111,  293,  642, 2327, 3509, 1366, 2928, 1575,\n",
      "        3106,  352,   33,  220,  476, 2637, 3402, 1180, 1211,  900, 1726,  847,\n",
      "        3682, 2847, 2614, 1287, 1195,  315, 3724,  908, 1245, 2918,  537, 3091,\n",
      "         453,  941, 2105, 1073, 1202, 1513,   31, 3184, 1854, 1166, 2588, 2536,\n",
      "        1058, 3412, 1214,  918,  593, 1628, 2632, 1543, 1899, 1271, 1204, 3441,\n",
      "        2433, 2233,  740,  770,  956, 3554, 1529, 1353,  912, 1533, 1282, 1246,\n",
      "        1120, 1023, 1238,  586,   46, 3430, 2324, 1931, 3107, 1568, 3686, 1373,\n",
      "        1840, 1885, 1232, 3178]) tensor([2.1271, 2.1258, 2.0717, 1.9989, 1.9866, 1.8851, 1.8264, 1.8195, 1.8040,\n",
      "        1.8006, 1.7929, 1.7913, 1.7867, 1.7825, 1.7511, 1.7185, 1.7134, 1.6917,\n",
      "        1.6797, 1.6610, 1.6569, 1.6292, 1.6153, 1.6131, 1.6088, 1.6063, 1.6017,\n",
      "        1.5603, 1.5589, 1.5530, 1.5476, 1.5298, 1.5297, 1.5266, 1.5113, 1.5078,\n",
      "        1.4992, 1.4878, 1.4809, 1.4740, 1.4342, 1.4294, 1.4269, 1.4226, 1.4184,\n",
      "        1.4161, 1.3976, 1.3877, 1.3868, 1.3768, 1.3652, 1.3612, 1.3392, 1.3252,\n",
      "        1.3250, 1.3221, 1.3088, 1.3008, 1.2952, 1.2933, 1.2845, 1.2799, 1.2745,\n",
      "        1.2740, 1.2693, 1.2640, 1.2622, 1.2538, 1.2457, 1.2434, 1.2321, 1.2311,\n",
      "        1.2292, 1.2274, 1.2148, 1.2100, 1.2061, 1.2030, 1.2009, 1.1992, 1.1935,\n",
      "        1.1922, 1.1878, 1.1771, 1.1749, 1.1684, 1.1650, 1.1648, 1.1563, 1.1557,\n",
      "        1.1411, 1.1381, 1.1375, 1.1295, 1.1253, 1.1252, 1.1201, 1.1168, 1.1143,\n",
      "        1.1106])\n"
     ]
    }
   ],
   "source": [
    "print(torch_user_ids[0], torch_item_ids[0], torch_scores[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to get the recomendations in PySpark format. \n",
    "Let's get the inverse representation of labels using inverse_transform method.\n",
    "\n",
    "Note that the reverse representation can only be obtained for PySpark and Pandas formats. When working with PyTorch tensors, the reverse representation must be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = tokenizer.query_and_item_id_encoder.inverse_transform(spark_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-------+\n",
      "|             score|user_id|item_id|\n",
      "+------------------+-------+-------+\n",
      "|2.1270530223846436|      1|   2628|\n",
      "|2.1258444786071777|      1|   1580|\n",
      "| 2.071683883666992|      1|    593|\n",
      "| 1.998902440071106|      1|   1210|\n",
      "|1.9865914583206177|      1|   1196|\n",
      "|1.8850951194763184|      1|    589|\n",
      "|1.8264131546020508|      1|   2716|\n",
      "|1.8195174932479858|      1|   2890|\n",
      "|1.8040269613265991|      1|   1304|\n",
      "|1.8005681037902832|      1|   2858|\n",
      "|1.7928752899169922|      1|   2571|\n",
      "| 1.791283369064331|      1|   1240|\n",
      "|1.7866688966751099|      1|    110|\n",
      "|1.7825181484222412|      1|   1214|\n",
      "|1.7511154413223267|      1|   1247|\n",
      "| 1.718513011932373|      1|   2599|\n",
      "| 1.713446855545044|      1|   1127|\n",
      "| 1.691711187362671|      1|    296|\n",
      "|1.6797393560409546|      1|    648|\n",
      "|1.6610043048858643|      1|   2396|\n",
      "+------------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference on a subset of items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It happens that it is necessary to process an inference not on all items, but on a certain subset (we will call it ``candidates``). For example, you want to make predictions only for the cartoons among all possible movies.\n",
    "\n",
    "To speed up the inference in this case, you can use the Bert4Rec's property ``candidates_to_score``. It should be a ``torch.LongTensor`` with the IDs of the objects on which you want to process an inference. It is important that the candidate scores will be returned in the order in which their IDs were in the ``candidates_to_score``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_candidates = Bert4Rec.load_from_checkpoint(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = 2\n",
    "CANDIDATES = torch.LongTensor([42, 1337])\n",
    "\n",
    "postprocessors = [RemoveSeenItems(sequential_test_dataset)]\n",
    "\n",
    "pandas_prediction_callback = PandasPredictionCallback(\n",
    "    top_k=TOPK,\n",
    "    query_column=\"user_id\",\n",
    "    item_column=\"item_id\",\n",
    "    rating_column=\"score\",\n",
    "    postprocessors=postprocessors,\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(callbacks=[pandas_prediction_callback], logger=csv_logger, inference_mode=True)\n",
    "best_model_candidates.candidates_to_score = CANDIDATES\n",
    "trainer.predict(best_model_candidates, dataloaders=prediction_dataloader, return_predictions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be scores only for items whose IDs are contained in ``candidates_to_score``.\n",
    "\n",
    "If ``candidates_to_score`` contains a small number of candidates and ``top_k`` parameter is small, it may happen that the required number of items will not remain after the postprocessor is running. In this case, the ``top_k`` items for each user will be returned from the model, then the postprocessor will remove the seen items and if the user has less than the ``top_k`` items, then the non-candidate items with a score equal to ``-inf`` will be added to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1337</td>\n",
       "      <td>0.963838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>-1.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1337</td>\n",
       "      <td>0.605986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.830044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1337</td>\n",
       "      <td>0.941634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6037</td>\n",
       "      <td>42</td>\n",
       "      <td>-1.272029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6038</td>\n",
       "      <td>1337</td>\n",
       "      <td>0.561242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6038</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.793737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.82424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12080 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id item_id     score\n",
       "0           0    1337  0.963838\n",
       "0           0      42 -1.138735\n",
       "1           1    1337  0.605986\n",
       "1           1      42 -0.830044\n",
       "2           2    1337  0.941634\n",
       "...       ...     ...       ...\n",
       "6037     6037      42 -1.272029\n",
       "6038     6038    1337  0.561242\n",
       "6038     6038      42 -0.793737\n",
       "6039     6039      42  -0.82424\n",
       "6039     6039       0      -inf\n",
       "\n",
       "[12080 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_prediction_callback.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** don`t forget to reset ``candidates_to_score`` to ``None`` if they are no longer needed and you want to run the model inference with all items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_candidates.candidates_to_score = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_args = {\"query_column\": \"user_id\", \"rating_column\": \"score\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics = OfflineMetrics(\n",
    "    [Recall(TOPK), Precision(TOPK), MAP(TOPK), NDCG(TOPK), MRR(TOPK), HitRate(TOPK)], **init_args\n",
    ")(recommendations.toPandas(), raw_test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HitRate</th>\n",
       "      <td>0.007119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP</th>\n",
       "      <td>0.005215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRR</th>\n",
       "      <td>0.005215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG</th>\n",
       "      <td>0.005714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.003560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.007119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                 2\n",
       "HitRate    0.007119\n",
       "MAP        0.005215\n",
       "MRR        0.005215\n",
       "NDCG       0.005714\n",
       "Precision  0.003560\n",
       "Recall     0.007119"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_to_df(result_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got 6040 x 300 user embeddings, because among all 12 batches: \n",
    "\n",
    "11 batches contains 512 samples\n",
    "\n",
    "1 batch contains 408 left samples\n",
    "\n",
    "11 * 512 + 408 == 6040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7878,  0.8159,  1.2742,  ..., -1.4545,  1.6887,  0.0550],\n",
       "        [-0.4360,  0.5662,  1.4676,  ..., -0.6618,  1.4071,  0.3617],\n",
       "        [-0.6623,  0.9143,  1.3480,  ..., -1.2325,  1.7697,  0.2644],\n",
       "        ...,\n",
       "        [-1.3103,  0.8071,  1.0478,  ..., -0.8558,  1.4005,  0.6592],\n",
       "        [-0.4810,  0.5335,  1.7069,  ..., -0.7740,  1.3061,  0.3048],\n",
       "        [-0.3925,  0.4476,  1.3665,  ..., -0.3378,  1.2455,  0.2170]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6040, 300])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access user embeddings directly with `Bert4RecModel` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5941,  0.4922,  1.0920,  ..., -0.6684,  0.4808, -0.6346],\n",
       "        [ 0.3899,  0.0972,  0.6055,  ..., -1.2973,  0.4056, -0.5432],\n",
       "        [-0.7955,  0.1026,  1.0066,  ..., -1.1204,  0.2826, -0.4639],\n",
       "        ...,\n",
       "        [ 0.1230,  0.2439,  0.3789,  ..., -1.8021,  0.0392, -0.5761],\n",
       "        [-0.4846,  0.6347,  1.2935,  ..., -1.7495,  0.5781, -0.9601],\n",
       "        [-0.8379,  0.3875,  0.8284,  ..., -1.1218,  0.6631, -0.2801]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "core_model = Bert4RecModel(\n",
    "    tensor_schema,\n",
    "    num_blocks=2,\n",
    "    num_heads=4,\n",
    "    max_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout=0.5\n",
    ")\n",
    "core_model.eval()\n",
    "core_model = core_model.to(device)\n",
    "\n",
    "# Get first batch of data\n",
    "data = next(iter(prediction_dataloader))\n",
    "tensor_map, padding_mask, tokens_mask = data[\"inputs\"], data[\"pad_mask\"], data[\"token_mask\"]\n",
    "\n",
    "# Ensure everything is on the same device\n",
    "padding_mask = padding_mask.to(device)\n",
    "tokens_mask = tokens_mask.to(device)\n",
    "tensor_map[\"item_id_seq\"] = tensor_map[\"item_id_seq\"].to(device)\n",
    "\n",
    "# Get user embeddings\n",
    "user_embeddings_batch = core_model.get_query_embeddings(tensor_map, padding_mask, tokens_mask)\n",
    "user_embeddings_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 300])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of launching an inference for a single user without using a trainer (in order to speed up)\n",
    "An example for the production of an online script\n",
    "\n",
    "Let's assume that the user's sequence consisted of a sequence of items [1, 2, 3, 4, 5]. \n",
    "Сreate a padding mask and tokens mask corresponding to the sequence of items.\n",
    "\n",
    "It is important to take only the latest MAX_SEQ_LEN or less items.\n",
    "\n",
    "You can use ``candidates_to_score`` here as well. It is possible to set a property or pass ``candidates_to_score`` as a parameter of predict method.\n",
    "\n",
    "**Note:** make sure that you set the ``torch.set_num_threads()`` parameter in the product environment. This is important because torch can consume resources exceeding the k8s limit and thus activating CPU throttling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequence, padding_mask and tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sequence = torch.arange(1, 5).unsqueeze(0)[:, -MAX_SEQ_LEN:]\n",
    "padding_mask = torch.ones_like(item_sequence, dtype=torch.bool)\n",
    "tokens_mask = padding_mask.roll(-1, dims=0)\n",
    "tokens_mask[-1, ...] = 0\n",
    "sequence_item_count = item_sequence.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping created tensors in the Bert4RecPredictionBatch entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Bert4RecPredictionBatch(\n",
    "    query_id=torch.arange(0, item_sequence.shape[0], 1).long(),\n",
    "    padding_mask=padding_mask,\n",
    "    features={ITEM_FEATURE_NAME: item_sequence.long()},\n",
    "    tokens_mask=tokens_mask\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run predict step of the Bert4Rec and get scores from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3967,  0.1647, -0.7265,  ..., -2.8732, -1.8079,  0.8802]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scores = best_model.predict(batch)\n",
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting five items with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 257, 2233,  476,    0,  352]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(scores, k=5).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass ``candidates_to_score`` in predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9725,  1.6978]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    scores = best_model.predict(batch, candidates_to_score=CANDIDATES)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized inference on CPU with OpenVino\n",
    "Bert4Rec model can be compiled into IR format of OpenVino for faster inference on CPU.\n",
    "\n",
    "Bert4Rec model itself or the path to the checkpoint of the model can be passed as ``model`` parameter. \n",
    "\n",
    "Parameter ``mode`` defines inference mode and shape of inputs. Could be one of ``one_query``, ``batch``, ``dynamic_batch_size``. This parameter determines whether the first dimension of the input (the batch size) will be static or dynamic.\n",
    "\n",
    "Parameter ``num_candidates_to_score`` defines number of item ids to calculate scores if it is necessary. This parameter determines whether the model will make a partial inference and, if so, whether the list of candidates will have a static or dynamic length.\n",
    "\n",
    "Parameter ``num_threads`` defines number of CPU threads to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay.models.nn.sequential.compiled import Bert4RecCompiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Bert4Rec.load_from_checkpoint(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Compile model from Bert4Rec model or checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model = Bert4RecCompiled.compile(\n",
    "    model=best_model,  # or checkpoint_callback.best_model_path\n",
    "    mode=\"one_query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping tensors in the Bert4RecPredictionBatch entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sequence = torch.arange(1, 5).unsqueeze(0)[:, -MAX_SEQ_LEN:]\n",
    "padding_mask = torch.ones_like(item_sequence, dtype=torch.bool)\n",
    "tokens_mask = padding_mask.roll(-1, dims=0)\n",
    "tokens_mask[-1, ...] = 0\n",
    "sequence_item_count = item_sequence.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Bert4RecPredictionBatch(\n",
    "    query_id=torch.arange(0, item_sequence.shape[0], 1).long(),\n",
    "    padding_mask=padding_mask,\n",
    "    features={ITEM_FEATURE_NAME: item_sequence.long()},\n",
    "    tokens_mask=tokens_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predict and get scores from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3883])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_model.predict(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiled model also supports inference on submitted candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping created tensors in the Bert4RecPredictionBatch entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Bert4RecPredictionBatch(\n",
    "    query_id=torch.arange(0, item_sequence.shape[0], 1).long(),\n",
    "    padding_mask=padding_mask,\n",
    "    features={ITEM_FEATURE_NAME: item_sequence.long()},\n",
    "    tokens_mask=tokens_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model with defined ``num_candidates_to_score``. There are 3 alternatives:\n",
    "- ``-1`` - sets candidates_to_score shape to dynamic range [1, ?]\n",
    "- ``N`` - sets candidates_to_score shape to [1, N]\n",
    "- ``None`` - disable candidates_to_score usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model = Bert4RecCompiled.compile(\n",
    "    model=best_model,\n",
    "    mode=\"one_query\",\n",
    "    num_candidates_to_score=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predict and get scores from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_model.predict(batch, CANDIDATES).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
