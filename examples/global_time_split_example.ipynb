{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752ca432",
   "metadata": {},
   "source": [
    "# Example of the SASRec training with using RandomTargetNextNSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43869dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from replay.metrics import OfflineMetrics, Recall, Precision, MAP, NDCG, HitRate, MRR\n",
    "from replay.metrics.torch_metrics_builder import metrics_to_df\n",
    "from replay.splitters import LastNSplitter, RandomTargetNextNSplitter, TimeSplitter\n",
    "from replay.preprocessing.filters import MinCountFilter\n",
    "from replay.data import (\n",
    "    FeatureHint,\n",
    "    FeatureInfo,\n",
    "    FeatureSchema,\n",
    "    FeatureSource,\n",
    "    FeatureType,\n",
    "    Dataset,\n",
    ")\n",
    "from replay.models.nn.optimizer_utils import FatOptimizerFactory\n",
    "from replay.models.nn.sequential.callbacks import (\n",
    "    ValidationMetricsCallback,\n",
    "    SparkPredictionCallback,\n",
    "    PandasPredictionCallback,\n",
    "    TorchPredictionCallback,\n",
    "    QueryEmbeddingsPredictionCallback,\n",
    ")\n",
    "from replay.models.nn.sequential.postprocessors import RemoveSeenItems\n",
    "from replay.data.nn import SequenceTokenizer, SequentialDataset, TensorFeatureSource, TensorSchema, TensorFeatureInfo\n",
    "from replay.models.nn.sequential import SasRec\n",
    "from replay.models.nn.sequential.sasrec import (\n",
    "    SasRecPredictionDataset,\n",
    "    SasRecTrainingDataset,\n",
    "    SasRecValidationDataset,\n",
    "    SasRecPredictionBatch,\n",
    "    SasRecModel,\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "from replay.preprocessing.filters import filter_cold\n",
    "from replay.preprocessing.utils import merge_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900ff7b",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "### Load raw movielens-1M interactions, item features and user features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc630ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rs-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bb051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rs_datasets import MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928c6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = MovieLens(\"1m\")\n",
    "interactions = movielens.ratings\n",
    "user_features = movielens.users\n",
    "item_features = movielens.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2b17f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109\n",
       "2        1      914       3  978301968\n",
       "3        1     3408       4  978300275\n",
       "4        1     2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ab5f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  occupation zip_code\n",
       "0        1      F    1          10    48067\n",
       "1        2      M   56          16    70072\n",
       "2        3      M   25          15    55117\n",
       "3        4      M   45           7    02460\n",
       "4        5      M   25          20    55455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a49fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7069e",
   "metadata": {},
   "source": [
    "Removing duplicates in the timestamp column without changing the original items order where timestamp is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673ef18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[\"timestamp\"] = interactions[\"timestamp\"].astype(\"int64\")\n",
    "interactions = interactions.sort_values(by=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217beb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_feature_schema(is_ground_truth: bool) -> FeatureSchema:\n",
    "    base_features = FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"user_id\",\n",
    "                feature_hint=FeatureHint.QUERY_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"item_id\",\n",
    "                feature_hint=FeatureHint.ITEM_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    if is_ground_truth:\n",
    "        return base_features\n",
    "\n",
    "    all_features = base_features + FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"timestamp\",\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "                feature_hint=FeatureHint.TIMESTAMP,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db00831",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_FEATURE_NAME = \"item_id_seq\"\n",
    "\n",
    "tensor_schema = TensorSchema(\n",
    "    TensorFeatureInfo(\n",
    "        name=ITEM_FEATURE_NAME,\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_sources=[TensorFeatureSource(FeatureSource.INTERACTIONS, train_dataset.feature_schema.item_id_column)],\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956848b1",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02d470",
   "metadata": {},
   "source": [
    "In this section, we will examine three different strategies for splitting data into training, validation, and test sets:\n",
    "\n",
    "1) Leave one out split (LOO).\n",
    "2) Global temporal split + LOO target.\n",
    "3) Global temporal split + random target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e613586",
   "metadata": {},
   "source": [
    "### Leave-one-out split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d249d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = LastNSplitter(\n",
    "    N=1,\n",
    "    divide_column=\"user_id\",\n",
    "    query_column=\"user_id\",\n",
    "    strategy=\"interactions\",\n",
    ")\n",
    "\n",
    "raw_test_events, raw_test_gt = splitter.split(interactions)\n",
    "raw_validation_events, raw_validation_gt = splitter.split(raw_test_events)\n",
    "raw_train_events = raw_validation_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "771856cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_train_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "validation_dataset_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_validation_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=raw_validation_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "test_dataset_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=raw_test_events,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=raw_test_gt,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb76ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset_loo)\n",
    "\n",
    "sequential_train_dataset_loo = tokenizer.transform(train_dataset_loo)\n",
    "\n",
    "sequential_validation_dataset_loo = tokenizer.transform(validation_dataset_loo)\n",
    "sequential_validation_gt_loo = tokenizer.transform(validation_gt_loo, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_validation_dataset_loo, sequential_validation_gt_loo = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_validation_dataset_loo, sequential_validation_gt_loo\n",
    ")\n",
    "\n",
    "sequential_test_dataset_loo = tokenizer.transform(test_dataset_loo)\n",
    "sequential_test_gt_loo = tokenizer.transform(test_gt_loo, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_test_dataset_loo, sequential_test_gt_loo = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_test_dataset_loo, sequential_test_gt_loo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349be8fb",
   "metadata": {},
   "source": [
    "### Global temporal split + LOO target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7650ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_splitter = TimeSplitter(\n",
    "    time_threshold=0.1,\n",
    "    query_column=\"user_id\"\n",
    ")\n",
    "\n",
    "loo_splitter = LastNSplitter(\n",
    "    N=1,\n",
    "    divide_column=\"user_id\",\n",
    "    query_column=\"user_id\",\n",
    "    strategy=\"interactions\",\n",
    ")\n",
    "\n",
    "min_cnt_filter = MinCountFilter(num_entries=2, groupby_column=\"user_id\")\n",
    "\n",
    "train_val, test_holdout = time_splitter.split(interactions)\n",
    "train, val_holdout = time_splitter.split(train_val)\n",
    "\n",
    "train = min_cnt_filter.transform(train)\n",
    "\n",
    "test_holdout = filter_cold(test_holdout, train, mode=\"items\")\n",
    "val_holdout = filter_cold(val_holdout, train, mode=\"items\")\n",
    "train_val = filter_cold(train_val, train, mode=\"items\")\n",
    "\n",
    "val_input, val_target = loo_splitter.split(val_holdout)\n",
    "test_input, test_target = loo_splitter.split(test_holdout)\n",
    "\n",
    "val_input = merge_subsets([val_input, train])\n",
    "test_input = merge_subsets([test_input, train_val])\n",
    "\n",
    "val_target = filter_cold(val_target, train, mode=\"users\", query_column=\"user_id\")\n",
    "test_target = filter_cold(test_target, train, mode=\"users\", query_column=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b98796d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_gts_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=train,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "validation_dataset_gts_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=val_input,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt_gts_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=val_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "test_dataset_gts_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=test_input,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt_gts_loo = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=test_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "951ddb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset_gts_loo)\n",
    "\n",
    "sequential_train_dataset_gts_loo = tokenizer.transform(train_dataset_gts_loo)\n",
    "\n",
    "sequential_validation_dataset_gts_loo = tokenizer.transform(validation_dataset_gts_loo)\n",
    "sequential_validation_gt_gts_loo = tokenizer.transform(validation_gt_gts_loo, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_validation_dataset_gts_loo, sequential_validation_gt_gts_loo = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_validation_dataset_gts_loo, sequential_validation_gt_gts_loo\n",
    ")\n",
    "\n",
    "sequential_test_dataset_gts_loo = tokenizer.transform(test_dataset_gts_loo)\n",
    "sequential_test_gt_gts_loo = tokenizer.transform(test_gt_gts_loo, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_test_dataset_gts_loo, sequential_test_gt_gts_loo = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_test_dataset_gts_loo, sequential_test_gt_gts_loo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1afd9ae",
   "metadata": {},
   "source": [
    "### Global temporal split + random target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b1daa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_splitter = TimeSplitter(\n",
    "    time_threshold=0.1,\n",
    "    query_column=\"user_id\"\n",
    ")\n",
    "\n",
    "random_splitter = RandomTargetNextNSplitter(\n",
    "    N=1,\n",
    "    seed=42,\n",
    "    divide_column=\"user_id\",\n",
    "    query_column=\"user_id\"\n",
    ")\n",
    "\n",
    "min_cnt_filter = MinCountFilter(num_entries=2, groupby_column=\"user_id\")\n",
    "\n",
    "train_val, test_holdout = time_splitter.split(interactions)\n",
    "train, val_holdout = time_splitter.split(train_val)\n",
    "\n",
    "train = min_cnt_filter.transform(train)\n",
    "\n",
    "test_holdout = filter_cold(test_holdout, train, mode=\"items\")\n",
    "val_holdout = filter_cold(val_holdout, train, mode=\"items\")\n",
    "train_val = filter_cold(train_val, train, mode=\"items\")\n",
    "\n",
    "val_input, val_target = random_splitter.split(val_holdout)\n",
    "test_input, test_target = random_splitter.split(test_holdout)\n",
    "\n",
    "val_input = merge_subsets([val_input, train])\n",
    "test_input = merge_subsets([test_input, train_val])\n",
    "\n",
    "val_target = filter_cold(val_target, train, mode=\"users\", query_column=\"user_id\")\n",
    "test_target = filter_cold(test_target, train, mode=\"users\", query_column=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13fa04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_gts_random = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=train,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "validation_dataset_gts_random = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=val_input,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt_gts_random = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=val_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "test_dataset_gts_random = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=test_input,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt_gts_random = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=test_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec4f3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset_gts_random)\n",
    "\n",
    "sequential_train_dataset_gts_random = tokenizer.transform(train_dataset_gts_random)\n",
    "\n",
    "sequential_validation_dataset_gts_random = tokenizer.transform(validation_dataset_gts_random)\n",
    "sequential_validation_gt_gts_random = tokenizer.transform(validation_gt_gts_random, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_validation_dataset_gts_random, sequential_validation_gt_gts_random = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_validation_dataset_gts_random, sequential_validation_gt_gts_random\n",
    ")\n",
    "\n",
    "sequential_test_dataset_gts_random = tokenizer.transform(test_dataset_gts_random)\n",
    "sequential_test_gt_gts_random = tokenizer.transform(test_gt_gts_random, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_test_dataset_gts_random, sequential_test_gt_gts_random = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_test_dataset_gts_random, sequential_test_gt_gts_random\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98ff37",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b20828",
   "metadata": {},
   "source": [
    "### Train SASRec with LOO split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "model = SasRec(\n",
    "    tensor_schema,\n",
    "    block_count=2,\n",
    "    head_count=2,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"SASRec_example\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset_loo.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_validation_dataset_loo)],\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=SasRecTrainingDataset(\n",
    "        sequential_train_dataset_loo,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_validation_dataset_loo,\n",
    "        sequential_validation_gt_loo,\n",
    "        sequential_train_dataset_loo,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d951b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SasRec.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    tensor_schema=tensor_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_test_dataset_loo,\n",
    "        sequential_test_gt_loo,\n",
    "        sequential_train_dataset_loo,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c23faf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064412e9751c4c87b2f9320a65609cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.040894  0.077621  0.083144  0.069200\n",
      "ndcg    0.040894  0.102925  0.123141  0.082525\n",
      "recall  0.040894  0.186258  0.266391  0.123179\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0408940427005291     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@10           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07762108743190765    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@20           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08314439654350281    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06919977813959122    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0408940427005291     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@10          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10292463004589081    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@20          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12314070761203766    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08252540975809097    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0408940427005291     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@10         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18625827133655548    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@20         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.26639074087142944    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12317880988121033    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0408940427005291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@10          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07762108743190765   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@20          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08314439654350281   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06919977813959122   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0408940427005291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@10         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10292463004589081   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@20         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12314070761203766   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08252540975809097   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0408940427005291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@10        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18625827133655548   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@20        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.26639074087142944   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12317880988121033   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'recall@1': 0.0408940427005291,\n",
       "  'ndcg@1': 0.0408940427005291,\n",
       "  'map@1': 0.0408940427005291,\n",
       "  'recall@5': 0.12317880988121033,\n",
       "  'ndcg@5': 0.08252540975809097,\n",
       "  'map@5': 0.06919977813959122,\n",
       "  'recall@10': 0.18625827133655548,\n",
       "  'ndcg@10': 0.10292463004589081,\n",
       "  'map@10': 0.07762108743190765,\n",
       "  'recall@20': 0.26639074087142944,\n",
       "  'ndcg@20': 0.12314070761203766,\n",
       "  'map@20': 0.08314439654350281}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset_loo.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_test_dataset_loo)],\n",
    ")\n",
    "\n",
    "trainer_test = L.Trainer(callbacks=[test_metrics_callback], logger=csv_logger)\n",
    "trainer_test.validate(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815860f",
   "metadata": {},
   "source": [
    "### Train SASRec with Gloabal Temporal split + LOO target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "model = SasRec(\n",
    "    tensor_schema,\n",
    "    block_count=2,\n",
    "    head_count=2,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"SASRec_example\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset_gts_loo.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_validation_dataset_gts_loo)],\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=SasRecTrainingDataset(\n",
    "        sequential_train_dataset_gts_loo,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_validation_dataset_gts_loo,\n",
    "        sequential_validation_gt_gts_loo,\n",
    "        sequential_train_dataset_gts_loo,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92c14b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SasRec.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    tensor_schema=tensor_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_test_dataset_gts_loo,\n",
    "        sequential_test_gt_gts_loo,\n",
    "        sequential_train_dataset_gts_loo,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00a4ba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c84618b15048ec814afffecc3683a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.019569  0.043450  0.047445  0.038536\n",
      "ndcg    0.019569  0.058902  0.073808  0.046928\n",
      "recall  0.019569  0.109589  0.169276  0.072407\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01956947147846222    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@10           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04344966635107994    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@20           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.047445159405469894    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.038535553961992264    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01956947147846222    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@10          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05890187993645668    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@20          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07380761206150055    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04692849889397621    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01956947147846222    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@10         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10958904027938843    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@20         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1692759245634079     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07240704447031021    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01956947147846222   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@10          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04344966635107994   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@20          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.047445159405469894   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.038535553961992264   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01956947147846222   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@10         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05890187993645668   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@20         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07380761206150055   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04692849889397621   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01956947147846222   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@10        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10958904027938843   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@20        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1692759245634079    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07240704447031021   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'recall@1': 0.01956947147846222,\n",
       "  'ndcg@1': 0.01956947147846222,\n",
       "  'map@1': 0.01956947147846222,\n",
       "  'recall@5': 0.07240704447031021,\n",
       "  'ndcg@5': 0.04692849889397621,\n",
       "  'map@5': 0.038535553961992264,\n",
       "  'recall@10': 0.10958904027938843,\n",
       "  'ndcg@10': 0.05890187993645668,\n",
       "  'map@10': 0.04344966635107994,\n",
       "  'recall@20': 0.1692759245634079,\n",
       "  'ndcg@20': 0.07380761206150055,\n",
       "  'map@20': 0.047445159405469894}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset_loo.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_test_dataset_gts_loo)],\n",
    ")\n",
    "\n",
    "trainer_test = L.Trainer(callbacks=[test_metrics_callback], logger=csv_logger)\n",
    "trainer_test.validate(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9889f8af",
   "metadata": {},
   "source": [
    "### Train SASRec with Global Temporal split + random target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c44d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "model = SasRec(\n",
    "    tensor_schema,\n",
    "    block_count=2,\n",
    "    head_count=2,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"SASRec_example\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset_gts_random.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_validation_dataset_gts_random)],\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=SasRecTrainingDataset(\n",
    "        sequential_train_dataset_gts_random,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_validation_dataset_gts_random,\n",
    "        sequential_validation_gt_gts_random,\n",
    "        sequential_train_dataset_gts_random,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c9bbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SasRec.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    tensor_schema=tensor_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_test_dataset_gts_random,\n",
    "        sequential_test_gt_gts_random,\n",
    "        sequential_train_dataset_gts_random,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3706c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097c90cf193d420e961a3e2fdb8f1415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.019569  0.047283  0.051570  0.040753\n",
      "ndcg    0.019569  0.067384  0.083146  0.051194\n",
      "recall  0.019569  0.134051  0.196673  0.083170\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01956947147846222    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@10           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04728318378329277    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@20           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05157012864947319    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.040753427892923355    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01956947147846222    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@10          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06738412380218506    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@20          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08314632624387741    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0511941984295845     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01956947147846222    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@10         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1340508759021759     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@20         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.196673184633255     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08317025750875473    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01956947147846222   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@10          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04728318378329277   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@20          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05157012864947319   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.040753427892923355   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01956947147846222   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@10         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06738412380218506   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@20         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08314632624387741   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0511941984295845    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01956947147846222   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@10        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1340508759021759    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@20        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.196673184633255    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08317025750875473   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'recall@1': 0.01956947147846222,\n",
       "  'ndcg@1': 0.01956947147846222,\n",
       "  'map@1': 0.01956947147846222,\n",
       "  'recall@5': 0.08317025750875473,\n",
       "  'ndcg@5': 0.0511941984295845,\n",
       "  'map@5': 0.040753427892923355,\n",
       "  'recall@10': 0.1340508759021759,\n",
       "  'ndcg@10': 0.06738412380218506,\n",
       "  'map@10': 0.04728318378329277,\n",
       "  'recall@20': 0.196673184633255,\n",
       "  'ndcg@20': 0.08314632624387741,\n",
       "  'map@20': 0.05157012864947319}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset_loo.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_test_dataset_gts_random)],\n",
    ")\n",
    "\n",
    "trainer_test = L.Trainer(callbacks=[test_metrics_callback], logger=csv_logger)\n",
    "trainer_test.validate(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee184c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
