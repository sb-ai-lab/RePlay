{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752ca432",
   "metadata": {},
   "source": [
    "# Example of the SASRec training with using RandomTargetNextNSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43869dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from replay.metrics import OfflineMetrics, Recall, Precision, MAP, NDCG, HitRate, MRR\n",
    "from replay.metrics.torch_metrics_builder import metrics_to_df\n",
    "from replay.splitters import LastNSplitter, RandomTargetNextNSplitter, TimeSplitter\n",
    "from replay.preprocessing.filters import MinCountFilter\n",
    "from replay.data import (\n",
    "    FeatureHint,\n",
    "    FeatureInfo,\n",
    "    FeatureSchema,\n",
    "    FeatureSource,\n",
    "    FeatureType,\n",
    "    Dataset,\n",
    ")\n",
    "from replay.models.nn.optimizer_utils import FatOptimizerFactory\n",
    "from replay.models.nn.sequential.callbacks import (\n",
    "    ValidationMetricsCallback,\n",
    "    SparkPredictionCallback,\n",
    "    PandasPredictionCallback,\n",
    "    TorchPredictionCallback,\n",
    "    QueryEmbeddingsPredictionCallback,\n",
    ")\n",
    "from replay.models.nn.sequential.postprocessors import RemoveSeenItems\n",
    "from replay.data.nn import SequenceTokenizer, SequentialDataset, TensorFeatureSource, TensorSchema, TensorFeatureInfo\n",
    "from replay.models.nn.sequential import SasRec\n",
    "from replay.models.nn.sequential.sasrec import (\n",
    "    SasRecPredictionDataset,\n",
    "    SasRecTrainingDataset,\n",
    "    SasRecValidationDataset,\n",
    "    SasRecPredictionBatch,\n",
    "    SasRecModel,\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900ff7b",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "### Load raw movielens-1M interactions, item features and user features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc630ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rs-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bb051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rs_datasets import MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928c6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens = MovieLens(\"1m\")\n",
    "interactions = movielens.ratings\n",
    "user_features = movielens.users\n",
    "item_features = movielens.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd2b17f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109\n",
       "2        1      914       3  978301968\n",
       "3        1     3408       4  978300275\n",
       "4        1     2355       5  978824291"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76ab5f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age  occupation zip_code\n",
       "0        1      F    1          10    48067\n",
       "1        2      M   56          16    70072\n",
       "2        3      M   25          15    55117\n",
       "3        4      M   45           7    02460\n",
       "4        5      M   25          20    55455"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a49fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7069e",
   "metadata": {},
   "source": [
    "Removing duplicates in the timestamp column without changing the original items order where timestamp is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "673ef18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[\"timestamp\"] = interactions[\"timestamp\"].astype(\"int64\")\n",
    "interactions = interactions.sort_values(by=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02d470",
   "metadata": {},
   "source": [
    "### Split interactions into the train, validation and test datasets using RandomTargetNextNSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "13fa04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_splitter = RandomTargetNextNSplitter(\n",
    "    N=1,\n",
    "    seed=42,\n",
    "    query_column=\"user_id\"\n",
    ")\n",
    "time_splitter = TimeSplitter(\n",
    "    time_threshold=0.1,\n",
    "    query_column=\"user_id\"\n",
    ")\n",
    "\n",
    "train_val, test_holdout = time_splitter.split(interactions)\n",
    "train, val_holdout = time_splitter.split(train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30133c1",
   "metadata": {},
   "source": [
    "Remove users with less than 1 interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3831acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cnt_filter = MinCountFilter(num_entries=1, groupby_column=\"user_id\")\n",
    "train = min_cnt_filter.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bea94d",
   "metadata": {},
   "source": [
    "Remove cold items from test_holdout, val_holdout based on filtered train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23786065",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_holdout = test_holdout[test_holdout[\"item_id\"].isin(train[\"item_id\"].unique())]\n",
    "val_holdout = val_holdout[val_holdout[\"item_id\"].isin(train[\"item_id\"].unique())]\n",
    "\n",
    "train_val = train_val[train_val[\"item_id\"].isin(train[\"item_id\"].unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d2593",
   "metadata": {},
   "source": [
    "Create input and target for validation and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f03ac52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input, val_target = random_splitter.split(val_holdout)\n",
    "test_input, test_target = random_splitter.split(test_holdout)\n",
    "\n",
    "test_input = pd.concat([train_val, test_input], axis=0)\n",
    "val_input = pd.concat([train, val_input], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fd90f",
   "metadata": {},
   "source": [
    "Remove targets with no input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8cc21ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_input[test_input[\"user_id\"].isin(test_target[\"user_id\"])]\n",
    "val_input = val_input[val_input[\"user_id\"].isin(val_target[\"user_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2e7cd1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 810169\n",
      "val_input: 170613\n",
      "val_target: 1045\n",
      "test_input: 314858\n",
      "test_target: 1208\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: {len(train)}\")\n",
    "print(f\"val_input: {len(val_input)}\")\n",
    "print(f\"val_target: {len(val_target)}\")\n",
    "print(f\"test_input: {len(test_input)}\")\n",
    "print(f\"test_target: {len(test_target)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ce3c6",
   "metadata": {},
   "source": [
    "### Prepare FeatureSchema required to create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c9a08545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_feature_schema(is_ground_truth: bool) -> FeatureSchema:\n",
    "    base_features = FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"user_id\",\n",
    "                feature_hint=FeatureHint.QUERY_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "            FeatureInfo(\n",
    "                column=\"item_id\",\n",
    "                feature_hint=FeatureHint.ITEM_ID,\n",
    "                feature_type=FeatureType.CATEGORICAL,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    if is_ground_truth:\n",
    "        return base_features\n",
    "\n",
    "    all_features = base_features + FeatureSchema(\n",
    "        [\n",
    "            FeatureInfo(\n",
    "                column=\"timestamp\",\n",
    "                feature_type=FeatureType.NUMERICAL,\n",
    "                feature_hint=FeatureHint.TIMESTAMP,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73168f8e",
   "metadata": {},
   "source": [
    "### Create Dataset for the training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c92dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=train,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5329979",
   "metadata": {},
   "source": [
    "### Create Datasets (events and ground_truth) for the validation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95243217",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=val_input,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=val_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394ea1b",
   "metadata": {},
   "source": [
    "### Create Datasets (events and ground_truth) for the testing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95b14dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=test_input,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=test_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d51216",
   "metadata": {},
   "source": [
    "### Create the tensor schema\n",
    "A schema shows the correspondence of columns from the source dataset with the internal representation of tensors inside the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8e25ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_FEATURE_NAME = \"item_id_seq\"\n",
    "\n",
    "tensor_schema = TensorSchema(\n",
    "    TensorFeatureInfo(\n",
    "        name=ITEM_FEATURE_NAME,\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_sources=[TensorFeatureSource(FeatureSource.INTERACTIONS, train_dataset.feature_schema.item_id_column)],\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3b615",
   "metadata": {},
   "source": [
    "### Create sequential datasets using SequenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c42effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset)\n",
    "\n",
    "sequential_train_dataset = tokenizer.transform(train_dataset)\n",
    "\n",
    "sequential_validation_dataset = tokenizer.transform(validation_dataset)\n",
    "sequential_validation_gt = tokenizer.transform(validation_gt, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_test_dataset = tokenizer.transform(test_dataset)\n",
    "sequential_test_gt = tokenizer.transform(test_gt, [tensor_schema.item_id_feature_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b98ff37",
   "metadata": {},
   "source": [
    "## Train model\n",
    "### Create SASRec model instance and run the training stage using lightning\n",
    "After each epoch validation metrics are shown. You can change the list of validation metrics in ValidationMetricsCallback\n",
    "The model is determined to be the best and is saved if the metric updates its maximum during validation (see the ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "model = SasRec(\n",
    "    tensor_schema,\n",
    "    block_count=2,\n",
    "    head_count=2,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"SASRec_example\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_validation_dataset)],\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=SasRecTrainingDataset(\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_validation_dataset,\n",
    "        sequential_validation_gt,\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d951b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SasRec.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    tensor_schema=tensor_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917d780",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_test_dataset,\n",
    "        sequential_test_gt,\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "052de593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fc6eb7ab174a69a65ddfcaedb12b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.020695  0.045578  0.049658  0.038562\n",
      "ndcg    0.020695  0.064293  0.079709  0.047215\n",
      "recall  0.020695  0.126656  0.188742  0.073675\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.020695364102721214    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@10           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04557809233665466    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@20           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04965835064649582    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.038562361150979996    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.020695364102721214    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@10          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06429333984851837    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@20          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0797085240483284     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04721491411328316    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.020695364102721214    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@10         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12665562331676483    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@20         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18874172866344452    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0736754983663559     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.020695364102721214   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@10          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04557809233665466   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@20          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04965835064649582   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.038562361150979996   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.020695364102721214   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@10         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06429333984851837   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@20         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0797085240483284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04721491411328316   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.020695364102721214   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@10        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12665562331676483   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@20        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18874172866344452   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0736754983663559    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'recall@1': 0.020695364102721214,\n",
       "  'ndcg@1': 0.020695364102721214,\n",
       "  'map@1': 0.020695364102721214,\n",
       "  'recall@5': 0.0736754983663559,\n",
       "  'ndcg@5': 0.04721491411328316,\n",
       "  'map@5': 0.038562361150979996,\n",
       "  'recall@10': 0.12665562331676483,\n",
       "  'ndcg@10': 0.06429333984851837,\n",
       "  'map@10': 0.04557809233665466,\n",
       "  'recall@20': 0.18874172866344452,\n",
       "  'ndcg@20': 0.0797085240483284,\n",
       "  'map@20': 0.04965835064649582}]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_test_dataset)],\n",
    ")\n",
    "\n",
    "trainer_test = L.Trainer(callbacks=[test_metrics_callback], logger=csv_logger)\n",
    "trainer_test.validate(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c4d71",
   "metadata": {},
   "source": [
    "## Comparing with LOO splitter \n",
    "\n",
    "In this section, we will train the same SASRec model using Leave-One-Out (LOO) splitter and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "61e2f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import T\n",
    "\n",
    "\n",
    "splitter = LastNSplitter(\n",
    "    N=1,\n",
    "    divide_column=\"user_id\",\n",
    "    query_column=\"user_id\",\n",
    "    strategy=\"interactions\",\n",
    ")\n",
    "\n",
    "test_input, test_target = splitter.split(interactions)\n",
    "train, val_target = splitter.split(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2e1797b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=train,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "\n",
    "validation_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=train,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "validation_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=val_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=False),\n",
    "    interactions=test_input,\n",
    "    query_features=user_features,\n",
    "    item_features=item_features,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n",
    "test_gt = Dataset(\n",
    "    feature_schema=prepare_feature_schema(is_ground_truth=True),\n",
    "    interactions=test_target,\n",
    "    check_consistency=True,\n",
    "    categorical_encoded=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c98ed298",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_FEATURE_NAME = \"item_id_seq\"\n",
    "\n",
    "tensor_schema = TensorSchema(\n",
    "    TensorFeatureInfo(\n",
    "        name=ITEM_FEATURE_NAME,\n",
    "        is_seq=True,\n",
    "        feature_type=FeatureType.CATEGORICAL,\n",
    "        feature_sources=[TensorFeatureSource(FeatureSource.INTERACTIONS, train_dataset.feature_schema.item_id_column)],\n",
    "        feature_hint=FeatureHint.ITEM_ID,\n",
    "    )\n",
    ")\n",
    "\n",
    "tokenizer = SequenceTokenizer(tensor_schema, allow_collect_to_master=True)\n",
    "tokenizer.fit(train_dataset)\n",
    "\n",
    "sequential_train_dataset = tokenizer.transform(train_dataset)\n",
    "\n",
    "sequential_validation_dataset = tokenizer.transform(validation_dataset)\n",
    "sequential_validation_gt = tokenizer.transform(validation_gt, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_validation_dataset, sequential_validation_gt = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_validation_dataset, sequential_validation_gt\n",
    ")\n",
    "\n",
    "sequential_test_dataset = tokenizer.transform(test_dataset)\n",
    "sequential_test_gt = tokenizer.transform(test_gt, [tensor_schema.item_id_feature_name])\n",
    "\n",
    "sequential_test_dataset, sequential_test_gt = SequentialDataset.keep_common_query_ids(\n",
    "    sequential_test_dataset, sequential_test_gt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44877b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "model = SasRec(\n",
    "    tensor_schema,\n",
    "    block_count=2,\n",
    "    head_count=2,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    hidden_size=300,\n",
    "    dropout_rate=0.5,\n",
    "    optimizer_factory=FatOptimizerFactory(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(save_dir=\".logs/train\", name=\"SASRec_example\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\".checkpoints\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    # if you use multiple dataloaders, then add the serial number of the dataloader to the suffix of the metric name.\n",
    "    # For example,\"recall@10/dataloader_idx_0\"\n",
    "    monitor=\"recall@10\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "validation_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_validation_dataset)],\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, validation_metrics_callback],\n",
    "    logger=csv_logger,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=SasRecTrainingDataset(\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=SasRecValidationDataset(\n",
    "        sequential_validation_dataset,\n",
    "        sequential_validation_gt,\n",
    "        sequential_train_dataset,\n",
    "        max_sequence_length=MAX_SEQ_LEN,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=validation_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b3ecf1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SasRec.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    tensor_schema=tensor_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a78fd",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "87ce8657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f79e1dca12442c9854b375dd691e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k              1        10        20         5\n",
      "map     0.001656  0.003494  0.004011  0.002718\n",
      "ndcg    0.001656  0.005145  0.007026  0.003269\n",
      "recall  0.001656  0.010762  0.018212  0.004967\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0016556291375309229   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@10           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0034939032047986984   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          map@20           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.00401055533438921    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           map@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0027179911267012358   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0016556291375309229   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@10          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0051450589671730995   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@20          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.007026043254882097    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          ndcg@5           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.003268592059612274    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0016556291375309229   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@10         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010761589743196964    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@20         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01821191981434822    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         recall@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.004966887645423412    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0016556291375309229  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@10          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0034939032047986984  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         map@20          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.00401055533438921   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          map@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0027179911267012358  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0016556291375309229  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@10         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0051450589671730995  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@20         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.007026043254882097   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         ndcg@5          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.003268592059612274   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0016556291375309229  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@10        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010761589743196964   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@20        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01821191981434822   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        recall@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.004966887645423412   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'recall@1': 0.0016556291375309229,\n",
       "  'ndcg@1': 0.0016556291375309229,\n",
       "  'map@1': 0.0016556291375309229,\n",
       "  'recall@5': 0.004966887645423412,\n",
       "  'ndcg@5': 0.003268592059612274,\n",
       "  'map@5': 0.0027179911267012358,\n",
       "  'recall@10': 0.010761589743196964,\n",
       "  'ndcg@10': 0.0051450589671730995,\n",
       "  'map@10': 0.0034939032047986984,\n",
       "  'recall@20': 0.01821191981434822,\n",
       "  'ndcg@20': 0.007026043254882097,\n",
       "  'map@20': 0.00401055533438921}]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_callback = ValidationMetricsCallback(\n",
    "    metrics=[\"map\", \"ndcg\", \"recall\"],\n",
    "    ks=[1, 5, 10, 20],\n",
    "    item_count=train_dataset.item_count,\n",
    "    postprocessors=[RemoveSeenItems(sequential_test_dataset)],\n",
    ")\n",
    "\n",
    "trainer_test = L.Trainer(callbacks=[test_metrics_callback], logger=csv_logger)\n",
    "trainer_test.validate(best_model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
